{
  "best_metric": 0.6018048524856567,
  "best_model_checkpoint": "output_zhihan_softmax1_Full_double/zhihan_softmax1_dnabert2_Full_double_H3K4me2/checkpoint-1200",
  "epoch": 5.0,
  "eval_steps": 200,
  "global_step": 15790,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06514657980456026,
      "grad_norm": 2.771411657333374,
      "learning_rate": 2.9670691547749724e-05,
      "loss": 0.6716,
      "step": 100
    },
    {
      "epoch": 0.13029315960912052,
      "grad_norm": 2.8540914058685303,
      "learning_rate": 2.901207464324918e-05,
      "loss": 0.6502,
      "step": 200
    },
    {
      "epoch": 0.13029315960912052,
      "eval_accuracy": 0.6285434995112414,
      "eval_f1": 0.6255368647100931,
      "eval_loss": 0.6427357792854309,
      "eval_matthews_correlation": 0.2598021302258264,
      "eval_precision": 0.627959763524705,
      "eval_recall": 0.6318718185518639,
      "eval_runtime": 2.2532,
      "eval_samples_per_second": 1362.039,
      "eval_steps_per_second": 42.605,
      "step": 200
    },
    {
      "epoch": 0.19543973941368079,
      "grad_norm": 1.8812662363052368,
      "learning_rate": 2.8353457738748626e-05,
      "loss": 0.6401,
      "step": 300
    },
    {
      "epoch": 0.26058631921824105,
      "grad_norm": 1.8454500436782837,
      "learning_rate": 2.769484083424808e-05,
      "loss": 0.6349,
      "step": 400
    },
    {
      "epoch": 0.26058631921824105,
      "eval_accuracy": 0.6536331052460085,
      "eval_f1": 0.6130407527229271,
      "eval_loss": 0.6395612359046936,
      "eval_matthews_correlation": 0.26000648800620035,
      "eval_precision": 0.645557799091368,
      "eval_recall": 0.6161108752456527,
      "eval_runtime": 2.0122,
      "eval_samples_per_second": 1525.209,
      "eval_steps_per_second": 47.709,
      "step": 400
    },
    {
      "epoch": 0.3257328990228013,
      "grad_norm": 4.921627521514893,
      "learning_rate": 2.703622392974753e-05,
      "loss": 0.6136,
      "step": 500
    },
    {
      "epoch": 0.39087947882736157,
      "grad_norm": 2.1207706928253174,
      "learning_rate": 2.637760702524698e-05,
      "loss": 0.6152,
      "step": 600
    },
    {
      "epoch": 0.39087947882736157,
      "eval_accuracy": 0.6591723688497882,
      "eval_f1": 0.6187785900560046,
      "eval_loss": 0.6274767518043518,
      "eval_matthews_correlation": 0.2726904244053274,
      "eval_precision": 0.6529660643455266,
      "eval_recall": 0.6215303340000788,
      "eval_runtime": 2.0278,
      "eval_samples_per_second": 1513.451,
      "eval_steps_per_second": 47.342,
      "step": 600
    },
    {
      "epoch": 0.4560260586319218,
      "grad_norm": 3.0993428230285645,
      "learning_rate": 2.5718990120746435e-05,
      "loss": 0.6231,
      "step": 700
    },
    {
      "epoch": 0.5211726384364821,
      "grad_norm": 3.9448235034942627,
      "learning_rate": 2.5060373216245883e-05,
      "loss": 0.6373,
      "step": 800
    },
    {
      "epoch": 0.5211726384364821,
      "eval_accuracy": 0.660475724991854,
      "eval_f1": 0.6344423868312757,
      "eval_loss": 0.6196973323822021,
      "eval_matthews_correlation": 0.2816253775379565,
      "eval_precision": 0.6487568507537049,
      "eval_recall": 0.6332927742008903,
      "eval_runtime": 2.0262,
      "eval_samples_per_second": 1514.635,
      "eval_steps_per_second": 47.379,
      "step": 800
    },
    {
      "epoch": 0.5863192182410424,
      "grad_norm": 1.9910342693328857,
      "learning_rate": 2.4401756311745337e-05,
      "loss": 0.6362,
      "step": 900
    },
    {
      "epoch": 0.6514657980456026,
      "grad_norm": 2.919733762741089,
      "learning_rate": 2.3743139407244784e-05,
      "loss": 0.6227,
      "step": 1000
    },
    {
      "epoch": 0.6514657980456026,
      "eval_accuracy": 0.6731834473769958,
      "eval_f1": 0.6446252139118833,
      "eval_loss": 0.6061502695083618,
      "eval_matthews_correlation": 0.3075356415672473,
      "eval_precision": 0.664842107381065,
      "eval_recall": 0.6434375177810945,
      "eval_runtime": 2.0274,
      "eval_samples_per_second": 1513.797,
      "eval_steps_per_second": 47.352,
      "step": 1000
    },
    {
      "epoch": 0.7166123778501629,
      "grad_norm": 1.3458707332611084,
      "learning_rate": 2.3084522502744238e-05,
      "loss": 0.6195,
      "step": 1100
    },
    {
      "epoch": 0.7817589576547231,
      "grad_norm": 2.1660399436950684,
      "learning_rate": 2.242590559824369e-05,
      "loss": 0.6056,
      "step": 1200
    },
    {
      "epoch": 0.7817589576547231,
      "eval_accuracy": 0.6748126425545781,
      "eval_f1": 0.6432389630890025,
      "eval_loss": 0.6018048524856567,
      "eval_matthews_correlation": 0.3100324897992671,
      "eval_precision": 0.6684809977364594,
      "eval_recall": 0.6426275752495919,
      "eval_runtime": 2.0307,
      "eval_samples_per_second": 1511.271,
      "eval_steps_per_second": 47.273,
      "step": 1200
    },
    {
      "epoch": 0.8469055374592834,
      "grad_norm": 2.307255744934082,
      "learning_rate": 2.176728869374314e-05,
      "loss": 0.6073,
      "step": 1300
    },
    {
      "epoch": 0.9120521172638436,
      "grad_norm": 2.711703300476074,
      "learning_rate": 2.110867178924259e-05,
      "loss": 0.5978,
      "step": 1400
    },
    {
      "epoch": 0.9120521172638436,
      "eval_accuracy": 0.6529814271749755,
      "eval_f1": 0.6448636464635874,
      "eval_loss": 0.616811215877533,
      "eval_matthews_correlation": 0.2903258764596017,
      "eval_precision": 0.6442141959229164,
      "eval_recall": 0.6461179220301743,
      "eval_runtime": 2.0247,
      "eval_samples_per_second": 1515.765,
      "eval_steps_per_second": 47.414,
      "step": 1400
    },
    {
      "epoch": 0.9771986970684039,
      "grad_norm": 2.3270559310913086,
      "learning_rate": 2.045005488474204e-05,
      "loss": 0.6175,
      "step": 1500
    },
    {
      "epoch": 1.0423452768729642,
      "grad_norm": 3.403353214263916,
      "learning_rate": 1.97980241492865e-05,
      "loss": 0.5681,
      "step": 1600
    },
    {
      "epoch": 1.0423452768729642,
      "eval_accuracy": 0.6868686868686869,
      "eval_f1": 0.6675396827991286,
      "eval_loss": 0.6203054189682007,
      "eval_matthews_correlation": 0.34202754298894344,
      "eval_precision": 0.6771750313587868,
      "eval_recall": 0.6650667693775631,
      "eval_runtime": 2.0292,
      "eval_samples_per_second": 1512.4,
      "eval_steps_per_second": 47.309,
      "step": 1600
    },
    {
      "epoch": 1.1074918566775245,
      "grad_norm": 7.120452880859375,
      "learning_rate": 1.913940724478595e-05,
      "loss": 0.511,
      "step": 1700
    },
    {
      "epoch": 1.1726384364820848,
      "grad_norm": 9.809470176696777,
      "learning_rate": 1.84807903402854e-05,
      "loss": 0.5543,
      "step": 1800
    },
    {
      "epoch": 1.1726384364820848,
      "eval_accuracy": 0.6920821114369502,
      "eval_f1": 0.6516121708493274,
      "eval_loss": 0.6252687573432922,
      "eval_matthews_correlation": 0.34962072327888455,
      "eval_precision": 0.7000865278093154,
      "eval_recall": 0.6527272369163971,
      "eval_runtime": 2.0299,
      "eval_samples_per_second": 1511.908,
      "eval_steps_per_second": 47.293,
      "step": 1800
    },
    {
      "epoch": 1.237785016286645,
      "grad_norm": 4.309272766113281,
      "learning_rate": 1.7822173435784854e-05,
      "loss": 0.5309,
      "step": 1900
    },
    {
      "epoch": 1.3029315960912053,
      "grad_norm": 5.3544135093688965,
      "learning_rate": 1.7163556531284302e-05,
      "loss": 0.5492,
      "step": 2000
    },
    {
      "epoch": 1.3029315960912053,
      "eval_accuracy": 0.6907787552948843,
      "eval_f1": 0.6719094655722359,
      "eval_loss": 0.6139483451843262,
      "eval_matthews_correlation": 0.3505454930675809,
      "eval_precision": 0.6814260886203103,
      "eval_recall": 0.6693281044149637,
      "eval_runtime": 2.0297,
      "eval_samples_per_second": 1512.074,
      "eval_steps_per_second": 47.298,
      "step": 2000
    },
    {
      "epoch": 1.3680781758957654,
      "grad_norm": 5.482283592224121,
      "learning_rate": 1.6504939626783756e-05,
      "loss": 0.5168,
      "step": 2100
    },
    {
      "epoch": 1.4332247557003257,
      "grad_norm": 7.043550491333008,
      "learning_rate": 1.5846322722283203e-05,
      "loss": 0.5177,
      "step": 2200
    },
    {
      "epoch": 1.4332247557003257,
      "eval_accuracy": 0.6940371456500489,
      "eval_f1": 0.6783384047262904,
      "eval_loss": 0.6245837807655334,
      "eval_matthews_correlation": 0.36013911630394374,
      "eval_precision": 0.6841876294815974,
      "eval_recall": 0.67604355875749,
      "eval_runtime": 2.0373,
      "eval_samples_per_second": 1506.43,
      "eval_steps_per_second": 47.122,
      "step": 2200
    },
    {
      "epoch": 1.498371335504886,
      "grad_norm": 6.214386940002441,
      "learning_rate": 1.5187705817782657e-05,
      "loss": 0.5288,
      "step": 2300
    },
    {
      "epoch": 1.5635179153094463,
      "grad_norm": 5.219539165496826,
      "learning_rate": 1.4529088913282108e-05,
      "loss": 0.516,
      "step": 2400
    },
    {
      "epoch": 1.5635179153094463,
      "eval_accuracy": 0.6800260671228413,
      "eval_f1": 0.6739486325082222,
      "eval_loss": 0.6245806217193604,
      "eval_matthews_correlation": 0.3496815052920795,
      "eval_precision": 0.6731034571524184,
      "eval_recall": 0.6765954839302675,
      "eval_runtime": 2.0341,
      "eval_samples_per_second": 1508.812,
      "eval_steps_per_second": 47.196,
      "step": 2400
    },
    {
      "epoch": 1.6286644951140063,
      "grad_norm": 9.82664966583252,
      "learning_rate": 1.3870472008781559e-05,
      "loss": 0.5087,
      "step": 2500
    },
    {
      "epoch": 1.6938110749185666,
      "grad_norm": 4.471195220947266,
      "learning_rate": 1.3211855104281011e-05,
      "loss": 0.5143,
      "step": 2600
    },
    {
      "epoch": 1.6938110749185666,
      "eval_accuracy": 0.6881720430107527,
      "eval_f1": 0.6468325128323895,
      "eval_loss": 0.6465321183204651,
      "eval_matthews_correlation": 0.34047815847116636,
      "eval_precision": 0.6952053887942544,
      "eval_recall": 0.6484659018789967,
      "eval_runtime": 2.0326,
      "eval_samples_per_second": 1509.913,
      "eval_steps_per_second": 47.231,
      "step": 2600
    },
    {
      "epoch": 1.758957654723127,
      "grad_norm": 6.5487847328186035,
      "learning_rate": 1.2553238199780462e-05,
      "loss": 0.5072,
      "step": 2700
    },
    {
      "epoch": 1.8241042345276872,
      "grad_norm": 7.181171417236328,
      "learning_rate": 1.1894621295279912e-05,
      "loss": 0.5087,
      "step": 2800
    },
    {
      "epoch": 1.8241042345276872,
      "eval_accuracy": 0.6959921798631477,
      "eval_f1": 0.6683512928600674,
      "eval_loss": 0.6278543472290039,
      "eval_matthews_correlation": 0.3577208191077052,
      "eval_precision": 0.6926956434271409,
      "eval_recall": 0.6660185229764568,
      "eval_runtime": 2.037,
      "eval_samples_per_second": 1506.607,
      "eval_steps_per_second": 47.127,
      "step": 2800
    },
    {
      "epoch": 1.8892508143322475,
      "grad_norm": 5.021544456481934,
      "learning_rate": 1.1236004390779363e-05,
      "loss": 0.4982,
      "step": 2900
    },
    {
      "epoch": 1.9543973941368078,
      "grad_norm": 5.204891204833984,
      "learning_rate": 1.0577387486278814e-05,
      "loss": 0.5053,
      "step": 3000
    },
    {
      "epoch": 1.9543973941368078,
      "eval_accuracy": 0.6956663408276311,
      "eval_f1": 0.6860544432265339,
      "eval_loss": 0.6240073442459106,
      "eval_matthews_correlation": 0.37211866916136177,
      "eval_precision": 0.6862345062387247,
      "eval_recall": 0.6858843276886109,
      "eval_runtime": 2.0392,
      "eval_samples_per_second": 1505.013,
      "eval_steps_per_second": 47.078,
      "step": 3000
    },
    {
      "epoch": 2.019543973941368,
      "grad_norm": 12.7387056350708,
      "learning_rate": 9.918770581778265e-06,
      "loss": 0.4652,
      "step": 3100
    },
    {
      "epoch": 2.0846905537459284,
      "grad_norm": 10.32815170288086,
      "learning_rate": 9.260153677277717e-06,
      "loss": 0.3655,
      "step": 3200
    },
    {
      "epoch": 2.0846905537459284,
      "eval_accuracy": 0.7005539263603779,
      "eval_f1": 0.6862174407640939,
      "eval_loss": 0.7047178149223328,
      "eval_matthews_correlation": 0.37496669658597687,
      "eval_precision": 0.690998029451926,
      "eval_recall": 0.684033343108376,
      "eval_runtime": 2.0566,
      "eval_samples_per_second": 1492.241,
      "eval_steps_per_second": 46.678,
      "step": 3200
    },
    {
      "epoch": 2.1498371335504887,
      "grad_norm": 12.356419563293457,
      "learning_rate": 8.60153677277717e-06,
      "loss": 0.3595,
      "step": 3300
    },
    {
      "epoch": 2.214983713355049,
      "grad_norm": 13.905800819396973,
      "learning_rate": 7.94291986827662e-06,
      "loss": 0.3504,
      "step": 3400
    },
    {
      "epoch": 2.214983713355049,
      "eval_accuracy": 0.6920821114369502,
      "eval_f1": 0.6574366140120964,
      "eval_loss": 0.7905325889587402,
      "eval_matthews_correlation": 0.3486028365303792,
      "eval_precision": 0.6937820605066494,
      "eval_recall": 0.6567791380163083,
      "eval_runtime": 2.0533,
      "eval_samples_per_second": 1494.687,
      "eval_steps_per_second": 46.755,
      "step": 3400
    },
    {
      "epoch": 2.2801302931596092,
      "grad_norm": 5.170810222625732,
      "learning_rate": 7.284302963776071e-06,
      "loss": 0.3434,
      "step": 3500
    },
    {
      "epoch": 2.3452768729641695,
      "grad_norm": 11.760454177856445,
      "learning_rate": 6.632272228320527e-06,
      "loss": 0.3547,
      "step": 3600
    },
    {
      "epoch": 2.3452768729641695,
      "eval_accuracy": 0.6976213750407299,
      "eval_f1": 0.6852265945171685,
      "eval_loss": 0.7290791869163513,
      "eval_matthews_correlation": 0.37144483367034925,
      "eval_precision": 0.6877348491285817,
      "eval_recall": 0.6837315569016907,
      "eval_runtime": 2.0621,
      "eval_samples_per_second": 1488.292,
      "eval_steps_per_second": 46.555,
      "step": 3600
    },
    {
      "epoch": 2.41042345276873,
      "grad_norm": 9.230633735656738,
      "learning_rate": 5.980241492864983e-06,
      "loss": 0.3423,
      "step": 3700
    },
    {
      "epoch": 2.47557003257329,
      "grad_norm": 9.068292617797852,
      "learning_rate": 5.321624588364435e-06,
      "loss": 0.3415,
      "step": 3800
    },
    {
      "epoch": 2.47557003257329,
      "eval_accuracy": 0.6966438579341805,
      "eval_f1": 0.6897339634272874,
      "eval_loss": 0.7652047872543335,
      "eval_matthews_correlation": 0.3802329530025858,
      "eval_precision": 0.6887778088491177,
      "eval_recall": 0.6914646369592906,
      "eval_runtime": 2.0632,
      "eval_samples_per_second": 1487.53,
      "eval_steps_per_second": 46.531,
      "step": 3800
    },
    {
      "epoch": 2.5407166123778504,
      "grad_norm": 5.243819236755371,
      "learning_rate": 4.6630076838638865e-06,
      "loss": 0.3189,
      "step": 3900
    },
    {
      "epoch": 2.6058631921824107,
      "grad_norm": 7.111670970916748,
      "learning_rate": 4.004390779363337e-06,
      "loss": 0.3341,
      "step": 4000
    },
    {
      "epoch": 2.6058631921824107,
      "eval_accuracy": 0.7018572825024438,
      "eval_f1": 0.6790569711634895,
      "eval_loss": 0.775640070438385,
      "eval_matthews_correlation": 0.37175665888522236,
      "eval_precision": 0.6963118211536434,
      "eval_recall": 0.6759993522210501,
      "eval_runtime": 2.0453,
      "eval_samples_per_second": 1500.511,
      "eval_steps_per_second": 46.937,
      "step": 4000
    },
    {
      "epoch": 2.6710097719869705,
      "grad_norm": 7.749329090118408,
      "learning_rate": 3.345773874862788e-06,
      "loss": 0.3459,
      "step": 4100
    },
    {
      "epoch": 2.736156351791531,
      "grad_norm": 12.187702178955078,
      "learning_rate": 2.6871569703622394e-06,
      "loss": 0.3435,
      "step": 4200
    },
    {
      "epoch": 2.736156351791531,
      "eval_accuracy": 0.7005539263603779,
      "eval_f1": 0.6863088773329462,
      "eval_loss": 0.7440248131752014,
      "eval_matthews_correlation": 0.3750695340106885,
      "eval_precision": 0.6909826689302672,
      "eval_recall": 0.6841491117112306,
      "eval_runtime": 2.0536,
      "eval_samples_per_second": 1494.467,
      "eval_steps_per_second": 46.748,
      "step": 4200
    },
    {
      "epoch": 2.801302931596091,
      "grad_norm": 10.710466384887695,
      "learning_rate": 2.0285400658616905e-06,
      "loss": 0.3535,
      "step": 4300
    },
    {
      "epoch": 2.8664495114006514,
      "grad_norm": 4.163182258605957,
      "learning_rate": 1.3699231613611414e-06,
      "loss": 0.3129,
      "step": 4400
    },
    {
      "epoch": 2.8664495114006514,
      "eval_accuracy": 0.7093515803193222,
      "eval_f1": 0.6887820250470655,
      "eval_loss": 0.7507220506668091,
      "eval_matthews_correlation": 0.3886623461615797,
      "eval_precision": 0.7036906313263672,
      "eval_recall": 0.6854017761398502,
      "eval_runtime": 2.0448,
      "eval_samples_per_second": 1500.907,
      "eval_steps_per_second": 46.949,
      "step": 4400
    },
    {
      "epoch": 2.9315960912052117,
      "grad_norm": 15.070542335510254,
      "learning_rate": 7.113062568605927e-07,
      "loss": 0.3163,
      "step": 4500
    },
    {
      "epoch": 2.996742671009772,
      "grad_norm": 13.312589645385742,
      "learning_rate": 5.268935236004391e-08,
      "loss": 0.3075,
      "step": 4600
    },
    {
      "epoch": 2.996742671009772,
      "eval_accuracy": 0.7054415118931248,
      "eval_f1": 0.6892277224173775,
      "eval_loss": 0.7559091448783875,
      "eval_matthews_correlation": 0.38317938586039574,
      "eval_precision": 0.6968543886352105,
      "eval_recall": 0.6864657968337615,
      "eval_runtime": 2.0513,
      "eval_samples_per_second": 1496.124,
      "eval_steps_per_second": 46.8,
      "step": 4600
    },
    {
      "epoch": 3.0,
      "step": 4605,
      "total_flos": 5838539879088128.0,
      "train_loss": 0.4950068317458891,
      "train_runtime": 326.8292,
      "train_samples_per_second": 225.301,
      "train_steps_per_second": 14.09
    },
    {
      "epoch": 1.4882837238758708,
      "grad_norm": 3.8203752040863037,
      "learning_rate": 2.981950601646612e-05,
      "loss": 0.8341,
      "step": 4700
    },
    {
      "epoch": 1.519949335022166,
      "grad_norm": 4.205009460449219,
      "learning_rate": 2.9629512349588347e-05,
      "loss": 0.7074,
      "step": 4800
    },
    {
      "epoch": 1.5516149461684612,
      "grad_norm": 3.4112043380737305,
      "learning_rate": 2.943951868271058e-05,
      "loss": 0.7037,
      "step": 4900
    },
    {
      "epoch": 1.5832805573147561,
      "grad_norm": 4.731504917144775,
      "learning_rate": 2.9249525015832804e-05,
      "loss": 0.6425,
      "step": 5000
    },
    {
      "epoch": 1.6149461684610513,
      "grad_norm": 6.1639404296875,
      "learning_rate": 2.9059531348955036e-05,
      "loss": 0.7085,
      "step": 5100
    },
    {
      "epoch": 1.6466117796073463,
      "grad_norm": 6.256903648376465,
      "learning_rate": 2.8869537682077265e-05,
      "loss": 0.665,
      "step": 5200
    },
    {
      "epoch": 1.6782773907536415,
      "grad_norm": 5.555464744567871,
      "learning_rate": 2.8679544015199494e-05,
      "loss": 0.6665,
      "step": 5300
    },
    {
      "epoch": 1.7099430018999366,
      "grad_norm": 2.8503220081329346,
      "learning_rate": 2.8489550348321722e-05,
      "loss": 0.622,
      "step": 5400
    },
    {
      "epoch": 1.7416086130462318,
      "grad_norm": 6.032345771789551,
      "learning_rate": 2.8299556681443954e-05,
      "loss": 0.6245,
      "step": 5500
    },
    {
      "epoch": 1.773274224192527,
      "grad_norm": 7.871797561645508,
      "learning_rate": 2.810956301456618e-05,
      "loss": 0.6278,
      "step": 5600
    },
    {
      "epoch": 1.8049398353388222,
      "grad_norm": 3.301053524017334,
      "learning_rate": 2.7919569347688412e-05,
      "loss": 0.656,
      "step": 5700
    },
    {
      "epoch": 1.8366054464851171,
      "grad_norm": 5.727723598480225,
      "learning_rate": 2.772957568081064e-05,
      "loss": 0.6399,
      "step": 5800
    },
    {
      "epoch": 1.8682710576314123,
      "grad_norm": 6.909485340118408,
      "learning_rate": 2.753958201393287e-05,
      "loss": 0.606,
      "step": 5900
    },
    {
      "epoch": 1.8999366687777073,
      "grad_norm": 7.559669017791748,
      "learning_rate": 2.7349588347055098e-05,
      "loss": 0.6393,
      "step": 6000
    },
    {
      "epoch": 1.9316022799240025,
      "grad_norm": 5.714965343475342,
      "learning_rate": 2.715959468017733e-05,
      "loss": 0.6163,
      "step": 6100
    },
    {
      "epoch": 1.9632678910702976,
      "grad_norm": 5.8549933433532715,
      "learning_rate": 2.6969601013299555e-05,
      "loss": 0.5876,
      "step": 6200
    },
    {
      "epoch": 1.9949335022165928,
      "grad_norm": 12.678625106811523,
      "learning_rate": 2.6779607346421787e-05,
      "loss": 0.6195,
      "step": 6300
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.40888035473909257,
      "eval_f1": 0.13667517279870584,
      "eval_loss": 0.48596900701522827,
      "eval_matthews_correlation": 0.259850843061459,
      "eval_precision": 0.10215325495058633,
      "eval_recall": 0.2072842617354867,
      "eval_runtime": 233.6225,
      "eval_samples_per_second": 216.229,
      "eval_steps_per_second": 13.518,
      "step": 6316
    },
    {
      "epoch": 2.026599113362888,
      "grad_norm": 11.711952209472656,
      "learning_rate": 2.6589613679544016e-05,
      "loss": 0.5417,
      "step": 6400
    },
    {
      "epoch": 2.058264724509183,
      "grad_norm": 8.448431015014648,
      "learning_rate": 2.6399620012666245e-05,
      "loss": 0.483,
      "step": 6500
    },
    {
      "epoch": 2.0899303356554784,
      "grad_norm": 10.878684997558594,
      "learning_rate": 2.6209626345788473e-05,
      "loss": 0.4752,
      "step": 6600
    },
    {
      "epoch": 2.121595946801773,
      "grad_norm": 9.272000312805176,
      "learning_rate": 2.6019632678910705e-05,
      "loss": 0.4644,
      "step": 6700
    },
    {
      "epoch": 2.1532615579480683,
      "grad_norm": 65.15754699707031,
      "learning_rate": 2.582963901203293e-05,
      "loss": 0.5465,
      "step": 6800
    },
    {
      "epoch": 2.1849271690943635,
      "grad_norm": 4.8607048988342285,
      "learning_rate": 2.5639645345155163e-05,
      "loss": 0.4736,
      "step": 6900
    },
    {
      "epoch": 2.2165927802406586,
      "grad_norm": 6.087337017059326,
      "learning_rate": 2.544965167827739e-05,
      "loss": 0.5226,
      "step": 7000
    },
    {
      "epoch": 2.248258391386954,
      "grad_norm": 14.196633338928223,
      "learning_rate": 2.525965801139962e-05,
      "loss": 0.4623,
      "step": 7100
    },
    {
      "epoch": 2.279924002533249,
      "grad_norm": 18.248287200927734,
      "learning_rate": 2.506966434452185e-05,
      "loss": 0.4745,
      "step": 7200
    },
    {
      "epoch": 2.311589613679544,
      "grad_norm": 16.443065643310547,
      "learning_rate": 2.487967067764408e-05,
      "loss": 0.443,
      "step": 7300
    },
    {
      "epoch": 2.343255224825839,
      "grad_norm": 16.65764808654785,
      "learning_rate": 2.4689677010766306e-05,
      "loss": 0.4631,
      "step": 7400
    },
    {
      "epoch": 2.374920835972134,
      "grad_norm": 13.888747215270996,
      "learning_rate": 2.4499683343888538e-05,
      "loss": 0.4715,
      "step": 7500
    },
    {
      "epoch": 2.4065864471184293,
      "grad_norm": 15.690165519714355,
      "learning_rate": 2.4309689677010767e-05,
      "loss": 0.4682,
      "step": 7600
    },
    {
      "epoch": 2.4382520582647245,
      "grad_norm": 24.427169799804688,
      "learning_rate": 2.4119696010132995e-05,
      "loss": 0.4552,
      "step": 7700
    },
    {
      "epoch": 2.4699176694110196,
      "grad_norm": 11.369894027709961,
      "learning_rate": 2.3929702343255224e-05,
      "loss": 0.4128,
      "step": 7800
    },
    {
      "epoch": 2.501583280557315,
      "grad_norm": 8.589340209960938,
      "learning_rate": 2.3739708676377456e-05,
      "loss": 0.4601,
      "step": 7900
    },
    {
      "epoch": 2.53324889170361,
      "grad_norm": 8.45804214477539,
      "learning_rate": 2.354971500949968e-05,
      "loss": 0.4378,
      "step": 8000
    },
    {
      "epoch": 2.5649145028499047,
      "grad_norm": 4.62851095199585,
      "learning_rate": 2.3359721342621913e-05,
      "loss": 0.4023,
      "step": 8100
    },
    {
      "epoch": 2.5965801139962004,
      "grad_norm": 2.162088394165039,
      "learning_rate": 2.3169727675744142e-05,
      "loss": 0.4216,
      "step": 8200
    },
    {
      "epoch": 2.628245725142495,
      "grad_norm": 14.855228424072266,
      "learning_rate": 2.297973400886637e-05,
      "loss": 0.4157,
      "step": 8300
    },
    {
      "epoch": 2.6599113362887903,
      "grad_norm": 513.1456298828125,
      "learning_rate": 2.27897403419886e-05,
      "loss": 0.3996,
      "step": 8400
    },
    {
      "epoch": 2.6915769474350855,
      "grad_norm": 13.2334623336792,
      "learning_rate": 2.259974667511083e-05,
      "loss": 0.4094,
      "step": 8500
    },
    {
      "epoch": 2.7232425585813806,
      "grad_norm": 25.247095108032227,
      "learning_rate": 2.2409753008233057e-05,
      "loss": 0.3479,
      "step": 8600
    },
    {
      "epoch": 2.754908169727676,
      "grad_norm": 6.274057865142822,
      "learning_rate": 2.221975934135529e-05,
      "loss": 0.4077,
      "step": 8700
    },
    {
      "epoch": 2.786573780873971,
      "grad_norm": 7.044394493103027,
      "learning_rate": 2.2029765674477518e-05,
      "loss": 0.3563,
      "step": 8800
    },
    {
      "epoch": 2.818239392020266,
      "grad_norm": 9.678951263427734,
      "learning_rate": 2.1839772007599746e-05,
      "loss": 0.3784,
      "step": 8900
    },
    {
      "epoch": 2.849905003166561,
      "grad_norm": 12.993939399719238,
      "learning_rate": 2.1649778340721975e-05,
      "loss": 0.3854,
      "step": 9000
    },
    {
      "epoch": 2.881570614312856,
      "grad_norm": 17.780302047729492,
      "learning_rate": 2.1459784673844207e-05,
      "loss": 0.3373,
      "step": 9100
    },
    {
      "epoch": 2.9132362254591513,
      "grad_norm": 12.244216918945312,
      "learning_rate": 2.1269791006966432e-05,
      "loss": 0.3607,
      "step": 9200
    },
    {
      "epoch": 2.9449018366054465,
      "grad_norm": 12.297382354736328,
      "learning_rate": 2.1079797340088664e-05,
      "loss": 0.3999,
      "step": 9300
    },
    {
      "epoch": 2.9765674477517416,
      "grad_norm": 11.20114803314209,
      "learning_rate": 2.0889803673210893e-05,
      "loss": 0.3725,
      "step": 9400
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.45658801171905933,
      "eval_f1": 0.15324290134867857,
      "eval_loss": 0.26324379444122314,
      "eval_matthews_correlation": 0.340943181016452,
      "eval_precision": 0.11361538560332202,
      "eval_recall": 0.23582467130092122,
      "eval_runtime": 78.4924,
      "eval_samples_per_second": 643.579,
      "eval_steps_per_second": 40.233,
      "step": 9474
    },
    {
      "epoch": 3.008233058898037,
      "grad_norm": 10.400343894958496,
      "learning_rate": 2.069981000633312e-05,
      "loss": 0.3745,
      "step": 9500
    },
    {
      "epoch": 3.039898670044332,
      "grad_norm": 34.30104064941406,
      "learning_rate": 2.050981633945535e-05,
      "loss": 0.2391,
      "step": 9600
    },
    {
      "epoch": 3.071564281190627,
      "grad_norm": 55.91737365722656,
      "learning_rate": 2.0319822672577582e-05,
      "loss": 0.2784,
      "step": 9700
    },
    {
      "epoch": 3.103229892336922,
      "grad_norm": 3.0473244190216064,
      "learning_rate": 2.0129829005699808e-05,
      "loss": 0.2961,
      "step": 9800
    },
    {
      "epoch": 3.134895503483217,
      "grad_norm": 12.099723815917969,
      "learning_rate": 1.993983533882204e-05,
      "loss": 0.2476,
      "step": 9900
    },
    {
      "epoch": 3.1665611146295123,
      "grad_norm": 26.356224060058594,
      "learning_rate": 1.974984167194427e-05,
      "loss": 0.2898,
      "step": 10000
    },
    {
      "epoch": 3.1982267257758075,
      "grad_norm": 10.010144233703613,
      "learning_rate": 1.9559848005066497e-05,
      "loss": 0.2561,
      "step": 10100
    },
    {
      "epoch": 3.2298923369221026,
      "grad_norm": 8.859146118164062,
      "learning_rate": 1.9369854338188726e-05,
      "loss": 0.2579,
      "step": 10200
    },
    {
      "epoch": 3.261557948068398,
      "grad_norm": 1.0432593822479248,
      "learning_rate": 1.9179860671310958e-05,
      "loss": 0.2172,
      "step": 10300
    },
    {
      "epoch": 3.293223559214693,
      "grad_norm": 40.76223373413086,
      "learning_rate": 1.8989867004433183e-05,
      "loss": 0.2539,
      "step": 10400
    },
    {
      "epoch": 3.324889170360988,
      "grad_norm": 7.108303070068359,
      "learning_rate": 1.8799873337555415e-05,
      "loss": 0.2141,
      "step": 10500
    },
    {
      "epoch": 3.356554781507283,
      "grad_norm": 26.360010147094727,
      "learning_rate": 1.8609879670677644e-05,
      "loss": 0.2316,
      "step": 10600
    },
    {
      "epoch": 3.388220392653578,
      "grad_norm": 1.5457892417907715,
      "learning_rate": 1.8419886003799872e-05,
      "loss": 0.2744,
      "step": 10700
    },
    {
      "epoch": 3.4198860037998733,
      "grad_norm": 21.146068572998047,
      "learning_rate": 1.82298923369221e-05,
      "loss": 0.2616,
      "step": 10800
    },
    {
      "epoch": 3.4515516149461685,
      "grad_norm": 19.165922164916992,
      "learning_rate": 1.8039898670044333e-05,
      "loss": 0.1876,
      "step": 10900
    },
    {
      "epoch": 3.4832172260924636,
      "grad_norm": 7.459912300109863,
      "learning_rate": 1.784990500316656e-05,
      "loss": 0.2339,
      "step": 11000
    },
    {
      "epoch": 3.514882837238759,
      "grad_norm": 18.906042098999023,
      "learning_rate": 1.765991133628879e-05,
      "loss": 0.1562,
      "step": 11100
    },
    {
      "epoch": 3.546548448385054,
      "grad_norm": 2.894824266433716,
      "learning_rate": 1.746991766941102e-05,
      "loss": 0.2085,
      "step": 11200
    },
    {
      "epoch": 3.5782140595313487,
      "grad_norm": 46.40732192993164,
      "learning_rate": 1.7279924002533248e-05,
      "loss": 0.235,
      "step": 11300
    },
    {
      "epoch": 3.609879670677644,
      "grad_norm": 0.11254791170358658,
      "learning_rate": 1.7089930335655477e-05,
      "loss": 0.2148,
      "step": 11400
    },
    {
      "epoch": 3.641545281823939,
      "grad_norm": 88.63898468017578,
      "learning_rate": 1.689993666877771e-05,
      "loss": 0.2359,
      "step": 11500
    },
    {
      "epoch": 3.6732108929702343,
      "grad_norm": 0.3571517765522003,
      "learning_rate": 1.6709943001899934e-05,
      "loss": 0.2076,
      "step": 11600
    },
    {
      "epoch": 3.7048765041165295,
      "grad_norm": 14.621962547302246,
      "learning_rate": 1.6519949335022166e-05,
      "loss": 0.194,
      "step": 11700
    },
    {
      "epoch": 3.7365421152628246,
      "grad_norm": 0.22318825125694275,
      "learning_rate": 1.6329955668144395e-05,
      "loss": 0.2658,
      "step": 11800
    },
    {
      "epoch": 3.76820772640912,
      "grad_norm": 0.12140699476003647,
      "learning_rate": 1.6139962001266623e-05,
      "loss": 0.2278,
      "step": 11900
    },
    {
      "epoch": 3.7998733375554146,
      "grad_norm": 1.381942629814148,
      "learning_rate": 1.5949968334388852e-05,
      "loss": 0.2017,
      "step": 12000
    },
    {
      "epoch": 3.83153894870171,
      "grad_norm": 0.36570224165916443,
      "learning_rate": 1.5759974667511084e-05,
      "loss": 0.2252,
      "step": 12100
    },
    {
      "epoch": 3.863204559848005,
      "grad_norm": 3.761911153793335,
      "learning_rate": 1.5569981000633313e-05,
      "loss": 0.168,
      "step": 12200
    },
    {
      "epoch": 3.8948701709943,
      "grad_norm": 0.11029236763715744,
      "learning_rate": 1.537998733375554e-05,
      "loss": 0.164,
      "step": 12300
    },
    {
      "epoch": 3.9265357821405953,
      "grad_norm": 7.520323276519775,
      "learning_rate": 1.518999366687777e-05,
      "loss": 0.1874,
      "step": 12400
    },
    {
      "epoch": 3.9582013932868905,
      "grad_norm": 38.13560485839844,
      "learning_rate": 1.5e-05,
      "loss": 0.2323,
      "step": 12500
    },
    {
      "epoch": 3.9898670044331856,
      "grad_norm": 63.346900939941406,
      "learning_rate": 1.4810006333122229e-05,
      "loss": 0.1868,
      "step": 12600
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.4775714625069285,
      "eval_f1": 0.16063275308268485,
      "eval_loss": 0.127725288271904,
      "eval_matthews_correlation": 0.3747323170534486,
      "eval_precision": 0.11923189292678583,
      "eval_recall": 0.24612539702801184,
      "eval_runtime": 79.8152,
      "eval_samples_per_second": 632.912,
      "eval_steps_per_second": 39.566,
      "step": 12632
    },
    {
      "epoch": 4.02153261557948,
      "grad_norm": 0.07075242698192596,
      "learning_rate": 1.462001266624446e-05,
      "loss": 0.1622,
      "step": 12700
    },
    {
      "epoch": 4.053198226725776,
      "grad_norm": 0.20397540926933289,
      "learning_rate": 1.4430018999366688e-05,
      "loss": 0.1141,
      "step": 12800
    },
    {
      "epoch": 4.084863837872071,
      "grad_norm": 0.12781448662281036,
      "learning_rate": 1.4240025332488917e-05,
      "loss": 0.0925,
      "step": 12900
    },
    {
      "epoch": 4.116529449018366,
      "grad_norm": 5.763382911682129,
      "learning_rate": 1.4050031665611147e-05,
      "loss": 0.1197,
      "step": 13000
    },
    {
      "epoch": 4.148195060164661,
      "grad_norm": 0.36271026730537415,
      "learning_rate": 1.3860037998733376e-05,
      "loss": 0.1521,
      "step": 13100
    },
    {
      "epoch": 4.179860671310957,
      "grad_norm": 0.2745439410209656,
      "learning_rate": 1.3670044331855604e-05,
      "loss": 0.1178,
      "step": 13200
    },
    {
      "epoch": 4.2115262824572515,
      "grad_norm": 0.18416067957878113,
      "learning_rate": 1.3480050664977835e-05,
      "loss": 0.1573,
      "step": 13300
    },
    {
      "epoch": 4.243191893603546,
      "grad_norm": 14.95043659210205,
      "learning_rate": 1.3290056998100063e-05,
      "loss": 0.1309,
      "step": 13400
    },
    {
      "epoch": 4.274857504749842,
      "grad_norm": 1.124822974205017,
      "learning_rate": 1.3100063331222292e-05,
      "loss": 0.1268,
      "step": 13500
    },
    {
      "epoch": 4.306523115896137,
      "grad_norm": 0.1816752552986145,
      "learning_rate": 1.2910069664344523e-05,
      "loss": 0.1877,
      "step": 13600
    },
    {
      "epoch": 4.338188727042432,
      "grad_norm": 0.37014827132225037,
      "learning_rate": 1.2720075997466751e-05,
      "loss": 0.1384,
      "step": 13700
    },
    {
      "epoch": 4.369854338188727,
      "grad_norm": 102.50501251220703,
      "learning_rate": 1.253008233058898e-05,
      "loss": 0.1029,
      "step": 13800
    },
    {
      "epoch": 4.4015199493350226,
      "grad_norm": 0.05914000794291496,
      "learning_rate": 1.234008866371121e-05,
      "loss": 0.1194,
      "step": 13900
    },
    {
      "epoch": 4.433185560481317,
      "grad_norm": 0.21128305792808533,
      "learning_rate": 1.2150094996833439e-05,
      "loss": 0.127,
      "step": 14000
    },
    {
      "epoch": 4.464851171627612,
      "grad_norm": 0.9437077641487122,
      "learning_rate": 1.1960101329955668e-05,
      "loss": 0.138,
      "step": 14100
    },
    {
      "epoch": 4.496516782773908,
      "grad_norm": 43.37318801879883,
      "learning_rate": 1.1770107663077898e-05,
      "loss": 0.1254,
      "step": 14200
    },
    {
      "epoch": 4.528182393920202,
      "grad_norm": 50.349979400634766,
      "learning_rate": 1.1580113996200127e-05,
      "loss": 0.1278,
      "step": 14300
    },
    {
      "epoch": 4.559848005066498,
      "grad_norm": 13.544761657714844,
      "learning_rate": 1.1390120329322355e-05,
      "loss": 0.1385,
      "step": 14400
    },
    {
      "epoch": 4.591513616212793,
      "grad_norm": 6.419066429138184,
      "learning_rate": 1.1200126662444586e-05,
      "loss": 0.1018,
      "step": 14500
    },
    {
      "epoch": 4.623179227359088,
      "grad_norm": 0.0652332678437233,
      "learning_rate": 1.1010132995566814e-05,
      "loss": 0.111,
      "step": 14600
    },
    {
      "epoch": 4.654844838505383,
      "grad_norm": 0.17608188092708588,
      "learning_rate": 1.0820139328689043e-05,
      "loss": 0.1253,
      "step": 14700
    },
    {
      "epoch": 4.686510449651678,
      "grad_norm": 127.1986312866211,
      "learning_rate": 1.0630145661811273e-05,
      "loss": 0.1452,
      "step": 14800
    },
    {
      "epoch": 4.7181760607979735,
      "grad_norm": 2.40960693359375,
      "learning_rate": 1.0440151994933502e-05,
      "loss": 0.1023,
      "step": 14900
    },
    {
      "epoch": 4.749841671944268,
      "grad_norm": 107.06500244140625,
      "learning_rate": 1.025015832805573e-05,
      "loss": 0.1236,
      "step": 15000
    },
    {
      "epoch": 4.781507283090564,
      "grad_norm": 0.7200073003768921,
      "learning_rate": 1.0060164661177961e-05,
      "loss": 0.1103,
      "step": 15100
    },
    {
      "epoch": 4.813172894236859,
      "grad_norm": 1.3435497283935547,
      "learning_rate": 9.87017099430019e-06,
      "loss": 0.1392,
      "step": 15200
    },
    {
      "epoch": 4.844838505383154,
      "grad_norm": 61.500885009765625,
      "learning_rate": 9.680177327422418e-06,
      "loss": 0.1126,
      "step": 15300
    },
    {
      "epoch": 4.876504116529449,
      "grad_norm": 4.5894999504089355,
      "learning_rate": 9.490183660544649e-06,
      "loss": 0.1393,
      "step": 15400
    },
    {
      "epoch": 4.9081697276757446,
      "grad_norm": 0.616569459438324,
      "learning_rate": 9.300189993666877e-06,
      "loss": 0.1242,
      "step": 15500
    },
    {
      "epoch": 4.939835338822039,
      "grad_norm": 0.09364727884531021,
      "learning_rate": 9.110196326789108e-06,
      "loss": 0.1024,
      "step": 15600
    },
    {
      "epoch": 4.971500949968334,
      "grad_norm": 30.215133666992188,
      "learning_rate": 8.920202659911336e-06,
      "loss": 0.1342,
      "step": 15700
    }
  ],
  "logging_steps": 100,
  "max_steps": 15790,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.149214381944832e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
