{
  "best_metric": 0.5016831159591675,
  "best_model_checkpoint": "output_zhihan_softmax1_Full_double/zhihan_softmax1_dnabert2_Full_double_H3K14ac/checkpoint-1600",
  "epoch": 4.9955921245959445,
  "eval_steps": 200,
  "global_step": 17000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.060496067755595885,
      "grad_norm": 3.3884329795837402,
      "learning_rate": 2.9694438785903442e-05,
      "loss": 0.6583,
      "step": 100
    },
    {
      "epoch": 0.12099213551119177,
      "grad_norm": 13.358588218688965,
      "learning_rate": 2.908942758199226e-05,
      "loss": 0.6039,
      "step": 200
    },
    {
      "epoch": 0.12099213551119177,
      "eval_accuracy": 0.7040847201210287,
      "eval_f1": 0.6751093794100547,
      "eval_loss": 0.6016627550125122,
      "eval_matthews_correlation": 0.37851809940903575,
      "eval_precision": 0.7069315750195573,
      "eval_recall": 0.673095806629181,
      "eval_runtime": 2.5446,
      "eval_samples_per_second": 1298.806,
      "eval_steps_per_second": 40.87,
      "step": 200
    },
    {
      "epoch": 0.18148820326678766,
      "grad_norm": 3.160977840423584,
      "learning_rate": 2.8478305153799145e-05,
      "loss": 0.6072,
      "step": 300
    },
    {
      "epoch": 0.24198427102238354,
      "grad_norm": 10.056490898132324,
      "learning_rate": 2.786718272560603e-05,
      "loss": 0.5859,
      "step": 400
    },
    {
      "epoch": 0.24198427102238354,
      "eval_accuracy": 0.7077155824508321,
      "eval_f1": 0.705587314866456,
      "eval_loss": 0.5810941457748413,
      "eval_matthews_correlation": 0.4204833037892117,
      "eval_precision": 0.7073442706998205,
      "eval_recall": 0.7131795204284412,
      "eval_runtime": 2.2172,
      "eval_samples_per_second": 1490.626,
      "eval_steps_per_second": 46.906,
      "step": 400
    },
    {
      "epoch": 0.3024803387779794,
      "grad_norm": 2.2259016036987305,
      "learning_rate": 2.7256060297412914e-05,
      "loss": 0.5737,
      "step": 500
    },
    {
      "epoch": 0.3629764065335753,
      "grad_norm": 3.4902195930480957,
      "learning_rate": 2.66449378692198e-05,
      "loss": 0.5573,
      "step": 600
    },
    {
      "epoch": 0.3629764065335753,
      "eval_accuracy": 0.740393343419062,
      "eval_f1": 0.7273452601733643,
      "eval_loss": 0.538860023021698,
      "eval_matthews_correlation": 0.45917439615806377,
      "eval_precision": 0.7352928731137586,
      "eval_recall": 0.7240198813684273,
      "eval_runtime": 2.2201,
      "eval_samples_per_second": 1488.7,
      "eval_steps_per_second": 46.846,
      "step": 600
    },
    {
      "epoch": 0.42347247428917123,
      "grad_norm": 3.9062657356262207,
      "learning_rate": 2.6033815441026687e-05,
      "loss": 0.5601,
      "step": 700
    },
    {
      "epoch": 0.4839685420447671,
      "grad_norm": 5.350819110870361,
      "learning_rate": 2.542269301283357e-05,
      "loss": 0.5785,
      "step": 800
    },
    {
      "epoch": 0.4839685420447671,
      "eval_accuracy": 0.7228441754916792,
      "eval_f1": 0.6961860123814502,
      "eval_loss": 0.572584867477417,
      "eval_matthews_correlation": 0.42052351962318685,
      "eval_precision": 0.7293103618139691,
      "eval_recall": 0.6927955077535228,
      "eval_runtime": 2.2173,
      "eval_samples_per_second": 1490.538,
      "eval_steps_per_second": 46.903,
      "step": 800
    },
    {
      "epoch": 0.5444646098003629,
      "grad_norm": 2.534309148788452,
      "learning_rate": 2.481157058464046e-05,
      "loss": 0.5489,
      "step": 900
    },
    {
      "epoch": 0.6049606775559588,
      "grad_norm": 6.310018539428711,
      "learning_rate": 2.4200448156447342e-05,
      "loss": 0.5452,
      "step": 1000
    },
    {
      "epoch": 0.6049606775559588,
      "eval_accuracy": 0.7470499243570348,
      "eval_f1": 0.7377306809673299,
      "eval_loss": 0.5235593318939209,
      "eval_matthews_correlation": 0.4762900247116125,
      "eval_precision": 0.7402965415244771,
      "eval_recall": 0.7360127472087242,
      "eval_runtime": 2.2221,
      "eval_samples_per_second": 1487.35,
      "eval_steps_per_second": 46.803,
      "step": 1000
    },
    {
      "epoch": 0.6654567453115547,
      "grad_norm": 4.049527168273926,
      "learning_rate": 2.3589325728254225e-05,
      "loss": 0.5274,
      "step": 1100
    },
    {
      "epoch": 0.7259528130671506,
      "grad_norm": 5.266887664794922,
      "learning_rate": 2.2978203300061114e-05,
      "loss": 0.5385,
      "step": 1200
    },
    {
      "epoch": 0.7259528130671506,
      "eval_accuracy": 0.7497730711043873,
      "eval_f1": 0.7464919327275448,
      "eval_loss": 0.521052360534668,
      "eval_matthews_correlation": 0.49707956001822023,
      "eval_precision": 0.7455849646172227,
      "eval_recall": 0.7515301469829674,
      "eval_runtime": 2.2234,
      "eval_samples_per_second": 1486.435,
      "eval_steps_per_second": 46.774,
      "step": 1200
    },
    {
      "epoch": 0.7864488808227466,
      "grad_norm": 5.422243118286133,
      "learning_rate": 2.2373192096149928e-05,
      "loss": 0.5461,
      "step": 1300
    },
    {
      "epoch": 0.8469449485783425,
      "grad_norm": 2.652207851409912,
      "learning_rate": 2.1762069667956814e-05,
      "loss": 0.5463,
      "step": 1400
    },
    {
      "epoch": 0.8469449485783425,
      "eval_accuracy": 0.7340393343419062,
      "eval_f1": 0.7337225226440737,
      "eval_loss": 0.5379589796066284,
      "eval_matthews_correlation": 0.49312496122662314,
      "eval_precision": 0.744302698834443,
      "eval_recall": 0.7488431652054215,
      "eval_runtime": 2.2184,
      "eval_samples_per_second": 1489.783,
      "eval_steps_per_second": 46.88,
      "step": 1400
    },
    {
      "epoch": 0.9074410163339383,
      "grad_norm": 5.12576150894165,
      "learning_rate": 2.11509472397637e-05,
      "loss": 0.5367,
      "step": 1500
    },
    {
      "epoch": 0.9679370840895342,
      "grad_norm": 8.16061019897461,
      "learning_rate": 2.0539824811570587e-05,
      "loss": 0.5114,
      "step": 1600
    },
    {
      "epoch": 0.9679370840895342,
      "eval_accuracy": 0.7594553706505295,
      "eval_f1": 0.7554301310525335,
      "eval_loss": 0.5016831159591675,
      "eval_matthews_correlation": 0.5130151535401177,
      "eval_precision": 0.7540256917565266,
      "eval_recall": 0.7590137103278145,
      "eval_runtime": 2.2287,
      "eval_samples_per_second": 1482.912,
      "eval_steps_per_second": 46.663,
      "step": 1600
    },
    {
      "epoch": 1.02843315184513,
      "grad_norm": 3.597937822341919,
      "learning_rate": 1.992870238337747e-05,
      "loss": 0.4728,
      "step": 1700
    },
    {
      "epoch": 1.0889292196007259,
      "grad_norm": 4.164131164550781,
      "learning_rate": 1.9317579955184356e-05,
      "loss": 0.4391,
      "step": 1800
    },
    {
      "epoch": 1.0889292196007259,
      "eval_accuracy": 0.7576399394856278,
      "eval_f1": 0.7558625207854918,
      "eval_loss": 0.5162401795387268,
      "eval_matthews_correlation": 0.5216293375302793,
      "eval_precision": 0.7572210845341314,
      "eval_recall": 0.76445845824137,
      "eval_runtime": 2.2251,
      "eval_samples_per_second": 1485.347,
      "eval_steps_per_second": 46.74,
      "step": 1800
    },
    {
      "epoch": 1.1494252873563218,
      "grad_norm": 6.602136611938477,
      "learning_rate": 1.8706457526991242e-05,
      "loss": 0.4481,
      "step": 1900
    },
    {
      "epoch": 1.2099213551119177,
      "grad_norm": 12.043084144592285,
      "learning_rate": 1.8095335098798125e-05,
      "loss": 0.4145,
      "step": 2000
    },
    {
      "epoch": 1.2099213551119177,
      "eval_accuracy": 0.7476550680786687,
      "eval_f1": 0.7374039404699573,
      "eval_loss": 0.5343993902206421,
      "eval_matthews_correlation": 0.476429792087823,
      "eval_precision": 0.7413810299930105,
      "eval_recall": 0.7350902914734216,
      "eval_runtime": 2.2216,
      "eval_samples_per_second": 1487.666,
      "eval_steps_per_second": 46.813,
      "step": 2000
    },
    {
      "epoch": 1.2704174228675136,
      "grad_norm": 8.10683822631836,
      "learning_rate": 1.7484212670605014e-05,
      "loss": 0.4648,
      "step": 2100
    },
    {
      "epoch": 1.3309134906231095,
      "grad_norm": 11.925862312316895,
      "learning_rate": 1.6873090242411897e-05,
      "loss": 0.4511,
      "step": 2200
    },
    {
      "epoch": 1.3309134906231095,
      "eval_accuracy": 0.7521936459909229,
      "eval_f1": 0.7453967835920396,
      "eval_loss": 0.5251129865646362,
      "eval_matthews_correlation": 0.49080056234079605,
      "eval_precision": 0.745225838373311,
      "eval_recall": 0.7455748480583624,
      "eval_runtime": 2.2287,
      "eval_samples_per_second": 1482.911,
      "eval_steps_per_second": 46.663,
      "step": 2200
    },
    {
      "epoch": 1.3914095583787054,
      "grad_norm": 9.456466674804688,
      "learning_rate": 1.626196781421878e-05,
      "loss": 0.4019,
      "step": 2300
    },
    {
      "epoch": 1.4519056261343013,
      "grad_norm": 8.966322898864746,
      "learning_rate": 1.565084538602567e-05,
      "loss": 0.4186,
      "step": 2400
    },
    {
      "epoch": 1.4519056261343013,
      "eval_accuracy": 0.7612708018154312,
      "eval_f1": 0.7506531186325057,
      "eval_loss": 0.5184229612350464,
      "eval_matthews_correlation": 0.5040055415440425,
      "eval_precision": 0.7564876180045588,
      "eval_recall": 0.7475963439125828,
      "eval_runtime": 2.2234,
      "eval_samples_per_second": 1486.448,
      "eval_steps_per_second": 46.775,
      "step": 2400
    },
    {
      "epoch": 1.5124016938898972,
      "grad_norm": 6.8832573890686035,
      "learning_rate": 1.5039722957832552e-05,
      "loss": 0.424,
      "step": 2500
    },
    {
      "epoch": 1.572897761645493,
      "grad_norm": 8.863253593444824,
      "learning_rate": 1.4428600529639439e-05,
      "loss": 0.4393,
      "step": 2600
    },
    {
      "epoch": 1.572897761645493,
      "eval_accuracy": 0.7633888048411498,
      "eval_f1": 0.7611637605366619,
      "eval_loss": 0.5297363996505737,
      "eval_matthews_correlation": 0.5297242185216422,
      "eval_precision": 0.7613083733342715,
      "eval_recall": 0.7684641752078538,
      "eval_runtime": 2.238,
      "eval_samples_per_second": 1476.779,
      "eval_steps_per_second": 46.47,
      "step": 2600
    },
    {
      "epoch": 1.633393829401089,
      "grad_norm": 12.025508880615234,
      "learning_rate": 1.3817478101446323e-05,
      "loss": 0.427,
      "step": 2700
    },
    {
      "epoch": 1.693889897156685,
      "grad_norm": 4.849658966064453,
      "learning_rate": 1.320635567325321e-05,
      "loss": 0.4173,
      "step": 2800
    },
    {
      "epoch": 1.693889897156685,
      "eval_accuracy": 0.7461422087745839,
      "eval_f1": 0.7460148793470036,
      "eval_loss": 0.5533755421638489,
      "eval_matthews_correlation": 0.5232562260473566,
      "eval_precision": 0.759921009485105,
      "eval_recall": 0.7633464284396492,
      "eval_runtime": 2.2324,
      "eval_samples_per_second": 1480.492,
      "eval_steps_per_second": 46.587,
      "step": 2800
    },
    {
      "epoch": 1.7543859649122808,
      "grad_norm": 9.446429252624512,
      "learning_rate": 1.2595233245060094e-05,
      "loss": 0.423,
      "step": 2900
    },
    {
      "epoch": 1.8148820326678767,
      "grad_norm": 8.400736808776855,
      "learning_rate": 1.1984110816866978e-05,
      "loss": 0.4172,
      "step": 3000
    },
    {
      "epoch": 1.8148820326678767,
      "eval_accuracy": 0.7591527987897125,
      "eval_f1": 0.7573484107804977,
      "eval_loss": 0.5262430906295776,
      "eval_matthews_correlation": 0.5243984981992413,
      "eval_precision": 0.7585894286434163,
      "eval_recall": 0.7658594614213952,
      "eval_runtime": 2.2416,
      "eval_samples_per_second": 1474.413,
      "eval_steps_per_second": 46.396,
      "step": 3000
    },
    {
      "epoch": 1.8753781004234726,
      "grad_norm": 4.36464786529541,
      "learning_rate": 1.1372988388673865e-05,
      "loss": 0.3896,
      "step": 3100
    },
    {
      "epoch": 1.9358741681790683,
      "grad_norm": 16.632600784301758,
      "learning_rate": 1.0761865960480751e-05,
      "loss": 0.4212,
      "step": 3200
    },
    {
      "epoch": 1.9358741681790683,
      "eval_accuracy": 0.7658093797276854,
      "eval_f1": 0.7619838503297149,
      "eval_loss": 0.51487797498703,
      "eval_matthews_correlation": 0.5263207580496692,
      "eval_precision": 0.7605429390320144,
      "eval_recall": 0.7658041140772769,
      "eval_runtime": 2.2342,
      "eval_samples_per_second": 1479.285,
      "eval_steps_per_second": 46.549,
      "step": 3200
    },
    {
      "epoch": 1.9963702359346642,
      "grad_norm": 11.166255950927734,
      "learning_rate": 1.0150743532287635e-05,
      "loss": 0.4027,
      "step": 3300
    },
    {
      "epoch": 2.05686630369026,
      "grad_norm": 5.520999431610107,
      "learning_rate": 9.545732328376452e-06,
      "loss": 0.2776,
      "step": 3400
    },
    {
      "epoch": 2.05686630369026,
      "eval_accuracy": 0.7531013615733737,
      "eval_f1": 0.7509524622173364,
      "eval_loss": 0.578149676322937,
      "eval_matthews_correlation": 0.5099842482175334,
      "eval_precision": 0.7515271278127398,
      "eval_recall": 0.7585048536232178,
      "eval_runtime": 2.2279,
      "eval_samples_per_second": 1483.438,
      "eval_steps_per_second": 46.68,
      "step": 3400
    },
    {
      "epoch": 2.117362371445856,
      "grad_norm": 6.182106018066406,
      "learning_rate": 8.934609900183337e-06,
      "loss": 0.3049,
      "step": 3500
    },
    {
      "epoch": 2.1778584392014517,
      "grad_norm": 1.5574599504470825,
      "learning_rate": 8.323487471990221e-06,
      "loss": 0.2569,
      "step": 3600
    },
    {
      "epoch": 2.1778584392014517,
      "eval_accuracy": 0.7600605143721634,
      "eval_f1": 0.757874988140252,
      "eval_loss": 0.6259787082672119,
      "eval_matthews_correlation": 0.5234387217059929,
      "eval_precision": 0.75818744970899,
      "eval_recall": 0.7652995872669481,
      "eval_runtime": 2.2276,
      "eval_samples_per_second": 1483.671,
      "eval_steps_per_second": 46.687,
      "step": 3600
    },
    {
      "epoch": 2.2383545069570476,
      "grad_norm": 8.22519588470459,
      "learning_rate": 7.712365043797108e-06,
      "loss": 0.3059,
      "step": 3700
    },
    {
      "epoch": 2.2988505747126435,
      "grad_norm": 11.589820861816406,
      "learning_rate": 7.101242615603993e-06,
      "loss": 0.2941,
      "step": 3800
    },
    {
      "epoch": 2.2988505747126435,
      "eval_accuracy": 0.7594553706505295,
      "eval_f1": 0.756851733485495,
      "eval_loss": 0.5779064893722534,
      "eval_matthews_correlation": 0.5196573687290963,
      "eval_precision": 0.7564657322792128,
      "eval_recall": 0.7632357337514128,
      "eval_runtime": 2.231,
      "eval_samples_per_second": 1481.386,
      "eval_steps_per_second": 46.615,
      "step": 3800
    },
    {
      "epoch": 2.3593466424682394,
      "grad_norm": 16.93423080444336,
      "learning_rate": 6.490120187410878e-06,
      "loss": 0.2946,
      "step": 3900
    },
    {
      "epoch": 2.4198427102238353,
      "grad_norm": 5.227083683013916,
      "learning_rate": 5.885108983499694e-06,
      "loss": 0.2836,
      "step": 4000
    },
    {
      "epoch": 2.4198427102238353,
      "eval_accuracy": 0.74553706505295,
      "eval_f1": 0.7452011596328594,
      "eval_loss": 0.6526216268539429,
      "eval_matthews_correlation": 0.5157601931721646,
      "eval_precision": 0.7554279449496416,
      "eval_recall": 0.7603557892945435,
      "eval_runtime": 2.226,
      "eval_samples_per_second": 1484.748,
      "eval_steps_per_second": 46.721,
      "step": 4000
    },
    {
      "epoch": 2.4803387779794313,
      "grad_norm": 12.035477638244629,
      "learning_rate": 5.2739865553065805e-06,
      "loss": 0.2814,
      "step": 4100
    },
    {
      "epoch": 2.540834845735027,
      "grad_norm": 12.942011833190918,
      "learning_rate": 4.662864127113465e-06,
      "loss": 0.2759,
      "step": 4200
    },
    {
      "epoch": 2.540834845735027,
      "eval_accuracy": 0.7615733736762481,
      "eval_f1": 0.7596322817111061,
      "eval_loss": 0.6146067380905151,
      "eval_matthews_correlation": 0.5281293826178312,
      "eval_precision": 0.7604492191792263,
      "eval_recall": 0.7677303522576069,
      "eval_runtime": 2.2232,
      "eval_samples_per_second": 1486.582,
      "eval_steps_per_second": 46.779,
      "step": 4200
    },
    {
      "epoch": 2.601330913490623,
      "grad_norm": 10.826458930969238,
      "learning_rate": 4.05174169892035e-06,
      "loss": 0.2377,
      "step": 4300
    },
    {
      "epoch": 2.661826981246219,
      "grad_norm": 11.703418731689453,
      "learning_rate": 3.4406192707272358e-06,
      "loss": 0.2683,
      "step": 4400
    },
    {
      "epoch": 2.661826981246219,
      "eval_accuracy": 0.7540090771558245,
      "eval_f1": 0.7531230070762832,
      "eval_loss": 0.6585250496864319,
      "eval_matthews_correlation": 0.5233363648935244,
      "eval_precision": 0.7583291866295592,
      "eval_recall": 0.7650503359621439,
      "eval_runtime": 2.2268,
      "eval_samples_per_second": 1484.164,
      "eval_steps_per_second": 46.703,
      "step": 4400
    },
    {
      "epoch": 2.722323049001815,
      "grad_norm": 16.884441375732422,
      "learning_rate": 2.835608066816052e-06,
      "loss": 0.2776,
      "step": 4500
    },
    {
      "epoch": 2.782819116757411,
      "grad_norm": 9.672805786132812,
      "learning_rate": 2.224485638622938e-06,
      "loss": 0.2959,
      "step": 4600
    },
    {
      "epoch": 2.782819116757411,
      "eval_accuracy": 0.7573373676248109,
      "eval_f1": 0.7559521091197294,
      "eval_loss": 0.5992904901504517,
      "eval_matthews_correlation": 0.5244178182562521,
      "eval_precision": 0.7586211190862353,
      "eval_recall": 0.7658464717385919,
      "eval_runtime": 2.2292,
      "eval_samples_per_second": 1482.618,
      "eval_steps_per_second": 46.654,
      "step": 4600
    },
    {
      "epoch": 2.8433151845130067,
      "grad_norm": 9.329161643981934,
      "learning_rate": 1.6133632104298227e-06,
      "loss": 0.2577,
      "step": 4700
    },
    {
      "epoch": 2.9038112522686026,
      "grad_norm": 16.95904541015625,
      "learning_rate": 1.002240782236708e-06,
      "loss": 0.2999,
      "step": 4800
    },
    {
      "epoch": 2.9038112522686026,
      "eval_accuracy": 0.7506807866868381,
      "eval_f1": 0.7499140459244544,
      "eval_loss": 0.6203533411026001,
      "eval_matthews_correlation": 0.5183414430438686,
      "eval_precision": 0.7559805712698976,
      "eval_recall": 0.7624006289265552,
      "eval_runtime": 2.2232,
      "eval_samples_per_second": 1486.587,
      "eval_steps_per_second": 46.779,
      "step": 4800
    },
    {
      "epoch": 2.9643073200241985,
      "grad_norm": 14.962732315063477,
      "learning_rate": 3.9111835404359343e-07,
      "loss": 0.2753,
      "step": 4900
    },
    {
      "epoch": 3.0,
      "step": 4959,
      "total_flos": 6288829392617472.0,
      "train_loss": 0.42196512751147547,
      "train_runtime": 350.8384,
      "train_samples_per_second": 226.07,
      "train_steps_per_second": 14.135
    },
    {
      "epoch": 1.4692918013517484,
      "grad_norm": 4.715386390686035,
      "learning_rate": 2.9927710843373496e-05,
      "loss": 0.8967,
      "step": 5000
    },
    {
      "epoch": 1.4986776373787833,
      "grad_norm": 4.852955341339111,
      "learning_rate": 2.9751395827211286e-05,
      "loss": 0.6835,
      "step": 5100
    },
    {
      "epoch": 1.5280634734058185,
      "grad_norm": 5.065720081329346,
      "learning_rate": 2.9575080811049076e-05,
      "loss": 0.605,
      "step": 5200
    },
    {
      "epoch": 1.5574493094328532,
      "grad_norm": 3.976952075958252,
      "learning_rate": 2.9398765794886863e-05,
      "loss": 0.6029,
      "step": 5300
    },
    {
      "epoch": 1.5868351454598884,
      "grad_norm": 5.008033752441406,
      "learning_rate": 2.9222450778724653e-05,
      "loss": 0.5622,
      "step": 5400
    },
    {
      "epoch": 1.6162209814869233,
      "grad_norm": 4.15352201461792,
      "learning_rate": 2.9046135762562443e-05,
      "loss": 0.5936,
      "step": 5500
    },
    {
      "epoch": 1.6456068175139582,
      "grad_norm": 4.935469627380371,
      "learning_rate": 2.8869820746400236e-05,
      "loss": 0.5316,
      "step": 5600
    },
    {
      "epoch": 1.6749926535409934,
      "grad_norm": 6.576689720153809,
      "learning_rate": 2.8693505730238026e-05,
      "loss": 0.5413,
      "step": 5700
    },
    {
      "epoch": 1.704378489568028,
      "grad_norm": 6.808842658996582,
      "learning_rate": 2.8517190714075817e-05,
      "loss": 0.5423,
      "step": 5800
    },
    {
      "epoch": 1.7337643255950632,
      "grad_norm": 8.798518180847168,
      "learning_rate": 2.8340875697913607e-05,
      "loss": 0.5032,
      "step": 5900
    },
    {
      "epoch": 1.7631501616220981,
      "grad_norm": 7.672634601593018,
      "learning_rate": 2.8164560681751397e-05,
      "loss": 0.559,
      "step": 6000
    },
    {
      "epoch": 1.792535997649133,
      "grad_norm": 6.169346809387207,
      "learning_rate": 2.7988245665589187e-05,
      "loss": 0.5198,
      "step": 6100
    },
    {
      "epoch": 1.8219218336761682,
      "grad_norm": 8.195368766784668,
      "learning_rate": 2.7811930649426977e-05,
      "loss": 0.5044,
      "step": 6200
    },
    {
      "epoch": 1.851307669703203,
      "grad_norm": 5.054221153259277,
      "learning_rate": 2.7635615633264767e-05,
      "loss": 0.4911,
      "step": 6300
    },
    {
      "epoch": 1.880693505730238,
      "grad_norm": 5.679406642913818,
      "learning_rate": 2.7459300617102557e-05,
      "loss": 0.4738,
      "step": 6400
    },
    {
      "epoch": 1.910079341757273,
      "grad_norm": 11.084613800048828,
      "learning_rate": 2.728298560094035e-05,
      "loss": 0.4645,
      "step": 6500
    },
    {
      "epoch": 1.939465177784308,
      "grad_norm": 8.284838676452637,
      "learning_rate": 2.7106670584778137e-05,
      "loss": 0.5148,
      "step": 6600
    },
    {
      "epoch": 1.968851013811343,
      "grad_norm": 13.013833045959473,
      "learning_rate": 2.6930355568615927e-05,
      "loss": 0.4561,
      "step": 6700
    },
    {
      "epoch": 1.9982368498383778,
      "grad_norm": 8.056649208068848,
      "learning_rate": 2.6754040552453717e-05,
      "loss": 0.4547,
      "step": 6800
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.4384711457223671,
      "eval_f1": 0.14739663712739048,
      "eval_loss": 0.347807377576828,
      "eval_matthews_correlation": 0.31326571068149817,
      "eval_precision": 0.10957166717622242,
      "eval_recall": 0.22514997694805447,
      "eval_runtime": 254.1633,
      "eval_samples_per_second": 214.217,
      "eval_steps_per_second": 13.389,
      "step": 6806
    },
    {
      "epoch": 2.027622685865413,
      "grad_norm": 7.2590765953063965,
      "learning_rate": 2.6577725536291507e-05,
      "loss": 0.375,
      "step": 6900
    },
    {
      "epoch": 2.0570085218924477,
      "grad_norm": 1.1083842515945435,
      "learning_rate": 2.6401410520129297e-05,
      "loss": 0.3805,
      "step": 7000
    },
    {
      "epoch": 2.086394357919483,
      "grad_norm": 21.612693786621094,
      "learning_rate": 2.6225095503967087e-05,
      "loss": 0.3615,
      "step": 7100
    },
    {
      "epoch": 2.115780193946518,
      "grad_norm": 18.349336624145508,
      "learning_rate": 2.6048780487804877e-05,
      "loss": 0.364,
      "step": 7200
    },
    {
      "epoch": 2.1451660299735527,
      "grad_norm": 19.37392807006836,
      "learning_rate": 2.5872465471642667e-05,
      "loss": 0.3814,
      "step": 7300
    },
    {
      "epoch": 2.174551866000588,
      "grad_norm": 9.174528121948242,
      "learning_rate": 2.569615045548046e-05,
      "loss": 0.3522,
      "step": 7400
    },
    {
      "epoch": 2.2039377020276225,
      "grad_norm": 0.7870425581932068,
      "learning_rate": 2.551983543931825e-05,
      "loss": 0.3556,
      "step": 7500
    },
    {
      "epoch": 2.2333235380546577,
      "grad_norm": 14.904351234436035,
      "learning_rate": 2.534352042315604e-05,
      "loss": 0.3757,
      "step": 7600
    },
    {
      "epoch": 2.262709374081693,
      "grad_norm": 6.411470890045166,
      "learning_rate": 2.516720540699383e-05,
      "loss": 0.33,
      "step": 7700
    },
    {
      "epoch": 2.2920952101087275,
      "grad_norm": 27.202165603637695,
      "learning_rate": 2.499089039083162e-05,
      "loss": 0.3973,
      "step": 7800
    },
    {
      "epoch": 2.3214810461357627,
      "grad_norm": 16.183021545410156,
      "learning_rate": 2.481457537466941e-05,
      "loss": 0.3853,
      "step": 7900
    },
    {
      "epoch": 2.3508668821627974,
      "grad_norm": 13.12732982635498,
      "learning_rate": 2.4638260358507198e-05,
      "loss": 0.3584,
      "step": 8000
    },
    {
      "epoch": 2.3802527181898325,
      "grad_norm": 11.771763801574707,
      "learning_rate": 2.4461945342344988e-05,
      "loss": 0.3471,
      "step": 8100
    },
    {
      "epoch": 2.4096385542168672,
      "grad_norm": 2.5934746265411377,
      "learning_rate": 2.4285630326182778e-05,
      "loss": 0.3703,
      "step": 8200
    },
    {
      "epoch": 2.4390243902439024,
      "grad_norm": 0.8172279000282288,
      "learning_rate": 2.410931531002057e-05,
      "loss": 0.3228,
      "step": 8300
    },
    {
      "epoch": 2.4684102262709375,
      "grad_norm": 15.464940071105957,
      "learning_rate": 2.393300029385836e-05,
      "loss": 0.3655,
      "step": 8400
    },
    {
      "epoch": 2.4977960622979722,
      "grad_norm": 11.072470664978027,
      "learning_rate": 2.375668527769615e-05,
      "loss": 0.3081,
      "step": 8500
    },
    {
      "epoch": 2.5271818983250074,
      "grad_norm": 27.76506233215332,
      "learning_rate": 2.358037026153394e-05,
      "loss": 0.3644,
      "step": 8600
    },
    {
      "epoch": 2.5565677343520425,
      "grad_norm": 8.75820255279541,
      "learning_rate": 2.340405524537173e-05,
      "loss": 0.3063,
      "step": 8700
    },
    {
      "epoch": 2.5859535703790772,
      "grad_norm": 13.042980194091797,
      "learning_rate": 2.3227740229209522e-05,
      "loss": 0.3214,
      "step": 8800
    },
    {
      "epoch": 2.6153394064061124,
      "grad_norm": 11.981765747070312,
      "learning_rate": 2.3051425213047312e-05,
      "loss": 0.3578,
      "step": 8900
    },
    {
      "epoch": 2.644725242433147,
      "grad_norm": 36.69633483886719,
      "learning_rate": 2.2875110196885102e-05,
      "loss": 0.2859,
      "step": 9000
    },
    {
      "epoch": 2.6741110784601823,
      "grad_norm": 2.4854888916015625,
      "learning_rate": 2.2698795180722892e-05,
      "loss": 0.2969,
      "step": 9100
    },
    {
      "epoch": 2.703496914487217,
      "grad_norm": 25.435409545898438,
      "learning_rate": 2.2522480164560685e-05,
      "loss": 0.2838,
      "step": 9200
    },
    {
      "epoch": 2.732882750514252,
      "grad_norm": 23.373987197875977,
      "learning_rate": 2.2346165148398475e-05,
      "loss": 0.2608,
      "step": 9300
    },
    {
      "epoch": 2.7622685865412873,
      "grad_norm": 23.533203125,
      "learning_rate": 2.2169850132236262e-05,
      "loss": 0.3129,
      "step": 9400
    },
    {
      "epoch": 2.791654422568322,
      "grad_norm": 10.785135269165039,
      "learning_rate": 2.1993535116074052e-05,
      "loss": 0.2895,
      "step": 9500
    },
    {
      "epoch": 2.821040258595357,
      "grad_norm": 23.09943199157715,
      "learning_rate": 2.1817220099911842e-05,
      "loss": 0.2789,
      "step": 9600
    },
    {
      "epoch": 2.8504260946223923,
      "grad_norm": 15.427505493164062,
      "learning_rate": 2.1640905083749632e-05,
      "loss": 0.2595,
      "step": 9700
    },
    {
      "epoch": 2.879811930649427,
      "grad_norm": 15.609407424926758,
      "learning_rate": 2.1464590067587422e-05,
      "loss": 0.336,
      "step": 9800
    },
    {
      "epoch": 2.9091977666764617,
      "grad_norm": 13.941285133361816,
      "learning_rate": 2.1288275051425212e-05,
      "loss": 0.3308,
      "step": 9900
    },
    {
      "epoch": 2.938583602703497,
      "grad_norm": 29.51299285888672,
      "learning_rate": 2.1111960035263002e-05,
      "loss": 0.3039,
      "step": 10000
    },
    {
      "epoch": 2.967969438730532,
      "grad_norm": 5.652004718780518,
      "learning_rate": 2.0935645019100793e-05,
      "loss": 0.2695,
      "step": 10100
    },
    {
      "epoch": 2.9973552747575667,
      "grad_norm": 1.212883710861206,
      "learning_rate": 2.0759330002938586e-05,
      "loss": 0.2639,
      "step": 10200
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.47349667560518677,
      "eval_f1": 0.15945490179401128,
      "eval_loss": 0.16534407436847687,
      "eval_matthews_correlation": 0.3707802487643629,
      "eval_precision": 0.11861840292454075,
      "eval_recall": 0.24329929233208442,
      "eval_runtime": 87.2508,
      "eval_samples_per_second": 624.017,
      "eval_steps_per_second": 39.002,
      "step": 10209
    },
    {
      "epoch": 3.026741110784602,
      "grad_norm": 7.2365241050720215,
      "learning_rate": 2.0583014986776376e-05,
      "loss": 0.2123,
      "step": 10300
    },
    {
      "epoch": 3.056126946811637,
      "grad_norm": 0.12056821584701538,
      "learning_rate": 2.0406699970614166e-05,
      "loss": 0.2178,
      "step": 10400
    },
    {
      "epoch": 3.0855127828386717,
      "grad_norm": 8.521968841552734,
      "learning_rate": 2.0230384954451956e-05,
      "loss": 0.1728,
      "step": 10500
    },
    {
      "epoch": 3.114898618865707,
      "grad_norm": 16.07609748840332,
      "learning_rate": 2.0054069938289746e-05,
      "loss": 0.1723,
      "step": 10600
    },
    {
      "epoch": 3.1442844548927416,
      "grad_norm": 0.050700195133686066,
      "learning_rate": 1.9877754922127533e-05,
      "loss": 0.1468,
      "step": 10700
    },
    {
      "epoch": 3.1736702909197767,
      "grad_norm": 0.652362048625946,
      "learning_rate": 1.9701439905965323e-05,
      "loss": 0.1718,
      "step": 10800
    },
    {
      "epoch": 3.2030561269468114,
      "grad_norm": 2.9937357902526855,
      "learning_rate": 1.9525124889803113e-05,
      "loss": 0.2113,
      "step": 10900
    },
    {
      "epoch": 3.2324419629738466,
      "grad_norm": 1.6937370300292969,
      "learning_rate": 1.9348809873640903e-05,
      "loss": 0.1973,
      "step": 11000
    },
    {
      "epoch": 3.2618277990008817,
      "grad_norm": 26.663585662841797,
      "learning_rate": 1.9172494857478697e-05,
      "loss": 0.1577,
      "step": 11100
    },
    {
      "epoch": 3.2912136350279164,
      "grad_norm": 12.012463569641113,
      "learning_rate": 1.8996179841316487e-05,
      "loss": 0.2205,
      "step": 11200
    },
    {
      "epoch": 3.3205994710549516,
      "grad_norm": 19.031478881835938,
      "learning_rate": 1.8819864825154277e-05,
      "loss": 0.1799,
      "step": 11300
    },
    {
      "epoch": 3.3499853070819867,
      "grad_norm": 0.18157702684402466,
      "learning_rate": 1.8643549808992067e-05,
      "loss": 0.1942,
      "step": 11400
    },
    {
      "epoch": 3.3793711431090214,
      "grad_norm": 15.373065948486328,
      "learning_rate": 1.8467234792829857e-05,
      "loss": 0.1925,
      "step": 11500
    },
    {
      "epoch": 3.4087569791360566,
      "grad_norm": 0.10506099462509155,
      "learning_rate": 1.8290919776667647e-05,
      "loss": 0.1533,
      "step": 11600
    },
    {
      "epoch": 3.4381428151630913,
      "grad_norm": 0.08678869158029556,
      "learning_rate": 1.8114604760505437e-05,
      "loss": 0.1373,
      "step": 11700
    },
    {
      "epoch": 3.4675286511901264,
      "grad_norm": 14.959315299987793,
      "learning_rate": 1.7938289744343227e-05,
      "loss": 0.2598,
      "step": 11800
    },
    {
      "epoch": 3.496914487217161,
      "grad_norm": 4.783830165863037,
      "learning_rate": 1.7761974728181017e-05,
      "loss": 0.1197,
      "step": 11900
    },
    {
      "epoch": 3.5263003232441963,
      "grad_norm": 10.1480712890625,
      "learning_rate": 1.758565971201881e-05,
      "loss": 0.2106,
      "step": 12000
    },
    {
      "epoch": 3.5556861592712314,
      "grad_norm": 0.17148388922214508,
      "learning_rate": 1.7409344695856597e-05,
      "loss": 0.2071,
      "step": 12100
    },
    {
      "epoch": 3.585071995298266,
      "grad_norm": 0.28618621826171875,
      "learning_rate": 1.7233029679694387e-05,
      "loss": 0.1823,
      "step": 12200
    },
    {
      "epoch": 3.6144578313253013,
      "grad_norm": 0.1436346024274826,
      "learning_rate": 1.7056714663532177e-05,
      "loss": 0.1653,
      "step": 12300
    },
    {
      "epoch": 3.6438436673523364,
      "grad_norm": 43.6773681640625,
      "learning_rate": 1.6880399647369967e-05,
      "loss": 0.1771,
      "step": 12400
    },
    {
      "epoch": 3.673229503379371,
      "grad_norm": 0.09178580343723297,
      "learning_rate": 1.6704084631207757e-05,
      "loss": 0.1877,
      "step": 12500
    },
    {
      "epoch": 3.702615339406406,
      "grad_norm": 30.943391799926758,
      "learning_rate": 1.6527769615045547e-05,
      "loss": 0.1465,
      "step": 12600
    },
    {
      "epoch": 3.732001175433441,
      "grad_norm": 0.08180539309978485,
      "learning_rate": 1.6351454598883338e-05,
      "loss": 0.1653,
      "step": 12700
    },
    {
      "epoch": 3.761387011460476,
      "grad_norm": 87.55380249023438,
      "learning_rate": 1.6175139582721128e-05,
      "loss": 0.1373,
      "step": 12800
    },
    {
      "epoch": 3.790772847487511,
      "grad_norm": 1.027492642402649,
      "learning_rate": 1.599882456655892e-05,
      "loss": 0.1592,
      "step": 12900
    },
    {
      "epoch": 3.820158683514546,
      "grad_norm": 0.4523416757583618,
      "learning_rate": 1.582250955039671e-05,
      "loss": 0.1604,
      "step": 13000
    },
    {
      "epoch": 3.849544519541581,
      "grad_norm": 4.478135585784912,
      "learning_rate": 1.56461945342345e-05,
      "loss": 0.1445,
      "step": 13100
    },
    {
      "epoch": 3.878930355568616,
      "grad_norm": 0.706460177898407,
      "learning_rate": 1.546987951807229e-05,
      "loss": 0.1322,
      "step": 13200
    },
    {
      "epoch": 3.908316191595651,
      "grad_norm": 30.102094650268555,
      "learning_rate": 1.529356450191008e-05,
      "loss": 0.1354,
      "step": 13300
    },
    {
      "epoch": 3.9377020276226857,
      "grad_norm": 0.09681898355484009,
      "learning_rate": 1.5117249485747868e-05,
      "loss": 0.153,
      "step": 13400
    },
    {
      "epoch": 3.967087863649721,
      "grad_norm": 0.6794814467430115,
      "learning_rate": 1.494093446958566e-05,
      "loss": 0.1685,
      "step": 13500
    },
    {
      "epoch": 3.9964736996767556,
      "grad_norm": 4.482362270355225,
      "learning_rate": 1.4764619453423451e-05,
      "loss": 0.1198,
      "step": 13600
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.4818535796936414,
      "eval_f1": 0.16211297705056005,
      "eval_loss": 0.09551829844713211,
      "eval_matthews_correlation": 0.3844211286611518,
      "eval_precision": 0.12035988399068598,
      "eval_recall": 0.24824716145027426,
      "eval_runtime": 87.124,
      "eval_samples_per_second": 624.925,
      "eval_steps_per_second": 39.059,
      "step": 13612
    },
    {
      "epoch": 4.025859535703791,
      "grad_norm": 29.367483139038086,
      "learning_rate": 1.4588304437261242e-05,
      "loss": 0.0824,
      "step": 13700
    },
    {
      "epoch": 4.055245371730826,
      "grad_norm": 0.06638260930776596,
      "learning_rate": 1.441198942109903e-05,
      "loss": 0.1552,
      "step": 13800
    },
    {
      "epoch": 4.084631207757861,
      "grad_norm": 7.822793960571289,
      "learning_rate": 1.423567440493682e-05,
      "loss": 0.1096,
      "step": 13900
    },
    {
      "epoch": 4.114017043784895,
      "grad_norm": 2.80663800239563,
      "learning_rate": 1.405935938877461e-05,
      "loss": 0.0864,
      "step": 14000
    },
    {
      "epoch": 4.143402879811931,
      "grad_norm": 0.05511874705553055,
      "learning_rate": 1.3883044372612402e-05,
      "loss": 0.1157,
      "step": 14100
    },
    {
      "epoch": 4.172788715838966,
      "grad_norm": 0.24844741821289062,
      "learning_rate": 1.3706729356450192e-05,
      "loss": 0.0825,
      "step": 14200
    },
    {
      "epoch": 4.202174551866,
      "grad_norm": 0.06037251278758049,
      "learning_rate": 1.3530414340287982e-05,
      "loss": 0.1166,
      "step": 14300
    },
    {
      "epoch": 4.231560387893036,
      "grad_norm": 0.2947179079055786,
      "learning_rate": 1.3354099324125772e-05,
      "loss": 0.0863,
      "step": 14400
    },
    {
      "epoch": 4.260946223920071,
      "grad_norm": 0.015525602735579014,
      "learning_rate": 1.3177784307963562e-05,
      "loss": 0.094,
      "step": 14500
    },
    {
      "epoch": 4.290332059947105,
      "grad_norm": 0.12671545147895813,
      "learning_rate": 1.3001469291801352e-05,
      "loss": 0.1127,
      "step": 14600
    },
    {
      "epoch": 4.31971789597414,
      "grad_norm": 0.07765404134988785,
      "learning_rate": 1.2825154275639142e-05,
      "loss": 0.0732,
      "step": 14700
    },
    {
      "epoch": 4.349103732001176,
      "grad_norm": 2.8356521129608154,
      "learning_rate": 1.2648839259476932e-05,
      "loss": 0.088,
      "step": 14800
    },
    {
      "epoch": 4.37848956802821,
      "grad_norm": 0.4242537021636963,
      "learning_rate": 1.2472524243314722e-05,
      "loss": 0.132,
      "step": 14900
    },
    {
      "epoch": 4.407875404055245,
      "grad_norm": 0.8177635073661804,
      "learning_rate": 1.2296209227152514e-05,
      "loss": 0.1215,
      "step": 15000
    },
    {
      "epoch": 4.437261240082281,
      "grad_norm": 0.0478002093732357,
      "learning_rate": 1.2119894210990302e-05,
      "loss": 0.1286,
      "step": 15100
    },
    {
      "epoch": 4.466647076109315,
      "grad_norm": 0.38173148036003113,
      "learning_rate": 1.1943579194828092e-05,
      "loss": 0.085,
      "step": 15200
    },
    {
      "epoch": 4.49603291213635,
      "grad_norm": 32.51811599731445,
      "learning_rate": 1.1767264178665883e-05,
      "loss": 0.0861,
      "step": 15300
    },
    {
      "epoch": 4.525418748163386,
      "grad_norm": 88.59967803955078,
      "learning_rate": 1.1590949162503674e-05,
      "loss": 0.1239,
      "step": 15400
    },
    {
      "epoch": 4.55480458419042,
      "grad_norm": 0.3916022777557373,
      "learning_rate": 1.1414634146341464e-05,
      "loss": 0.0814,
      "step": 15500
    },
    {
      "epoch": 4.584190420217455,
      "grad_norm": 3.229280948638916,
      "learning_rate": 1.1238319130179254e-05,
      "loss": 0.1345,
      "step": 15600
    },
    {
      "epoch": 4.613576256244491,
      "grad_norm": 0.081824891269207,
      "learning_rate": 1.1062004114017044e-05,
      "loss": 0.0658,
      "step": 15700
    },
    {
      "epoch": 4.642962092271525,
      "grad_norm": 0.020079363137483597,
      "learning_rate": 1.0885689097854833e-05,
      "loss": 0.114,
      "step": 15800
    },
    {
      "epoch": 4.67234792829856,
      "grad_norm": 0.015220990404486656,
      "learning_rate": 1.0709374081692625e-05,
      "loss": 0.0972,
      "step": 15900
    },
    {
      "epoch": 4.701733764325595,
      "grad_norm": 0.0637706071138382,
      "learning_rate": 1.0533059065530415e-05,
      "loss": 0.1061,
      "step": 16000
    },
    {
      "epoch": 4.73111960035263,
      "grad_norm": 10.670486450195312,
      "learning_rate": 1.0356744049368205e-05,
      "loss": 0.086,
      "step": 16100
    },
    {
      "epoch": 4.760505436379665,
      "grad_norm": 0.01777520775794983,
      "learning_rate": 1.0180429033205995e-05,
      "loss": 0.0911,
      "step": 16200
    },
    {
      "epoch": 4.7898912724067,
      "grad_norm": 0.1299927830696106,
      "learning_rate": 1.0004114017043785e-05,
      "loss": 0.1364,
      "step": 16300
    },
    {
      "epoch": 4.8192771084337345,
      "grad_norm": 0.027350246906280518,
      "learning_rate": 9.827799000881577e-06,
      "loss": 0.0991,
      "step": 16400
    },
    {
      "epoch": 4.84866294446077,
      "grad_norm": 16.455289840698242,
      "learning_rate": 9.651483984719365e-06,
      "loss": 0.0999,
      "step": 16500
    },
    {
      "epoch": 4.878048780487805,
      "grad_norm": 0.9436561465263367,
      "learning_rate": 9.475168968557155e-06,
      "loss": 0.0903,
      "step": 16600
    },
    {
      "epoch": 4.9074346165148395,
      "grad_norm": 19.119873046875,
      "learning_rate": 9.298853952394945e-06,
      "loss": 0.1183,
      "step": 16700
    },
    {
      "epoch": 4.936820452541875,
      "grad_norm": 16.07992935180664,
      "learning_rate": 9.122538936232737e-06,
      "loss": 0.0669,
      "step": 16800
    },
    {
      "epoch": 4.96620628856891,
      "grad_norm": 3.4054505825042725,
      "learning_rate": 8.946223920070527e-06,
      "loss": 0.1099,
      "step": 16900
    },
    {
      "epoch": 4.9955921245959445,
      "grad_norm": 3.0630905628204346,
      "learning_rate": 8.769908903908317e-06,
      "loss": 0.112,
      "step": 17000
    }
  ],
  "logging_steps": 100,
  "max_steps": 17015,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.314441649191987e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
