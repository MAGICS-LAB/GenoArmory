{
  "best_metric": 0.09125589579343796,
  "best_model_checkpoint": "output_zhihan_softmax1_Full_double/zhihan_softmax1_dnabert2_Full_double_prom_300_notata/checkpoint-2800",
  "epoch": 5.0,
  "eval_steps": 400,
  "global_step": 26710,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.037678975131876416,
      "grad_norm": 14.846397399902344,
      "learning_rate": 2.9863713798977853e-05,
      "loss": 0.4542,
      "step": 100
    },
    {
      "epoch": 0.07535795026375283,
      "grad_norm": 1.031121015548706,
      "learning_rate": 2.958262350936968e-05,
      "loss": 0.2184,
      "step": 200
    },
    {
      "epoch": 0.11303692539562923,
      "grad_norm": 5.224958896636963,
      "learning_rate": 2.929869392390687e-05,
      "loss": 0.2494,
      "step": 300
    },
    {
      "epoch": 0.15071590052750566,
      "grad_norm": 0.4009731709957123,
      "learning_rate": 2.9014764338444066e-05,
      "loss": 0.154,
      "step": 400
    },
    {
      "epoch": 0.15071590052750566,
      "eval_accuracy": 0.9410212926323723,
      "eval_f1": 0.9407753370780809,
      "eval_loss": 0.1417805552482605,
      "eval_matthews_correlation": 0.887114527649659,
      "eval_precision": 0.9466819510722324,
      "eval_recall": 0.9404544347930331,
      "eval_runtime": 3.4745,
      "eval_samples_per_second": 1527.426,
      "eval_steps_per_second": 47.777,
      "step": 400
    },
    {
      "epoch": 0.18839487565938207,
      "grad_norm": 13.726097106933594,
      "learning_rate": 2.873367404883589e-05,
      "loss": 0.16,
      "step": 500
    },
    {
      "epoch": 0.22607385079125847,
      "grad_norm": 46.83217239379883,
      "learning_rate": 2.8449744463373084e-05,
      "loss": 0.149,
      "step": 600
    },
    {
      "epoch": 0.26375282592313487,
      "grad_norm": 3.791060209274292,
      "learning_rate": 2.816581487791028e-05,
      "loss": 0.1499,
      "step": 700
    },
    {
      "epoch": 0.30143180105501133,
      "grad_norm": 9.020281791687012,
      "learning_rate": 2.7884724588302102e-05,
      "loss": 0.1468,
      "step": 800
    },
    {
      "epoch": 0.30143180105501133,
      "eval_accuracy": 0.9657056717542868,
      "eval_f1": 0.9657050276028877,
      "eval_loss": 0.1196342185139656,
      "eval_matthews_correlation": 0.9318273811415471,
      "eval_precision": 0.9659730636248116,
      "eval_recall": 0.9658543250818927,
      "eval_runtime": 2.7081,
      "eval_samples_per_second": 1959.692,
      "eval_steps_per_second": 61.298,
      "step": 800
    },
    {
      "epoch": 0.33911077618688773,
      "grad_norm": 3.6168434619903564,
      "learning_rate": 2.7600795002839297e-05,
      "loss": 0.1463,
      "step": 900
    },
    {
      "epoch": 0.37678975131876413,
      "grad_norm": 0.7394442558288574,
      "learning_rate": 2.731686541737649e-05,
      "loss": 0.1789,
      "step": 1000
    },
    {
      "epoch": 0.41446872645064053,
      "grad_norm": 0.3800005614757538,
      "learning_rate": 2.7032935831913686e-05,
      "loss": 0.1409,
      "step": 1100
    },
    {
      "epoch": 0.45214770158251694,
      "grad_norm": 1.7782834768295288,
      "learning_rate": 2.674900624645088e-05,
      "loss": 0.1652,
      "step": 1200
    },
    {
      "epoch": 0.45214770158251694,
      "eval_accuracy": 0.9692858488788393,
      "eval_f1": 0.9692696087460587,
      "eval_loss": 0.10742225497961044,
      "eval_matthews_correlation": 0.9388485654562003,
      "eval_precision": 0.9696970278714905,
      "eval_recall": 0.9691516959632153,
      "eval_runtime": 2.6928,
      "eval_samples_per_second": 1970.79,
      "eval_steps_per_second": 61.645,
      "step": 1200
    },
    {
      "epoch": 0.4898266767143934,
      "grad_norm": 2.482083559036255,
      "learning_rate": 2.6467915956842704e-05,
      "loss": 0.1092,
      "step": 1300
    },
    {
      "epoch": 0.5275056518462697,
      "grad_norm": 0.30138957500457764,
      "learning_rate": 2.61839863713799e-05,
      "loss": 0.1284,
      "step": 1400
    },
    {
      "epoch": 0.5651846269781462,
      "grad_norm": 0.5069409608840942,
      "learning_rate": 2.5900056785917093e-05,
      "loss": 0.1247,
      "step": 1500
    },
    {
      "epoch": 0.6028636021100227,
      "grad_norm": 1.44145929813385,
      "learning_rate": 2.5616127200454288e-05,
      "loss": 0.1642,
      "step": 1600
    },
    {
      "epoch": 0.6028636021100227,
      "eval_accuracy": 0.9638213680045223,
      "eval_f1": 0.963800637484848,
      "eval_loss": 0.12402606010437012,
      "eval_matthews_correlation": 0.9279565399261529,
      "eval_precision": 0.9642798729427653,
      "eval_recall": 0.9636768629090837,
      "eval_runtime": 2.7655,
      "eval_samples_per_second": 1919.006,
      "eval_steps_per_second": 60.025,
      "step": 1600
    },
    {
      "epoch": 0.640542577241899,
      "grad_norm": 112.36060333251953,
      "learning_rate": 2.5332197614991483e-05,
      "loss": 0.1472,
      "step": 1700
    },
    {
      "epoch": 0.6782215523737755,
      "grad_norm": 4.298115253448486,
      "learning_rate": 2.5048268029528678e-05,
      "loss": 0.1127,
      "step": 1800
    },
    {
      "epoch": 0.7159005275056518,
      "grad_norm": 15.364116668701172,
      "learning_rate": 2.4764338444065872e-05,
      "loss": 0.1128,
      "step": 1900
    },
    {
      "epoch": 0.7535795026375283,
      "grad_norm": 0.22564880549907684,
      "learning_rate": 2.4480408858603067e-05,
      "loss": 0.1303,
      "step": 2000
    },
    {
      "epoch": 0.7535795026375283,
      "eval_accuracy": 0.9672131147540983,
      "eval_f1": 0.9672002751798515,
      "eval_loss": 0.11543843150138855,
      "eval_matthews_correlation": 0.934572404961525,
      "eval_precision": 0.9674605290988445,
      "eval_recall": 0.9671119408730245,
      "eval_runtime": 2.7679,
      "eval_samples_per_second": 1917.367,
      "eval_steps_per_second": 59.974,
      "step": 2000
    },
    {
      "epoch": 0.7912584777694047,
      "grad_norm": 15.033862113952637,
      "learning_rate": 2.4196479273140262e-05,
      "loss": 0.111,
      "step": 2100
    },
    {
      "epoch": 0.8289374529012811,
      "grad_norm": 2.045137882232666,
      "learning_rate": 2.3912549687677457e-05,
      "loss": 0.1126,
      "step": 2200
    },
    {
      "epoch": 0.8666164280331575,
      "grad_norm": 0.13232621550559998,
      "learning_rate": 2.362862010221465e-05,
      "loss": 0.1084,
      "step": 2300
    },
    {
      "epoch": 0.9042954031650339,
      "grad_norm": 0.08042582869529724,
      "learning_rate": 2.3344690516751846e-05,
      "loss": 0.1158,
      "step": 2400
    },
    {
      "epoch": 0.9042954031650339,
      "eval_accuracy": 0.9679668362540041,
      "eval_f1": 0.9679335438610858,
      "eval_loss": 0.09866312891244888,
      "eval_matthews_correlation": 0.9367943211174274,
      "eval_precision": 0.969058410619232,
      "eval_recall": 0.9677368426883717,
      "eval_runtime": 2.7144,
      "eval_samples_per_second": 1955.133,
      "eval_steps_per_second": 61.155,
      "step": 2400
    },
    {
      "epoch": 0.9419743782969103,
      "grad_norm": 0.1044788584113121,
      "learning_rate": 2.306076093128904e-05,
      "loss": 0.1293,
      "step": 2500
    },
    {
      "epoch": 0.9796533534287868,
      "grad_norm": 0.08308427035808563,
      "learning_rate": 2.2776831345826236e-05,
      "loss": 0.0912,
      "step": 2600
    },
    {
      "epoch": 1.0173323285606632,
      "grad_norm": 0.82650226354599,
      "learning_rate": 2.249290176036343e-05,
      "loss": 0.0885,
      "step": 2700
    },
    {
      "epoch": 1.0550113036925395,
      "grad_norm": 88.40900421142578,
      "learning_rate": 2.2211811470755254e-05,
      "loss": 0.0791,
      "step": 2800
    },
    {
      "epoch": 1.0550113036925395,
      "eval_accuracy": 0.9730544563783682,
      "eval_f1": 0.9730486343836682,
      "eval_loss": 0.09125589579343796,
      "eval_matthews_correlation": 0.946133837950296,
      "eval_precision": 0.973127203590759,
      "eval_recall": 0.9730066420408431,
      "eval_runtime": 2.704,
      "eval_samples_per_second": 1962.637,
      "eval_steps_per_second": 61.39,
      "step": 2800
    },
    {
      "epoch": 1.092690278824416,
      "grad_norm": 2.558290719985962,
      "learning_rate": 2.1927881885292448e-05,
      "loss": 0.1123,
      "step": 2900
    },
    {
      "epoch": 1.1303692539562924,
      "grad_norm": 0.08134586364030838,
      "learning_rate": 2.164395229982964e-05,
      "loss": 0.1108,
      "step": 3000
    },
    {
      "epoch": 1.1680482290881689,
      "grad_norm": 1.5504993200302124,
      "learning_rate": 2.1360022714366838e-05,
      "loss": 0.0758,
      "step": 3100
    },
    {
      "epoch": 1.2057272042200453,
      "grad_norm": 2.3987061977386475,
      "learning_rate": 2.1076093128904033e-05,
      "loss": 0.0805,
      "step": 3200
    },
    {
      "epoch": 1.2057272042200453,
      "eval_accuracy": 0.9704164311286979,
      "eval_f1": 0.9704162798711338,
      "eval_loss": 0.10485746711492538,
      "eval_matthews_correlation": 0.9409599862238431,
      "eval_precision": 0.9704627527865355,
      "eval_recall": 0.9704972340690874,
      "eval_runtime": 2.7118,
      "eval_samples_per_second": 1956.986,
      "eval_steps_per_second": 61.213,
      "step": 3200
    },
    {
      "epoch": 1.2434061793519215,
      "grad_norm": 1.126401662826538,
      "learning_rate": 2.0792163543441227e-05,
      "loss": 0.0783,
      "step": 3300
    },
    {
      "epoch": 1.281085154483798,
      "grad_norm": 2.5860724449157715,
      "learning_rate": 2.0508233957978422e-05,
      "loss": 0.0702,
      "step": 3400
    },
    {
      "epoch": 1.3187641296156745,
      "grad_norm": 3.195108652114868,
      "learning_rate": 2.0224304372515617e-05,
      "loss": 0.0707,
      "step": 3500
    },
    {
      "epoch": 1.356443104747551,
      "grad_norm": 0.03827442228794098,
      "learning_rate": 1.994037478705281e-05,
      "loss": 0.0852,
      "step": 3600
    },
    {
      "epoch": 1.356443104747551,
      "eval_accuracy": 0.9732428867533447,
      "eval_f1": 0.9732294264941552,
      "eval_loss": 0.11138055473566055,
      "eval_matthews_correlation": 0.9467422538209462,
      "eval_precision": 0.9736273744470465,
      "eval_recall": 0.9731150180120012,
      "eval_runtime": 2.7257,
      "eval_samples_per_second": 1947.004,
      "eval_steps_per_second": 60.901,
      "step": 3600
    },
    {
      "epoch": 1.3941220798794274,
      "grad_norm": 4.58756160736084,
      "learning_rate": 1.9656445201590006e-05,
      "loss": 0.0738,
      "step": 3700
    },
    {
      "epoch": 1.4318010550113036,
      "grad_norm": 14.999811172485352,
      "learning_rate": 1.93725156161272e-05,
      "loss": 0.0815,
      "step": 3800
    },
    {
      "epoch": 1.46948003014318,
      "grad_norm": 4.717482566833496,
      "learning_rate": 1.9088586030664396e-05,
      "loss": 0.0779,
      "step": 3900
    },
    {
      "epoch": 1.5071590052750565,
      "grad_norm": 5.975450038909912,
      "learning_rate": 1.880465644520159e-05,
      "loss": 0.0648,
      "step": 4000
    },
    {
      "epoch": 1.5071590052750565,
      "eval_accuracy": 0.9732428867533447,
      "eval_f1": 0.9732311762093169,
      "eval_loss": 0.10359732806682587,
      "eval_matthews_correlation": 0.9466792961819951,
      "eval_precision": 0.9735487461775438,
      "eval_recall": 0.9731306423328758,
      "eval_runtime": 2.713,
      "eval_samples_per_second": 1956.169,
      "eval_steps_per_second": 61.188,
      "step": 4000
    },
    {
      "epoch": 1.544837980406933,
      "grad_norm": 0.08853857964277267,
      "learning_rate": 1.8520726859738785e-05,
      "loss": 0.0922,
      "step": 4100
    },
    {
      "epoch": 1.5825169555388094,
      "grad_norm": 0.4839009940624237,
      "learning_rate": 1.823679727427598e-05,
      "loss": 0.0871,
      "step": 4200
    },
    {
      "epoch": 1.6201959306706857,
      "grad_norm": 11.40882396697998,
      "learning_rate": 1.7952867688813175e-05,
      "loss": 0.0766,
      "step": 4300
    },
    {
      "epoch": 1.6578749058025621,
      "grad_norm": 0.3583201467990875,
      "learning_rate": 1.766893810335037e-05,
      "loss": 0.0695,
      "step": 4400
    },
    {
      "epoch": 1.6578749058025621,
      "eval_accuracy": 0.973808177878274,
      "eval_f1": 0.9737969204411357,
      "eval_loss": 0.10635482519865036,
      "eval_matthews_correlation": 0.9478032234633748,
      "eval_precision": 0.974105363808198,
      "eval_recall": 0.9736979472199078,
      "eval_runtime": 2.7046,
      "eval_samples_per_second": 1962.206,
      "eval_steps_per_second": 61.377,
      "step": 4400
    },
    {
      "epoch": 1.6955538809344386,
      "grad_norm": 3.400505304336548,
      "learning_rate": 1.7385008517887564e-05,
      "loss": 0.0805,
      "step": 4500
    },
    {
      "epoch": 1.7332328560663148,
      "grad_norm": 0.07812280207872391,
      "learning_rate": 1.710107893242476e-05,
      "loss": 0.1011,
      "step": 4600
    },
    {
      "epoch": 1.7709118311981915,
      "grad_norm": 0.0941823348402977,
      "learning_rate": 1.6817149346961954e-05,
      "loss": 0.0737,
      "step": 4700
    },
    {
      "epoch": 1.8085908063300677,
      "grad_norm": 0.6230547428131104,
      "learning_rate": 1.653321976149915e-05,
      "loss": 0.0649,
      "step": 4800
    },
    {
      "epoch": 1.8085908063300677,
      "eval_accuracy": 0.9728660260033918,
      "eval_f1": 0.9728656011289383,
      "eval_loss": 0.12392512708902359,
      "eval_matthews_correlation": 0.9458110704290865,
      "eval_precision": 0.9728815569335125,
      "eval_recall": 0.9729295147114344,
      "eval_runtime": 2.7601,
      "eval_samples_per_second": 1922.75,
      "eval_steps_per_second": 60.143,
      "step": 4800
    },
    {
      "epoch": 1.8462697814619442,
      "grad_norm": 0.056498702615499496,
      "learning_rate": 1.6249290176036343e-05,
      "loss": 0.0756,
      "step": 4900
    },
    {
      "epoch": 1.8839487565938207,
      "grad_norm": 2.2857582569122314,
      "learning_rate": 1.5965360590573538e-05,
      "loss": 0.0707,
      "step": 5000
    },
    {
      "epoch": 1.921627731725697,
      "grad_norm": 0.023716861382126808,
      "learning_rate": 1.5681431005110733e-05,
      "loss": 0.0486,
      "step": 5100
    },
    {
      "epoch": 1.9593067068575736,
      "grad_norm": 0.038595981895923615,
      "learning_rate": 1.539750141964793e-05,
      "loss": 0.0634,
      "step": 5200
    },
    {
      "epoch": 1.9593067068575736,
      "eval_accuracy": 0.9711701526286037,
      "eval_f1": 0.9711425946854346,
      "eval_loss": 0.1199546679854393,
      "eval_matthews_correlation": 0.9431064278840404,
      "eval_precision": 0.972153015409196,
      "eval_recall": 0.9709541744350316,
      "eval_runtime": 2.7522,
      "eval_samples_per_second": 1928.294,
      "eval_steps_per_second": 60.316,
      "step": 5200
    },
    {
      "epoch": 1.9969856819894498,
      "grad_norm": 0.18849776685237885,
      "learning_rate": 1.5113571834185122e-05,
      "loss": 0.0916,
      "step": 5300
    },
    {
      "epoch": 2.0346646571213265,
      "grad_norm": 2.9432480335235596,
      "learning_rate": 1.4832481544576945e-05,
      "loss": 0.0456,
      "step": 5400
    },
    {
      "epoch": 2.0723436322532027,
      "grad_norm": 0.04891876503825188,
      "learning_rate": 1.454855195911414e-05,
      "loss": 0.0315,
      "step": 5500
    },
    {
      "epoch": 2.110022607385079,
      "grad_norm": 0.041655588895082474,
      "learning_rate": 1.4264622373651335e-05,
      "loss": 0.0398,
      "step": 5600
    },
    {
      "epoch": 2.110022607385079,
      "eval_accuracy": 0.9739966082532504,
      "eval_f1": 0.9739826324943728,
      "eval_loss": 0.10525982826948166,
      "eval_matthews_correlation": 0.9482854734422436,
      "eval_precision": 0.9744246326263784,
      "eval_recall": 0.9738610083141273,
      "eval_runtime": 2.7902,
      "eval_samples_per_second": 1902.045,
      "eval_steps_per_second": 59.495,
      "step": 5600
    },
    {
      "epoch": 2.1477015825169556,
      "grad_norm": 0.10578136891126633,
      "learning_rate": 1.398069278818853e-05,
      "loss": 0.0484,
      "step": 5700
    },
    {
      "epoch": 2.185380557648832,
      "grad_norm": 0.0369013175368309,
      "learning_rate": 1.3696763202725724e-05,
      "loss": 0.0425,
      "step": 5800
    },
    {
      "epoch": 2.2230595327807086,
      "grad_norm": 0.01933310739696026,
      "learning_rate": 1.3412833617262919e-05,
      "loss": 0.044,
      "step": 5900
    },
    {
      "epoch": 2.260738507912585,
      "grad_norm": 0.026894742622971535,
      "learning_rate": 1.3128904031800115e-05,
      "loss": 0.0282,
      "step": 6000
    },
    {
      "epoch": 2.260738507912585,
      "eval_accuracy": 0.9724891652534389,
      "eval_f1": 0.972488453147902,
      "eval_loss": 0.11717395484447479,
      "eval_matthews_correlation": 0.9450310523223673,
      "eval_precision": 0.9724901584448482,
      "eval_recall": 0.9725408952394967,
      "eval_runtime": 2.7786,
      "eval_samples_per_second": 1909.976,
      "eval_steps_per_second": 59.743,
      "step": 6000
    },
    {
      "epoch": 2.298417483044461,
      "grad_norm": 0.06688477098941803,
      "learning_rate": 1.2844974446337309e-05,
      "loss": 0.0408,
      "step": 6100
    },
    {
      "epoch": 2.3360964581763377,
      "grad_norm": 0.023227360099554062,
      "learning_rate": 1.2561044860874503e-05,
      "loss": 0.028,
      "step": 6200
    },
    {
      "epoch": 2.373775433308214,
      "grad_norm": 0.24025118350982666,
      "learning_rate": 1.2277115275411698e-05,
      "loss": 0.0589,
      "step": 6300
    },
    {
      "epoch": 2.4114544084400906,
      "grad_norm": 0.09038496017456055,
      "learning_rate": 1.1993185689948893e-05,
      "loss": 0.0385,
      "step": 6400
    },
    {
      "epoch": 2.4114544084400906,
      "eval_accuracy": 0.9760693423779914,
      "eval_f1": 0.9760675443156241,
      "eval_loss": 0.1077490970492363,
      "eval_matthews_correlation": 0.9521407037949356,
      "eval_precision": 0.9760563550318717,
      "eval_recall": 0.9760843491745955,
      "eval_runtime": 2.802,
      "eval_samples_per_second": 1894.017,
      "eval_steps_per_second": 59.244,
      "step": 6400
    },
    {
      "epoch": 2.449133383571967,
      "grad_norm": 0.017891166731715202,
      "learning_rate": 1.1709256104486088e-05,
      "loss": 0.0437,
      "step": 6500
    },
    {
      "epoch": 2.486812358703843,
      "grad_norm": 2.2715256214141846,
      "learning_rate": 1.1425326519023282e-05,
      "loss": 0.0351,
      "step": 6600
    },
    {
      "epoch": 2.5244913338357198,
      "grad_norm": 0.04258134961128235,
      "learning_rate": 1.1141396933560477e-05,
      "loss": 0.0514,
      "step": 6700
    },
    {
      "epoch": 2.562170308967596,
      "grad_norm": 0.05380069091916084,
      "learning_rate": 1.0857467348097672e-05,
      "loss": 0.0233,
      "step": 6800
    },
    {
      "epoch": 2.562170308967596,
      "eval_accuracy": 0.9773883550028265,
      "eval_f1": 0.9773851680452039,
      "eval_loss": 0.11859235167503357,
      "eval_matthews_correlation": 0.95477477932786,
      "eval_precision": 0.9774044781373112,
      "eval_recall": 0.9773703018022228,
      "eval_runtime": 2.7732,
      "eval_samples_per_second": 1913.705,
      "eval_steps_per_second": 59.86,
      "step": 6800
    },
    {
      "epoch": 2.5998492840994727,
      "grad_norm": 0.016610480844974518,
      "learning_rate": 1.0573537762634866e-05,
      "loss": 0.0489,
      "step": 6900
    },
    {
      "epoch": 2.637528259231349,
      "grad_norm": 6.033469200134277,
      "learning_rate": 1.0289608177172061e-05,
      "loss": 0.0497,
      "step": 7000
    },
    {
      "epoch": 2.675207234363225,
      "grad_norm": 0.016822315752506256,
      "learning_rate": 1.0005678591709258e-05,
      "loss": 0.0357,
      "step": 7100
    },
    {
      "epoch": 2.712886209495102,
      "grad_norm": 0.05039643496274948,
      "learning_rate": 9.72174900624645e-06,
      "loss": 0.0505,
      "step": 7200
    },
    {
      "epoch": 2.712886209495102,
      "eval_accuracy": 0.9753156208780855,
      "eval_f1": 0.9753082004284377,
      "eval_loss": 0.1005312129855156,
      "eval_matthews_correlation": 0.9507112767868612,
      "eval_precision": 0.975470597714733,
      "eval_recall": 0.9752407068670026,
      "eval_runtime": 2.7515,
      "eval_samples_per_second": 1928.756,
      "eval_steps_per_second": 60.33,
      "step": 7200
    },
    {
      "epoch": 2.750565184626978,
      "grad_norm": 10.457962036132812,
      "learning_rate": 9.437819420783647e-06,
      "loss": 0.0471,
      "step": 7300
    },
    {
      "epoch": 2.7882441597588548,
      "grad_norm": 0.021144887432456017,
      "learning_rate": 9.15388983532084e-06,
      "loss": 0.0404,
      "step": 7400
    },
    {
      "epoch": 2.825923134890731,
      "grad_norm": 0.030750004574656487,
      "learning_rate": 8.869960249858037e-06,
      "loss": 0.043,
      "step": 7500
    },
    {
      "epoch": 2.8636021100226072,
      "grad_norm": 0.017929725348949432,
      "learning_rate": 8.58603066439523e-06,
      "loss": 0.0547,
      "step": 7600
    },
    {
      "epoch": 2.8636021100226072,
      "eval_accuracy": 0.9766346335029207,
      "eval_f1": 0.9766240353970732,
      "eval_loss": 0.10185229778289795,
      "eval_matthews_correlation": 0.9534816081504847,
      "eval_precision": 0.9769628642010694,
      "eval_recall": 0.9765188473341926,
      "eval_runtime": 2.7621,
      "eval_samples_per_second": 1921.37,
      "eval_steps_per_second": 60.099,
      "step": 7600
    },
    {
      "epoch": 2.901281085154484,
      "grad_norm": 2.6261825561523438,
      "learning_rate": 8.304940374787053e-06,
      "loss": 0.0396,
      "step": 7700
    },
    {
      "epoch": 2.93896006028636,
      "grad_norm": 0.09515279531478882,
      "learning_rate": 8.02101078932425e-06,
      "loss": 0.0504,
      "step": 7800
    },
    {
      "epoch": 2.976639035418237,
      "grad_norm": 0.018642358481884003,
      "learning_rate": 7.737081203861442e-06,
      "loss": 0.0394,
      "step": 7900
    },
    {
      "epoch": 3.014318010550113,
      "grad_norm": 0.02129693143069744,
      "learning_rate": 7.453151618398637e-06,
      "loss": 0.0364,
      "step": 8000
    },
    {
      "epoch": 3.014318010550113,
      "eval_accuracy": 0.9790842283776144,
      "eval_f1": 0.9790782112994216,
      "eval_loss": 0.09817579388618469,
      "eval_matthews_correlation": 0.9582416445314039,
      "eval_precision": 0.9792280432606582,
      "eval_recall": 0.9790136252600384,
      "eval_runtime": 2.7947,
      "eval_samples_per_second": 1898.934,
      "eval_steps_per_second": 59.398,
      "step": 8000
    },
    {
      "epoch": 3.0519969856819893,
      "grad_norm": 0.033309515565633774,
      "learning_rate": 7.169222032935832e-06,
      "loss": 0.0178,
      "step": 8100
    },
    {
      "epoch": 3.089675960813866,
      "grad_norm": 0.013276271522045135,
      "learning_rate": 6.885292447473027e-06,
      "loss": 0.0125,
      "step": 8200
    },
    {
      "epoch": 3.127354935945742,
      "grad_norm": 0.06139272078871727,
      "learning_rate": 6.601362862010222e-06,
      "loss": 0.0154,
      "step": 8300
    },
    {
      "epoch": 3.165033911077619,
      "grad_norm": 0.009919361211359501,
      "learning_rate": 6.317433276547417e-06,
      "loss": 0.0195,
      "step": 8400
    },
    {
      "epoch": 3.165033911077619,
      "eval_accuracy": 0.9785189372526851,
      "eval_f1": 0.9785120516178454,
      "eval_loss": 0.12360835075378418,
      "eval_matthews_correlation": 0.9571353578434483,
      "eval_precision": 0.9786968845048949,
      "eval_recall": 0.9784385082125692,
      "eval_runtime": 2.7652,
      "eval_samples_per_second": 1919.186,
      "eval_steps_per_second": 60.031,
      "step": 8400
    },
    {
      "epoch": 3.202712886209495,
      "grad_norm": 0.009366081096231937,
      "learning_rate": 6.033503691084612e-06,
      "loss": 0.0239,
      "step": 8500
    },
    {
      "epoch": 3.2403918613413714,
      "grad_norm": 0.00721873389557004,
      "learning_rate": 5.749574105621806e-06,
      "loss": 0.0359,
      "step": 8600
    },
    {
      "epoch": 3.278070836473248,
      "grad_norm": 0.012619871646165848,
      "learning_rate": 5.465644520159001e-06,
      "loss": 0.0207,
      "step": 8700
    },
    {
      "epoch": 3.3157498116051243,
      "grad_norm": 0.0176852960139513,
      "learning_rate": 5.181714934696195e-06,
      "loss": 0.0249,
      "step": 8800
    },
    {
      "epoch": 3.3157498116051243,
      "eval_accuracy": 0.9779536461277558,
      "eval_f1": 0.9779470187032611,
      "eval_loss": 0.11475720256567001,
      "eval_matthews_correlation": 0.9559891701143,
      "eval_precision": 0.9781101825775036,
      "eval_recall": 0.9778790154859747,
      "eval_runtime": 2.7473,
      "eval_samples_per_second": 1931.719,
      "eval_steps_per_second": 60.423,
      "step": 8800
    },
    {
      "epoch": 3.353428786737001,
      "grad_norm": 0.024505026638507843,
      "learning_rate": 4.89778534923339e-06,
      "loss": 0.0236,
      "step": 8900
    },
    {
      "epoch": 3.391107761868877,
      "grad_norm": 0.5788570642471313,
      "learning_rate": 4.6138557637705846e-06,
      "loss": 0.0119,
      "step": 9000
    },
    {
      "epoch": 3.4287867370007534,
      "grad_norm": 0.009713280946016312,
      "learning_rate": 4.329926178307779e-06,
      "loss": 0.024,
      "step": 9100
    },
    {
      "epoch": 3.46646571213263,
      "grad_norm": 0.00652025593444705,
      "learning_rate": 4.045996592844974e-06,
      "loss": 0.017,
      "step": 9200
    },
    {
      "epoch": 3.46646571213263,
      "eval_accuracy": 0.9779536461277558,
      "eval_f1": 0.9779493588019621,
      "eval_loss": 0.12188450247049332,
      "eval_matthews_correlation": 0.9559237976282022,
      "eval_precision": 0.9780096321868474,
      "eval_recall": 0.9779141702079427,
      "eval_runtime": 2.7414,
      "eval_samples_per_second": 1935.849,
      "eval_steps_per_second": 60.552,
      "step": 9200
    },
    {
      "epoch": 3.5041446872645063,
      "grad_norm": 0.12155177444219589,
      "learning_rate": 3.762067007382169e-06,
      "loss": 0.0232,
      "step": 9300
    },
    {
      "epoch": 3.541823662396383,
      "grad_norm": 0.012790014035999775,
      "learning_rate": 3.478137421919364e-06,
      "loss": 0.0174,
      "step": 9400
    },
    {
      "epoch": 3.5795026375282593,
      "grad_norm": 0.05154751241207123,
      "learning_rate": 3.1942078364565587e-06,
      "loss": 0.0391,
      "step": 9500
    },
    {
      "epoch": 3.6171816126601355,
      "grad_norm": 0.02925085835158825,
      "learning_rate": 2.910278250993754e-06,
      "loss": 0.0235,
      "step": 9600
    },
    {
      "epoch": 3.6171816126601355,
      "eval_accuracy": 0.9768230638778971,
      "eval_f1": 0.9768166894293167,
      "eval_loss": 0.12384133040904999,
      "eval_matthews_correlation": 0.9537089621164536,
      "eval_precision": 0.9769528584554357,
      "eval_recall": 0.9767561239525668,
      "eval_runtime": 2.6673,
      "eval_samples_per_second": 1989.621,
      "eval_steps_per_second": 62.234,
      "step": 9600
    },
    {
      "epoch": 3.654860587792012,
      "grad_norm": 0.01140882819890976,
      "learning_rate": 2.6263486655309486e-06,
      "loss": 0.0131,
      "step": 9700
    },
    {
      "epoch": 3.6925395629238884,
      "grad_norm": 0.010966621339321136,
      "learning_rate": 2.3424190800681434e-06,
      "loss": 0.0231,
      "step": 9800
    },
    {
      "epoch": 3.730218538055765,
      "grad_norm": 0.011507470160722733,
      "learning_rate": 2.0584894946053377e-06,
      "loss": 0.0324,
      "step": 9900
    },
    {
      "epoch": 3.7678975131876413,
      "grad_norm": 0.010073116049170494,
      "learning_rate": 1.7745599091425328e-06,
      "loss": 0.0159,
      "step": 10000
    },
    {
      "epoch": 3.7678975131876413,
      "eval_accuracy": 0.9762577727529678,
      "eval_f1": 0.9762516805753335,
      "eval_loss": 0.12384281307458878,
      "eval_matthews_correlation": 0.9525657878186475,
      "eval_precision": 0.9763691722190995,
      "eval_recall": 0.9761966312259722,
      "eval_runtime": 2.6603,
      "eval_samples_per_second": 1994.898,
      "eval_steps_per_second": 62.399,
      "step": 10000
    },
    {
      "epoch": 3.8055764883195176,
      "grad_norm": 0.053388480097055435,
      "learning_rate": 1.4906303236797274e-06,
      "loss": 0.0173,
      "step": 10100
    },
    {
      "epoch": 3.8432554634513942,
      "grad_norm": 0.007739369757473469,
      "learning_rate": 1.2067007382169221e-06,
      "loss": 0.0103,
      "step": 10200
    },
    {
      "epoch": 3.8809344385832705,
      "grad_norm": 0.008169571869075298,
      "learning_rate": 9.22771152754117e-07,
      "loss": 0.0123,
      "step": 10300
    },
    {
      "epoch": 3.918613413715147,
      "grad_norm": 11.170659065246582,
      "learning_rate": 6.388415672913117e-07,
      "loss": 0.0184,
      "step": 10400
    },
    {
      "epoch": 3.918613413715147,
      "eval_accuracy": 0.9766346335029207,
      "eval_f1": 0.9766289169155064,
      "eval_loss": 0.12415151298046112,
      "eval_matthews_correlation": 0.953312233906831,
      "eval_precision": 0.9767348083584186,
      "eval_recall": 0.9765774385374727,
      "eval_runtime": 2.6906,
      "eval_samples_per_second": 1972.43,
      "eval_steps_per_second": 61.697,
      "step": 10400
    },
    {
      "epoch": 3.9562923888470234,
      "grad_norm": 0.2703685760498047,
      "learning_rate": 3.549119818285065e-07,
      "loss": 0.0307,
      "step": 10500
    },
    {
      "epoch": 3.9939713639788996,
      "grad_norm": 0.5032870769500732,
      "learning_rate": 7.382169222032936e-08,
      "loss": 0.0257,
      "step": 10600
    },
    {
      "epoch": 4.0,
      "step": 10616,
      "total_flos": 8124902207913984.0,
      "train_loss": 0.07393335661631198,
      "train_runtime": 666.3791,
      "train_samples_per_second": 254.822,
      "train_steps_per_second": 15.931
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.4823890098059866,
      "eval_f1": 0.16116693814506267,
      "eval_loss": NaN,
      "eval_matthews_correlation": 0.3815136757231358,
      "eval_precision": 0.12066324578856187,
      "eval_recall": 0.24276847280362707,
      "eval_runtime": 488.9294,
      "eval_samples_per_second": 174.786,
      "eval_steps_per_second": 10.926,
      "step": 10684
    },
    {
      "epoch": 2.0029951329090228,
      "grad_norm": 1.2818087339401245,
      "learning_rate": 2.990565331336578e-05,
      "loss": 0.4241,
      "step": 10700
    },
    {
      "epoch": 2.0217147135904154,
      "grad_norm": 0.46326524019241333,
      "learning_rate": 2.9793335829277423e-05,
      "loss": 0.1514,
      "step": 10800
    },
    {
      "epoch": 2.040434294271808,
      "grad_norm": 5.229877948760986,
      "learning_rate": 2.9681018345189065e-05,
      "loss": 0.1651,
      "step": 10900
    },
    {
      "epoch": 2.0591538749532012,
      "grad_norm": 0.13991111516952515,
      "learning_rate": 2.9568700861100715e-05,
      "loss": 0.1909,
      "step": 11000
    },
    {
      "epoch": 2.077873455634594,
      "grad_norm": 0.11240403354167938,
      "learning_rate": 2.9456383377012357e-05,
      "loss": 0.1323,
      "step": 11100
    },
    {
      "epoch": 2.0965930363159866,
      "grad_norm": 8.410670280456543,
      "learning_rate": 2.9344065892924e-05,
      "loss": 0.1212,
      "step": 11200
    },
    {
      "epoch": 2.1153126169973793,
      "grad_norm": 0.3720778822898865,
      "learning_rate": 2.9231748408835642e-05,
      "loss": 0.1229,
      "step": 11300
    },
    {
      "epoch": 2.134032197678772,
      "grad_norm": 0.22757580876350403,
      "learning_rate": 2.9119430924747288e-05,
      "loss": 0.0939,
      "step": 11400
    },
    {
      "epoch": 2.1527517783601646,
      "grad_norm": 8.637288093566895,
      "learning_rate": 2.900711344065893e-05,
      "loss": 0.1584,
      "step": 11500
    },
    {
      "epoch": 2.1714713590415573,
      "grad_norm": 0.14022479951381683,
      "learning_rate": 2.8894795956570573e-05,
      "loss": 0.1742,
      "step": 11600
    },
    {
      "epoch": 2.1901909397229504,
      "grad_norm": 0.7691003680229187,
      "learning_rate": 2.8782478472482216e-05,
      "loss": 0.1758,
      "step": 11700
    },
    {
      "epoch": 2.208910520404343,
      "grad_norm": 1.0570822954177856,
      "learning_rate": 2.867016098839386e-05,
      "loss": 0.1454,
      "step": 11800
    },
    {
      "epoch": 2.227630101085736,
      "grad_norm": 4.208011627197266,
      "learning_rate": 2.8557843504305504e-05,
      "loss": 0.1734,
      "step": 11900
    },
    {
      "epoch": 2.2463496817671285,
      "grad_norm": 0.32856494188308716,
      "learning_rate": 2.8445526020217147e-05,
      "loss": 0.1383,
      "step": 12000
    },
    {
      "epoch": 2.265069262448521,
      "grad_norm": 0.11425557732582092,
      "learning_rate": 2.8333208536128793e-05,
      "loss": 0.1262,
      "step": 12100
    },
    {
      "epoch": 2.283788843129914,
      "grad_norm": 48.93288803100586,
      "learning_rate": 2.8220891052040435e-05,
      "loss": 0.1861,
      "step": 12200
    },
    {
      "epoch": 2.3025084238113065,
      "grad_norm": 2.3481006622314453,
      "learning_rate": 2.8108573567952078e-05,
      "loss": 0.0952,
      "step": 12300
    },
    {
      "epoch": 2.321228004492699,
      "grad_norm": 1.492978811264038,
      "learning_rate": 2.7996256083863724e-05,
      "loss": 0.1527,
      "step": 12400
    },
    {
      "epoch": 2.3399475851740923,
      "grad_norm": 0.123751200735569,
      "learning_rate": 2.7883938599775366e-05,
      "loss": 0.1547,
      "step": 12500
    },
    {
      "epoch": 2.358667165855485,
      "grad_norm": 0.06616698950529099,
      "learning_rate": 2.777162111568701e-05,
      "loss": 0.1,
      "step": 12600
    },
    {
      "epoch": 2.3773867465368776,
      "grad_norm": 1.2863701581954956,
      "learning_rate": 2.765930363159865e-05,
      "loss": 0.1097,
      "step": 12700
    },
    {
      "epoch": 2.3961063272182703,
      "grad_norm": 1.00491201877594,
      "learning_rate": 2.7546986147510297e-05,
      "loss": 0.1398,
      "step": 12800
    },
    {
      "epoch": 2.414825907899663,
      "grad_norm": 0.09450684487819672,
      "learning_rate": 2.743466866342194e-05,
      "loss": 0.1247,
      "step": 12900
    },
    {
      "epoch": 2.4335454885810557,
      "grad_norm": 64.3247299194336,
      "learning_rate": 2.7322351179333582e-05,
      "loss": 0.1362,
      "step": 13000
    },
    {
      "epoch": 2.4522650692624484,
      "grad_norm": 28.231544494628906,
      "learning_rate": 2.7210033695245225e-05,
      "loss": 0.1735,
      "step": 13100
    },
    {
      "epoch": 2.4709846499438415,
      "grad_norm": 0.5649726986885071,
      "learning_rate": 2.709771621115687e-05,
      "loss": 0.125,
      "step": 13200
    },
    {
      "epoch": 2.489704230625234,
      "grad_norm": 0.19312413036823273,
      "learning_rate": 2.6985398727068517e-05,
      "loss": 0.1067,
      "step": 13300
    },
    {
      "epoch": 2.508423811306627,
      "grad_norm": 4.776828765869141,
      "learning_rate": 2.687308124298016e-05,
      "loss": 0.1397,
      "step": 13400
    },
    {
      "epoch": 2.5271433919880195,
      "grad_norm": 8.883413314819336,
      "learning_rate": 2.6760763758891802e-05,
      "loss": 0.1116,
      "step": 13500
    },
    {
      "epoch": 2.545862972669412,
      "grad_norm": 4.2587785720825195,
      "learning_rate": 2.6648446274803444e-05,
      "loss": 0.1,
      "step": 13600
    },
    {
      "epoch": 2.564582553350805,
      "grad_norm": 4.267656326293945,
      "learning_rate": 2.6536128790715087e-05,
      "loss": 0.1355,
      "step": 13700
    },
    {
      "epoch": 2.5833021340321976,
      "grad_norm": 0.04645482823252678,
      "learning_rate": 2.6423811306626733e-05,
      "loss": 0.0918,
      "step": 13800
    },
    {
      "epoch": 2.6020217147135902,
      "grad_norm": 14.54674243927002,
      "learning_rate": 2.6311493822538375e-05,
      "loss": 0.1335,
      "step": 13900
    },
    {
      "epoch": 2.620741295394983,
      "grad_norm": 28.391878128051758,
      "learning_rate": 2.6199176338450018e-05,
      "loss": 0.1336,
      "step": 14000
    },
    {
      "epoch": 2.639460876076376,
      "grad_norm": 0.18383058905601501,
      "learning_rate": 2.608685885436166e-05,
      "loss": 0.1147,
      "step": 14100
    },
    {
      "epoch": 2.6581804567577687,
      "grad_norm": 0.12234121561050415,
      "learning_rate": 2.597454137027331e-05,
      "loss": 0.1225,
      "step": 14200
    },
    {
      "epoch": 2.6769000374391614,
      "grad_norm": 124.8676528930664,
      "learning_rate": 2.5862223886184952e-05,
      "loss": 0.1027,
      "step": 14300
    },
    {
      "epoch": 2.695619618120554,
      "grad_norm": 0.048648957163095474,
      "learning_rate": 2.5749906402096595e-05,
      "loss": 0.0734,
      "step": 14400
    },
    {
      "epoch": 2.7143391988019467,
      "grad_norm": 0.05046042427420616,
      "learning_rate": 2.5637588918008237e-05,
      "loss": 0.1011,
      "step": 14500
    },
    {
      "epoch": 2.7330587794833394,
      "grad_norm": 0.11465981602668762,
      "learning_rate": 2.552527143391988e-05,
      "loss": 0.123,
      "step": 14600
    },
    {
      "epoch": 2.7517783601647325,
      "grad_norm": 1.1903955936431885,
      "learning_rate": 2.5412953949831526e-05,
      "loss": 0.1264,
      "step": 14700
    },
    {
      "epoch": 2.770497940846125,
      "grad_norm": 2.9101979732513428,
      "learning_rate": 2.5300636465743168e-05,
      "loss": 0.1299,
      "step": 14800
    },
    {
      "epoch": 2.789217521527518,
      "grad_norm": 9.4379243850708,
      "learning_rate": 2.518831898165481e-05,
      "loss": 0.1161,
      "step": 14900
    },
    {
      "epoch": 2.8079371022089106,
      "grad_norm": 0.09578457474708557,
      "learning_rate": 2.5076001497566453e-05,
      "loss": 0.1334,
      "step": 15000
    },
    {
      "epoch": 2.8266566828903033,
      "grad_norm": 0.07683119177818298,
      "learning_rate": 2.49636840134781e-05,
      "loss": 0.0883,
      "step": 15100
    },
    {
      "epoch": 2.845376263571696,
      "grad_norm": 1.1585252285003662,
      "learning_rate": 2.485136652938974e-05,
      "loss": 0.14,
      "step": 15200
    },
    {
      "epoch": 2.8640958442530886,
      "grad_norm": 0.2491634637117386,
      "learning_rate": 2.4739049045301388e-05,
      "loss": 0.1224,
      "step": 15300
    },
    {
      "epoch": 2.8828154249344813,
      "grad_norm": 27.012693405151367,
      "learning_rate": 2.462673156121303e-05,
      "loss": 0.1043,
      "step": 15400
    },
    {
      "epoch": 2.901535005615874,
      "grad_norm": 0.47072330117225647,
      "learning_rate": 2.4514414077124673e-05,
      "loss": 0.1062,
      "step": 15500
    },
    {
      "epoch": 2.920254586297267,
      "grad_norm": 3.671541213989258,
      "learning_rate": 2.440209659303632e-05,
      "loss": 0.0788,
      "step": 15600
    },
    {
      "epoch": 2.9389741669786598,
      "grad_norm": 7.966693878173828,
      "learning_rate": 2.428977910894796e-05,
      "loss": 0.1047,
      "step": 15700
    },
    {
      "epoch": 2.9576937476600524,
      "grad_norm": 53.434871673583984,
      "learning_rate": 2.4177461624859604e-05,
      "loss": 0.0858,
      "step": 15800
    },
    {
      "epoch": 2.976413328341445,
      "grad_norm": 25.71195411682129,
      "learning_rate": 2.4065144140771246e-05,
      "loss": 0.108,
      "step": 15900
    },
    {
      "epoch": 2.995132909022838,
      "grad_norm": 0.8052852153778076,
      "learning_rate": 2.395282665668289e-05,
      "loss": 0.0938,
      "step": 16000
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.49272157083011536,
      "eval_f1": 0.16459774024426493,
      "eval_loss": NaN,
      "eval_matthews_correlation": 0.39817194515232196,
      "eval_precision": 0.12318550166313486,
      "eval_recall": 0.24796824060607303,
      "eval_runtime": 145.0046,
      "eval_samples_per_second": 589.347,
      "eval_steps_per_second": 36.84,
      "step": 16026
    },
    {
      "epoch": 3.0138524897042305,
      "grad_norm": 0.06625857949256897,
      "learning_rate": 2.3840509172594535e-05,
      "loss": 0.1013,
      "step": 16100
    },
    {
      "epoch": 3.032572070385623,
      "grad_norm": 1.361025333404541,
      "learning_rate": 2.3728191688506177e-05,
      "loss": 0.0633,
      "step": 16200
    },
    {
      "epoch": 3.0512916510670163,
      "grad_norm": 0.2113879919052124,
      "learning_rate": 2.3615874204417823e-05,
      "loss": 0.1181,
      "step": 16300
    },
    {
      "epoch": 3.070011231748409,
      "grad_norm": 1.1715766191482544,
      "learning_rate": 2.3503556720329466e-05,
      "loss": 0.0868,
      "step": 16400
    },
    {
      "epoch": 3.0887308124298016,
      "grad_norm": 25.956127166748047,
      "learning_rate": 2.3391239236241108e-05,
      "loss": 0.0645,
      "step": 16500
    },
    {
      "epoch": 3.1074503931111943,
      "grad_norm": 12.293737411499023,
      "learning_rate": 2.3278921752152754e-05,
      "loss": 0.1088,
      "step": 16600
    },
    {
      "epoch": 3.126169973792587,
      "grad_norm": 1.98764169216156,
      "learning_rate": 2.3166604268064397e-05,
      "loss": 0.1476,
      "step": 16700
    },
    {
      "epoch": 3.1448895544739797,
      "grad_norm": 0.057815246284008026,
      "learning_rate": 2.305428678397604e-05,
      "loss": 0.0862,
      "step": 16800
    },
    {
      "epoch": 3.1636091351553723,
      "grad_norm": 0.24252842366695404,
      "learning_rate": 2.294196929988768e-05,
      "loss": 0.0682,
      "step": 16900
    },
    {
      "epoch": 3.182328715836765,
      "grad_norm": 0.17992441356182098,
      "learning_rate": 2.2829651815799328e-05,
      "loss": 0.0829,
      "step": 17000
    },
    {
      "epoch": 3.201048296518158,
      "grad_norm": 0.06300792843103409,
      "learning_rate": 2.271733433171097e-05,
      "loss": 0.0891,
      "step": 17100
    },
    {
      "epoch": 3.219767877199551,
      "grad_norm": 0.07280579209327698,
      "learning_rate": 2.2605016847622613e-05,
      "loss": 0.1124,
      "step": 17200
    },
    {
      "epoch": 3.2384874578809435,
      "grad_norm": 2.66859769821167,
      "learning_rate": 2.2492699363534255e-05,
      "loss": 0.1189,
      "step": 17300
    },
    {
      "epoch": 3.257207038562336,
      "grad_norm": 0.07613415271043777,
      "learning_rate": 2.23803818794459e-05,
      "loss": 0.1027,
      "step": 17400
    },
    {
      "epoch": 3.275926619243729,
      "grad_norm": 77.7967758178711,
      "learning_rate": 2.2268064395357547e-05,
      "loss": 0.0732,
      "step": 17500
    },
    {
      "epoch": 3.2946461999251215,
      "grad_norm": 0.04350031539797783,
      "learning_rate": 2.215574691126919e-05,
      "loss": 0.074,
      "step": 17600
    },
    {
      "epoch": 3.3133657806065147,
      "grad_norm": 9.902512550354004,
      "learning_rate": 2.2043429427180832e-05,
      "loss": 0.0664,
      "step": 17700
    },
    {
      "epoch": 3.3320853612879073,
      "grad_norm": 0.07632334530353546,
      "learning_rate": 2.1931111943092475e-05,
      "loss": 0.0906,
      "step": 17800
    },
    {
      "epoch": 3.3508049419693,
      "grad_norm": 6.743155002593994,
      "learning_rate": 2.181879445900412e-05,
      "loss": 0.1123,
      "step": 17900
    },
    {
      "epoch": 3.3695245226506927,
      "grad_norm": 0.0411403551697731,
      "learning_rate": 2.1706476974915763e-05,
      "loss": 0.0973,
      "step": 18000
    },
    {
      "epoch": 3.3882441033320854,
      "grad_norm": 0.07512003928422928,
      "learning_rate": 2.1594159490827406e-05,
      "loss": 0.1138,
      "step": 18100
    },
    {
      "epoch": 3.406963684013478,
      "grad_norm": 0.06076258048415184,
      "learning_rate": 2.1481842006739048e-05,
      "loss": 0.1201,
      "step": 18200
    },
    {
      "epoch": 3.4256832646948707,
      "grad_norm": 0.14059722423553467,
      "learning_rate": 2.136952452265069e-05,
      "loss": 0.124,
      "step": 18300
    },
    {
      "epoch": 3.4444028453762634,
      "grad_norm": 0.07319800555706024,
      "learning_rate": 2.1257207038562337e-05,
      "loss": 0.0889,
      "step": 18400
    },
    {
      "epoch": 3.463122426057656,
      "grad_norm": 59.261940002441406,
      "learning_rate": 2.1144889554473982e-05,
      "loss": 0.0501,
      "step": 18500
    },
    {
      "epoch": 3.481842006739049,
      "grad_norm": 0.13559073209762573,
      "learning_rate": 2.1032572070385625e-05,
      "loss": 0.1462,
      "step": 18600
    },
    {
      "epoch": 3.500561587420442,
      "grad_norm": 1.0517680644989014,
      "learning_rate": 2.0920254586297268e-05,
      "loss": 0.0724,
      "step": 18700
    },
    {
      "epoch": 3.5192811681018346,
      "grad_norm": 0.08803918212652206,
      "learning_rate": 2.080793710220891e-05,
      "loss": 0.1057,
      "step": 18800
    },
    {
      "epoch": 3.5380007487832272,
      "grad_norm": 0.11210784316062927,
      "learning_rate": 2.0695619618120556e-05,
      "loss": 0.1027,
      "step": 18900
    },
    {
      "epoch": 3.55672032946462,
      "grad_norm": 0.2894304096698761,
      "learning_rate": 2.05833021340322e-05,
      "loss": 0.0977,
      "step": 19000
    },
    {
      "epoch": 3.5754399101460126,
      "grad_norm": 1.3421348333358765,
      "learning_rate": 2.047098464994384e-05,
      "loss": 0.0658,
      "step": 19100
    },
    {
      "epoch": 3.5941594908274057,
      "grad_norm": 0.05683639645576477,
      "learning_rate": 2.0358667165855484e-05,
      "loss": 0.11,
      "step": 19200
    },
    {
      "epoch": 3.6128790715087984,
      "grad_norm": 0.3713160753250122,
      "learning_rate": 2.024634968176713e-05,
      "loss": 0.0811,
      "step": 19300
    },
    {
      "epoch": 3.631598652190191,
      "grad_norm": 1.7953388690948486,
      "learning_rate": 2.0134032197678772e-05,
      "loss": 0.1127,
      "step": 19400
    },
    {
      "epoch": 3.6503182328715837,
      "grad_norm": 0.06101206690073013,
      "learning_rate": 2.0021714713590418e-05,
      "loss": 0.0927,
      "step": 19500
    },
    {
      "epoch": 3.6690378135529764,
      "grad_norm": 0.08317410945892334,
      "learning_rate": 1.990939722950206e-05,
      "loss": 0.0698,
      "step": 19600
    },
    {
      "epoch": 3.687757394234369,
      "grad_norm": 9.410085678100586,
      "learning_rate": 1.9797079745413703e-05,
      "loss": 0.1451,
      "step": 19700
    },
    {
      "epoch": 3.706476974915762,
      "grad_norm": 0.16537928581237793,
      "learning_rate": 1.968476226132535e-05,
      "loss": 0.1066,
      "step": 19800
    },
    {
      "epoch": 3.7251965555971545,
      "grad_norm": 0.05719221010804176,
      "learning_rate": 1.957244477723699e-05,
      "loss": 0.1292,
      "step": 19900
    },
    {
      "epoch": 3.743916136278547,
      "grad_norm": 0.0708918422460556,
      "learning_rate": 1.9460127293148634e-05,
      "loss": 0.0977,
      "step": 20000
    },
    {
      "epoch": 3.7626357169599403,
      "grad_norm": 0.0721459910273552,
      "learning_rate": 1.9347809809060277e-05,
      "loss": 0.0744,
      "step": 20100
    },
    {
      "epoch": 3.781355297641333,
      "grad_norm": 0.069149449467659,
      "learning_rate": 1.923549232497192e-05,
      "loss": 0.1123,
      "step": 20200
    },
    {
      "epoch": 3.8000748783227256,
      "grad_norm": 0.046933989971876144,
      "learning_rate": 1.9123174840883565e-05,
      "loss": 0.0751,
      "step": 20300
    },
    {
      "epoch": 3.8187944590041183,
      "grad_norm": 0.5910888314247131,
      "learning_rate": 1.9010857356795208e-05,
      "loss": 0.0931,
      "step": 20400
    },
    {
      "epoch": 3.837514039685511,
      "grad_norm": 0.11772524565458298,
      "learning_rate": 1.889853987270685e-05,
      "loss": 0.1306,
      "step": 20500
    },
    {
      "epoch": 3.8562336203669036,
      "grad_norm": 0.07123027741909027,
      "learning_rate": 1.8786222388618496e-05,
      "loss": 0.0795,
      "step": 20600
    },
    {
      "epoch": 3.8749532010482968,
      "grad_norm": 0.12210424244403839,
      "learning_rate": 1.8673904904530142e-05,
      "loss": 0.1024,
      "step": 20700
    },
    {
      "epoch": 3.8936727817296894,
      "grad_norm": 10.15885066986084,
      "learning_rate": 1.8561587420441784e-05,
      "loss": 0.0758,
      "step": 20800
    },
    {
      "epoch": 3.912392362411082,
      "grad_norm": 5.254702568054199,
      "learning_rate": 1.8449269936353427e-05,
      "loss": 0.0888,
      "step": 20900
    },
    {
      "epoch": 3.931111943092475,
      "grad_norm": 0.07828379422426224,
      "learning_rate": 1.833695245226507e-05,
      "loss": 0.1029,
      "step": 21000
    },
    {
      "epoch": 3.9498315237738675,
      "grad_norm": 0.10174836218357086,
      "learning_rate": 1.8224634968176712e-05,
      "loss": 0.0936,
      "step": 21100
    },
    {
      "epoch": 3.96855110445526,
      "grad_norm": 1.655807614326477,
      "learning_rate": 1.8112317484088358e-05,
      "loss": 0.1285,
      "step": 21200
    },
    {
      "epoch": 3.987270685136653,
      "grad_norm": 0.07754090428352356,
      "learning_rate": 1.8e-05,
      "loss": 0.0542,
      "step": 21300
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.49378642139998596,
      "eval_f1": 0.1649523673355785,
      "eval_loss": NaN,
      "eval_matthews_correlation": 0.39989530702913506,
      "eval_precision": 0.12344805700026415,
      "eval_recall": 0.24850416522326974,
      "eval_runtime": 146.2032,
      "eval_samples_per_second": 584.515,
      "eval_steps_per_second": 36.538,
      "step": 21368
    },
    {
      "epoch": 4.0059902658180455,
      "grad_norm": 1.3705604076385498,
      "learning_rate": 1.7887682515911643e-05,
      "loss": 0.0961,
      "step": 21400
    },
    {
      "epoch": 4.024709846499438,
      "grad_norm": 0.07798819988965988,
      "learning_rate": 1.7775365031823286e-05,
      "loss": 0.0688,
      "step": 21500
    },
    {
      "epoch": 4.043429427180831,
      "grad_norm": 17.61058807373047,
      "learning_rate": 1.7663047547734928e-05,
      "loss": 0.0912,
      "step": 21600
    },
    {
      "epoch": 4.0621490078622235,
      "grad_norm": 0.141038179397583,
      "learning_rate": 1.7550730063646577e-05,
      "loss": 0.0633,
      "step": 21700
    },
    {
      "epoch": 4.080868588543616,
      "grad_norm": 0.1991279572248459,
      "learning_rate": 1.743841257955822e-05,
      "loss": 0.1057,
      "step": 21800
    },
    {
      "epoch": 4.09958816922501,
      "grad_norm": 0.04023633152246475,
      "learning_rate": 1.7326095095469862e-05,
      "loss": 0.1067,
      "step": 21900
    },
    {
      "epoch": 4.1183077499064025,
      "grad_norm": 0.02593058906495571,
      "learning_rate": 1.7213777611381505e-05,
      "loss": 0.049,
      "step": 22000
    },
    {
      "epoch": 4.137027330587795,
      "grad_norm": 2.369478940963745,
      "learning_rate": 1.710146012729315e-05,
      "loss": 0.0668,
      "step": 22100
    },
    {
      "epoch": 4.155746911269188,
      "grad_norm": 0.023932961747050285,
      "learning_rate": 1.6989142643204793e-05,
      "loss": 0.0605,
      "step": 22200
    },
    {
      "epoch": 4.1744664919505805,
      "grad_norm": 0.05580536648631096,
      "learning_rate": 1.6876825159116436e-05,
      "loss": 0.0819,
      "step": 22300
    },
    {
      "epoch": 4.193186072631973,
      "grad_norm": 0.059563737362623215,
      "learning_rate": 1.676450767502808e-05,
      "loss": 0.0866,
      "step": 22400
    },
    {
      "epoch": 4.211905653313366,
      "grad_norm": 0.26484304666519165,
      "learning_rate": 1.665219019093972e-05,
      "loss": 0.1164,
      "step": 22500
    },
    {
      "epoch": 4.2306252339947585,
      "grad_norm": 0.2743914723396301,
      "learning_rate": 1.6539872706851367e-05,
      "loss": 0.1107,
      "step": 22600
    },
    {
      "epoch": 4.249344814676151,
      "grad_norm": 0.021243512630462646,
      "learning_rate": 1.6427555222763013e-05,
      "loss": 0.0753,
      "step": 22700
    },
    {
      "epoch": 4.268064395357544,
      "grad_norm": 0.11108577996492386,
      "learning_rate": 1.6315237738674655e-05,
      "loss": 0.1091,
      "step": 22800
    },
    {
      "epoch": 4.286783976038937,
      "grad_norm": 3.2382097244262695,
      "learning_rate": 1.6202920254586298e-05,
      "loss": 0.1006,
      "step": 22900
    },
    {
      "epoch": 4.305503556720329,
      "grad_norm": 0.3070531487464905,
      "learning_rate": 1.609060277049794e-05,
      "loss": 0.1119,
      "step": 23000
    },
    {
      "epoch": 4.324223137401722,
      "grad_norm": 0.14304649829864502,
      "learning_rate": 1.5978285286409586e-05,
      "loss": 0.0485,
      "step": 23100
    },
    {
      "epoch": 4.342942718083115,
      "grad_norm": 0.17168186604976654,
      "learning_rate": 1.586596780232123e-05,
      "loss": 0.119,
      "step": 23200
    },
    {
      "epoch": 4.361662298764507,
      "grad_norm": 0.04363229498267174,
      "learning_rate": 1.575365031823287e-05,
      "loss": 0.1301,
      "step": 23300
    },
    {
      "epoch": 4.380381879445901,
      "grad_norm": 0.026653826236724854,
      "learning_rate": 1.5641332834144514e-05,
      "loss": 0.0479,
      "step": 23400
    },
    {
      "epoch": 4.3991014601272935,
      "grad_norm": 0.21643081307411194,
      "learning_rate": 1.552901535005616e-05,
      "loss": 0.0652,
      "step": 23500
    },
    {
      "epoch": 4.417821040808686,
      "grad_norm": 0.05029650405049324,
      "learning_rate": 1.5416697865967802e-05,
      "loss": 0.0711,
      "step": 23600
    },
    {
      "epoch": 4.436540621490079,
      "grad_norm": 29.756872177124023,
      "learning_rate": 1.5304380381879445e-05,
      "loss": 0.0638,
      "step": 23700
    },
    {
      "epoch": 4.455260202171472,
      "grad_norm": 0.028729183599352837,
      "learning_rate": 1.519206289779109e-05,
      "loss": 0.0772,
      "step": 23800
    },
    {
      "epoch": 4.473979782852864,
      "grad_norm": 0.12295927107334137,
      "learning_rate": 1.5079745413702735e-05,
      "loss": 0.0413,
      "step": 23900
    },
    {
      "epoch": 4.492699363534257,
      "grad_norm": 0.21379400789737701,
      "learning_rate": 1.4967427929614376e-05,
      "loss": 0.0507,
      "step": 24000
    },
    {
      "epoch": 4.51141894421565,
      "grad_norm": 0.019184207543730736,
      "learning_rate": 1.4855110445526022e-05,
      "loss": 0.0601,
      "step": 24100
    },
    {
      "epoch": 4.530138524897042,
      "grad_norm": 0.028886444866657257,
      "learning_rate": 1.4742792961437664e-05,
      "loss": 0.0853,
      "step": 24200
    },
    {
      "epoch": 4.548858105578435,
      "grad_norm": 0.08777547627687454,
      "learning_rate": 1.4630475477349307e-05,
      "loss": 0.0865,
      "step": 24300
    },
    {
      "epoch": 4.567577686259828,
      "grad_norm": 0.024651117622852325,
      "learning_rate": 1.4518157993260951e-05,
      "loss": 0.1056,
      "step": 24400
    },
    {
      "epoch": 4.58629726694122,
      "grad_norm": 1.483775019645691,
      "learning_rate": 1.4405840509172594e-05,
      "loss": 0.0496,
      "step": 24500
    },
    {
      "epoch": 4.605016847622613,
      "grad_norm": 0.024101821705698967,
      "learning_rate": 1.429352302508424e-05,
      "loss": 0.0825,
      "step": 24600
    },
    {
      "epoch": 4.623736428304006,
      "grad_norm": 0.3035678267478943,
      "learning_rate": 1.4181205540995882e-05,
      "loss": 0.0987,
      "step": 24700
    },
    {
      "epoch": 4.642456008985398,
      "grad_norm": 0.04406069219112396,
      "learning_rate": 1.4068888056907526e-05,
      "loss": 0.0534,
      "step": 24800
    },
    {
      "epoch": 4.661175589666792,
      "grad_norm": 2.253465175628662,
      "learning_rate": 1.3956570572819169e-05,
      "loss": 0.0722,
      "step": 24900
    },
    {
      "epoch": 4.679895170348185,
      "grad_norm": 0.24556362628936768,
      "learning_rate": 1.3844253088730811e-05,
      "loss": 0.0704,
      "step": 25000
    },
    {
      "epoch": 4.698614751029577,
      "grad_norm": 5.828938961029053,
      "learning_rate": 1.3731935604642457e-05,
      "loss": 0.0692,
      "step": 25100
    },
    {
      "epoch": 4.71733433171097,
      "grad_norm": 0.03736940771341324,
      "learning_rate": 1.36196181205541e-05,
      "loss": 0.0708,
      "step": 25200
    },
    {
      "epoch": 4.736053912392363,
      "grad_norm": 0.047953974455595016,
      "learning_rate": 1.3507300636465744e-05,
      "loss": 0.0952,
      "step": 25300
    },
    {
      "epoch": 4.754773493073755,
      "grad_norm": 0.01980164274573326,
      "learning_rate": 1.3394983152377387e-05,
      "loss": 0.0731,
      "step": 25400
    },
    {
      "epoch": 4.773493073755148,
      "grad_norm": 0.01670980080962181,
      "learning_rate": 1.328266566828903e-05,
      "loss": 0.0425,
      "step": 25500
    },
    {
      "epoch": 4.792212654436541,
      "grad_norm": 0.07807958126068115,
      "learning_rate": 1.3170348184200673e-05,
      "loss": 0.1197,
      "step": 25600
    },
    {
      "epoch": 4.810932235117933,
      "grad_norm": 0.07368873059749603,
      "learning_rate": 1.3058030700112318e-05,
      "loss": 0.0913,
      "step": 25700
    },
    {
      "epoch": 4.829651815799326,
      "grad_norm": 0.03646762669086456,
      "learning_rate": 1.2945713216023962e-05,
      "loss": 0.0733,
      "step": 25800
    },
    {
      "epoch": 4.848371396480719,
      "grad_norm": 0.09934835135936737,
      "learning_rate": 1.2833395731935604e-05,
      "loss": 0.1029,
      "step": 25900
    },
    {
      "epoch": 4.867090977162111,
      "grad_norm": 0.09220391511917114,
      "learning_rate": 1.2721078247847249e-05,
      "loss": 0.077,
      "step": 26000
    },
    {
      "epoch": 4.885810557843504,
      "grad_norm": 4.717562198638916,
      "learning_rate": 1.2608760763758891e-05,
      "loss": 0.068,
      "step": 26100
    },
    {
      "epoch": 4.904530138524897,
      "grad_norm": 0.3094402849674225,
      "learning_rate": 1.2496443279670537e-05,
      "loss": 0.0855,
      "step": 26200
    },
    {
      "epoch": 4.923249719206289,
      "grad_norm": 16.359342575073242,
      "learning_rate": 1.238412579558218e-05,
      "loss": 0.0742,
      "step": 26300
    },
    {
      "epoch": 4.941969299887683,
      "grad_norm": 0.04630820080637932,
      "learning_rate": 1.2271808311493822e-05,
      "loss": 0.1069,
      "step": 26400
    },
    {
      "epoch": 4.960688880569075,
      "grad_norm": 0.03772610053420067,
      "learning_rate": 1.2159490827405466e-05,
      "loss": 0.0798,
      "step": 26500
    },
    {
      "epoch": 4.979408461250468,
      "grad_norm": 0.023141613230109215,
      "learning_rate": 1.2047173343317109e-05,
      "loss": 0.0479,
      "step": 26600
    },
    {
      "epoch": 4.998128041931861,
      "grad_norm": 0.024788469076156616,
      "learning_rate": 1.1934855859228755e-05,
      "loss": 0.0815,
      "step": 26700
    }
  ],
  "logging_steps": 100,
  "max_steps": 26710,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 400,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.064988112066355e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
