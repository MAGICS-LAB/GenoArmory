{
  "best_metric": 0.36595863103866577,
  "best_model_checkpoint": "output_zhihan_softmax1_Full_double/zhihan_softmax1_dnabert2_Full_double_prom_core_notata/checkpoint-1600",
  "epoch": 4.95287377564221,
  "eval_steps": 400,
  "global_step": 26800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.037678975131876416,
      "grad_norm": 14.73023796081543,
      "learning_rate": 2.986939239068711e-05,
      "loss": 0.6397,
      "step": 100
    },
    {
      "epoch": 0.07535795026375283,
      "grad_norm": 8.88039779663086,
      "learning_rate": 2.9588302101078933e-05,
      "loss": 0.4968,
      "step": 200
    },
    {
      "epoch": 0.11303692539562923,
      "grad_norm": 8.151737213134766,
      "learning_rate": 2.9304372515616128e-05,
      "loss": 0.4623,
      "step": 300
    },
    {
      "epoch": 0.15071590052750566,
      "grad_norm": 2.7984631061553955,
      "learning_rate": 2.9020442930153323e-05,
      "loss": 0.4362,
      "step": 400
    },
    {
      "epoch": 0.15071590052750566,
      "eval_accuracy": 0.8245713208969286,
      "eval_f1": 0.8242962012754627,
      "eval_loss": 0.3941026031970978,
      "eval_matthews_correlation": 0.6492398147935509,
      "eval_precision": 0.8251295990340147,
      "eval_recall": 0.8241110147811135,
      "eval_runtime": 2.3592,
      "eval_samples_per_second": 2249.503,
      "eval_steps_per_second": 70.363,
      "step": 400
    },
    {
      "epoch": 0.18839487565938207,
      "grad_norm": 4.50525426864624,
      "learning_rate": 2.8736513344690518e-05,
      "loss": 0.4068,
      "step": 500
    },
    {
      "epoch": 0.22607385079125847,
      "grad_norm": 2.4904799461364746,
      "learning_rate": 2.8452583759227712e-05,
      "loss": 0.4112,
      "step": 600
    },
    {
      "epoch": 0.26375282592313487,
      "grad_norm": 4.527894973754883,
      "learning_rate": 2.8168654173764907e-05,
      "loss": 0.4209,
      "step": 700
    },
    {
      "epoch": 0.30143180105501133,
      "grad_norm": 3.0024924278259277,
      "learning_rate": 2.7884724588302102e-05,
      "loss": 0.4124,
      "step": 800
    },
    {
      "epoch": 0.30143180105501133,
      "eval_accuracy": 0.838703599020162,
      "eval_f1": 0.8383758027501067,
      "eval_loss": 0.36796513199806213,
      "eval_matthews_correlation": 0.6778252310566104,
      "eval_precision": 0.8396863242690843,
      "eval_recall": 0.8381406690757691,
      "eval_runtime": 2.3158,
      "eval_samples_per_second": 2291.603,
      "eval_steps_per_second": 71.68,
      "step": 800
    },
    {
      "epoch": 0.33911077618688773,
      "grad_norm": 9.577704429626465,
      "learning_rate": 2.7600795002839297e-05,
      "loss": 0.4418,
      "step": 900
    },
    {
      "epoch": 0.37678975131876413,
      "grad_norm": 3.8700625896453857,
      "learning_rate": 2.731686541737649e-05,
      "loss": 0.4147,
      "step": 1000
    },
    {
      "epoch": 0.41446872645064053,
      "grad_norm": 4.442183971405029,
      "learning_rate": 2.7032935831913686e-05,
      "loss": 0.4063,
      "step": 1100
    },
    {
      "epoch": 0.45214770158251694,
      "grad_norm": 4.416652679443359,
      "learning_rate": 2.674900624645088e-05,
      "loss": 0.3987,
      "step": 1200
    },
    {
      "epoch": 0.45214770158251694,
      "eval_accuracy": 0.8347465611456567,
      "eval_f1": 0.8333720644030084,
      "eval_loss": 0.3774404525756836,
      "eval_matthews_correlation": 0.6753263291685813,
      "eval_precision": 0.8421082951997144,
      "eval_recall": 0.8332757910781372,
      "eval_runtime": 2.3308,
      "eval_samples_per_second": 2276.924,
      "eval_steps_per_second": 71.221,
      "step": 1200
    },
    {
      "epoch": 0.4898266767143934,
      "grad_norm": 9.59412956237793,
      "learning_rate": 2.6465076660988076e-05,
      "loss": 0.3891,
      "step": 1300
    },
    {
      "epoch": 0.5275056518462697,
      "grad_norm": 7.061866760253906,
      "learning_rate": 2.618114707552527e-05,
      "loss": 0.3714,
      "step": 1400
    },
    {
      "epoch": 0.5651846269781462,
      "grad_norm": 7.847437858581543,
      "learning_rate": 2.5897217490062465e-05,
      "loss": 0.3645,
      "step": 1500
    },
    {
      "epoch": 0.6028636021100227,
      "grad_norm": 12.258716583251953,
      "learning_rate": 2.5613287904599663e-05,
      "loss": 0.4001,
      "step": 1600
    },
    {
      "epoch": 0.6028636021100227,
      "eval_accuracy": 0.8324853966459393,
      "eval_f1": 0.830784945783408,
      "eval_loss": 0.36595863103866577,
      "eval_matthews_correlation": 0.6725977197444446,
      "eval_precision": 0.8418609537137824,
      "eval_recall": 0.8308272615598129,
      "eval_runtime": 2.394,
      "eval_samples_per_second": 2216.816,
      "eval_steps_per_second": 69.341,
      "step": 1600
    },
    {
      "epoch": 0.640542577241899,
      "grad_norm": 4.856974124908447,
      "learning_rate": 2.5329358319136854e-05,
      "loss": 0.3902,
      "step": 1700
    },
    {
      "epoch": 0.6782215523737755,
      "grad_norm": 4.977665424346924,
      "learning_rate": 2.504542873367405e-05,
      "loss": 0.3936,
      "step": 1800
    },
    {
      "epoch": 0.7159005275056518,
      "grad_norm": 4.947350025177002,
      "learning_rate": 2.4761499148211244e-05,
      "loss": 0.3761,
      "step": 1900
    },
    {
      "epoch": 0.7535795026375283,
      "grad_norm": 4.613524913787842,
      "learning_rate": 2.447756956274844e-05,
      "loss": 0.3854,
      "step": 2000
    },
    {
      "epoch": 0.7535795026375283,
      "eval_accuracy": 0.8436027887695496,
      "eval_f1": 0.8435763462744778,
      "eval_loss": 0.3714089095592499,
      "eval_matthews_correlation": 0.6872303555989392,
      "eval_precision": 0.8435545585083493,
      "eval_recall": 0.8436758077867033,
      "eval_runtime": 2.3687,
      "eval_samples_per_second": 2240.456,
      "eval_steps_per_second": 70.08,
      "step": 2000
    },
    {
      "epoch": 0.7912584777694047,
      "grad_norm": 5.612464427947998,
      "learning_rate": 2.4193639977285633e-05,
      "loss": 0.3538,
      "step": 2100
    },
    {
      "epoch": 0.8289374529012811,
      "grad_norm": 1.3966997861862183,
      "learning_rate": 2.3909710391822828e-05,
      "loss": 0.4028,
      "step": 2200
    },
    {
      "epoch": 0.8666164280331575,
      "grad_norm": 5.107606887817383,
      "learning_rate": 2.3625780806360023e-05,
      "loss": 0.3482,
      "step": 2300
    },
    {
      "epoch": 0.9042954031650339,
      "grad_norm": 6.301872253417969,
      "learning_rate": 2.3341851220897218e-05,
      "loss": 0.4035,
      "step": 2400
    },
    {
      "epoch": 0.9042954031650339,
      "eval_accuracy": 0.847936687394008,
      "eval_f1": 0.8476749181573711,
      "eval_loss": 0.3850664496421814,
      "eval_matthews_correlation": 0.6961487906686562,
      "eval_precision": 0.8487016837002563,
      "eval_recall": 0.8474482354134646,
      "eval_runtime": 2.3656,
      "eval_samples_per_second": 2243.377,
      "eval_steps_per_second": 70.172,
      "step": 2400
    },
    {
      "epoch": 0.9419743782969103,
      "grad_norm": 1.6045746803283691,
      "learning_rate": 2.3057921635434412e-05,
      "loss": 0.3814,
      "step": 2500
    },
    {
      "epoch": 0.9796533534287868,
      "grad_norm": 9.540255546569824,
      "learning_rate": 2.2773992049971607e-05,
      "loss": 0.4393,
      "step": 2600
    },
    {
      "epoch": 1.0173323285606632,
      "grad_norm": 3.488095998764038,
      "learning_rate": 2.2490062464508805e-05,
      "loss": 0.3575,
      "step": 2700
    },
    {
      "epoch": 1.0550113036925395,
      "grad_norm": 0.5316185355186462,
      "learning_rate": 2.2206132879045997e-05,
      "loss": 0.3438,
      "step": 2800
    },
    {
      "epoch": 1.0550113036925395,
      "eval_accuracy": 0.8486904088939137,
      "eval_f1": 0.8486873143286389,
      "eval_loss": 0.4228630065917969,
      "eval_matthews_correlation": 0.6977701472829987,
      "eval_precision": 0.848836902098647,
      "eval_recall": 0.8489332518364504,
      "eval_runtime": 2.7277,
      "eval_samples_per_second": 1945.58,
      "eval_steps_per_second": 60.857,
      "step": 2800
    },
    {
      "epoch": 1.092690278824416,
      "grad_norm": 7.507256031036377,
      "learning_rate": 2.192220329358319e-05,
      "loss": 0.34,
      "step": 2900
    },
    {
      "epoch": 1.1303692539562924,
      "grad_norm": 14.629464149475098,
      "learning_rate": 2.1638273708120386e-05,
      "loss": 0.3161,
      "step": 3000
    },
    {
      "epoch": 1.1680482290881689,
      "grad_norm": 10.35838508605957,
      "learning_rate": 2.1354344122657584e-05,
      "loss": 0.3217,
      "step": 3100
    },
    {
      "epoch": 1.2057272042200453,
      "grad_norm": 8.122064590454102,
      "learning_rate": 2.1070414537194776e-05,
      "loss": 0.3533,
      "step": 3200
    },
    {
      "epoch": 1.2057272042200453,
      "eval_accuracy": 0.8517052948935369,
      "eval_f1": 0.8516242906065901,
      "eval_loss": 0.3797646164894104,
      "eval_matthews_correlation": 0.7032704349474082,
      "eval_precision": 0.8516940853758199,
      "eval_recall": 0.851576359425123,
      "eval_runtime": 2.3423,
      "eval_samples_per_second": 2265.768,
      "eval_steps_per_second": 70.872,
      "step": 3200
    },
    {
      "epoch": 1.2434061793519215,
      "grad_norm": 7.816596508026123,
      "learning_rate": 2.078648495173197e-05,
      "loss": 0.328,
      "step": 3300
    },
    {
      "epoch": 1.281085154483798,
      "grad_norm": 6.556663513183594,
      "learning_rate": 2.0502555366269165e-05,
      "loss": 0.3654,
      "step": 3400
    },
    {
      "epoch": 1.3187641296156745,
      "grad_norm": 6.8266191482543945,
      "learning_rate": 2.021862578080636e-05,
      "loss": 0.3549,
      "step": 3500
    },
    {
      "epoch": 1.356443104747551,
      "grad_norm": 12.511305809020996,
      "learning_rate": 1.9934696195343555e-05,
      "loss": 0.3213,
      "step": 3600
    },
    {
      "epoch": 1.356443104747551,
      "eval_accuracy": 0.8468061051441492,
      "eval_f1": 0.8468059093289773,
      "eval_loss": 0.40193626284599304,
      "eval_matthews_correlation": 0.6942013925703618,
      "eval_precision": 0.8470860503771896,
      "eval_recall": 0.8471153428111822,
      "eval_runtime": 2.3495,
      "eval_samples_per_second": 2258.751,
      "eval_steps_per_second": 70.652,
      "step": 3600
    },
    {
      "epoch": 1.3941220798794274,
      "grad_norm": 2.5790770053863525,
      "learning_rate": 1.965076660988075e-05,
      "loss": 0.2981,
      "step": 3700
    },
    {
      "epoch": 1.4318010550113036,
      "grad_norm": 3.910693407058716,
      "learning_rate": 1.9366837024417948e-05,
      "loss": 0.3312,
      "step": 3800
    },
    {
      "epoch": 1.46948003014318,
      "grad_norm": 4.047670364379883,
      "learning_rate": 1.908290743895514e-05,
      "loss": 0.3092,
      "step": 3900
    },
    {
      "epoch": 1.5071590052750565,
      "grad_norm": 5.5551958084106445,
      "learning_rate": 1.8798977853492334e-05,
      "loss": 0.3365,
      "step": 4000
    },
    {
      "epoch": 1.5071590052750565,
      "eval_accuracy": 0.8413416242698323,
      "eval_f1": 0.8412164601524381,
      "eval_loss": 0.3908763527870178,
      "eval_matthews_correlation": 0.6863012753659867,
      "eval_precision": 0.8440769606568711,
      "eval_recall": 0.8422268085530809,
      "eval_runtime": 2.3193,
      "eval_samples_per_second": 2288.183,
      "eval_steps_per_second": 71.573,
      "step": 4000
    },
    {
      "epoch": 1.544837980406933,
      "grad_norm": 5.202474117279053,
      "learning_rate": 1.851504826802953e-05,
      "loss": 0.3335,
      "step": 4100
    },
    {
      "epoch": 1.5825169555388094,
      "grad_norm": 10.635783195495605,
      "learning_rate": 1.8231118682566726e-05,
      "loss": 0.3003,
      "step": 4200
    },
    {
      "epoch": 1.6201959306706857,
      "grad_norm": 5.069516658782959,
      "learning_rate": 1.7947189097103918e-05,
      "loss": 0.3308,
      "step": 4300
    },
    {
      "epoch": 1.6578749058025621,
      "grad_norm": 10.124955177307129,
      "learning_rate": 1.7663259511641113e-05,
      "loss": 0.3056,
      "step": 4400
    },
    {
      "epoch": 1.6578749058025621,
      "eval_accuracy": 0.8460523836442434,
      "eval_f1": 0.8459016132421817,
      "eval_loss": 0.375986784696579,
      "eval_matthews_correlation": 0.6920271716918306,
      "eval_precision": 0.846262759348793,
      "eval_recall": 0.8457645916503205,
      "eval_runtime": 2.3581,
      "eval_samples_per_second": 2250.544,
      "eval_steps_per_second": 70.396,
      "step": 4400
    },
    {
      "epoch": 1.6955538809344386,
      "grad_norm": 1.6954354047775269,
      "learning_rate": 1.738216922203294e-05,
      "loss": 0.3215,
      "step": 4500
    },
    {
      "epoch": 1.7332328560663148,
      "grad_norm": 9.056958198547363,
      "learning_rate": 1.709823963657013e-05,
      "loss": 0.3149,
      "step": 4600
    },
    {
      "epoch": 1.7709118311981915,
      "grad_norm": 1.3074613809585571,
      "learning_rate": 1.6814310051107325e-05,
      "loss": 0.3189,
      "step": 4700
    },
    {
      "epoch": 1.8085908063300677,
      "grad_norm": 3.713270902633667,
      "learning_rate": 1.653038046564452e-05,
      "loss": 0.3157,
      "step": 4800
    },
    {
      "epoch": 1.8085908063300677,
      "eval_accuracy": 0.8503862822687017,
      "eval_f1": 0.8503341994131797,
      "eval_loss": 0.3669488728046417,
      "eval_matthews_correlation": 0.7006705740315888,
      "eval_precision": 0.8503205046243021,
      "eval_recall": 0.8503500700310558,
      "eval_runtime": 2.328,
      "eval_samples_per_second": 2279.67,
      "eval_steps_per_second": 71.307,
      "step": 4800
    },
    {
      "epoch": 1.8462697814619442,
      "grad_norm": 6.517007350921631,
      "learning_rate": 1.6246450880181718e-05,
      "loss": 0.3275,
      "step": 4900
    },
    {
      "epoch": 1.8839487565938207,
      "grad_norm": 17.10664939880371,
      "learning_rate": 1.596252129471891e-05,
      "loss": 0.329,
      "step": 5000
    },
    {
      "epoch": 1.921627731725697,
      "grad_norm": 6.918020725250244,
      "learning_rate": 1.5678591709256104e-05,
      "loss": 0.3345,
      "step": 5100
    },
    {
      "epoch": 1.9593067068575736,
      "grad_norm": 2.942467212677002,
      "learning_rate": 1.53946621237933e-05,
      "loss": 0.3073,
      "step": 5200
    },
    {
      "epoch": 1.9593067068575736,
      "eval_accuracy": 0.8454870925193141,
      "eval_f1": 0.8453651987232771,
      "eval_loss": 0.3746213912963867,
      "eval_matthews_correlation": 0.6908467923082683,
      "eval_precision": 0.8455843851103921,
      "eval_recall": 0.8452624821938688,
      "eval_runtime": 2.3344,
      "eval_samples_per_second": 2273.38,
      "eval_steps_per_second": 71.11,
      "step": 5200
    },
    {
      "epoch": 1.9969856819894498,
      "grad_norm": 3.0511372089385986,
      "learning_rate": 1.5110732538330492e-05,
      "loss": 0.299,
      "step": 5300
    },
    {
      "epoch": 2.0346646571213265,
      "grad_norm": 7.020855903625488,
      "learning_rate": 1.4826802952867688e-05,
      "loss": 0.2909,
      "step": 5400
    },
    {
      "epoch": 2.0723436322532027,
      "grad_norm": 2.540761709213257,
      "learning_rate": 1.4542873367404885e-05,
      "loss": 0.2709,
      "step": 5500
    },
    {
      "epoch": 2.110022607385079,
      "grad_norm": 19.16358184814453,
      "learning_rate": 1.4258943781942078e-05,
      "loss": 0.2428,
      "step": 5600
    },
    {
      "epoch": 2.110022607385079,
      "eval_accuracy": 0.844168079894479,
      "eval_f1": 0.8441637419259314,
      "eval_loss": 0.47841009497642517,
      "eval_matthews_correlation": 0.6886829951093725,
      "eval_precision": 0.844288769685853,
      "eval_recall": 0.8443942334987993,
      "eval_runtime": 2.3185,
      "eval_samples_per_second": 2288.933,
      "eval_steps_per_second": 71.597,
      "step": 5600
    },
    {
      "epoch": 2.1477015825169556,
      "grad_norm": 5.8806023597717285,
      "learning_rate": 1.3975014196479274e-05,
      "loss": 0.2601,
      "step": 5700
    },
    {
      "epoch": 2.185380557648832,
      "grad_norm": 11.505572319030762,
      "learning_rate": 1.3691084611016467e-05,
      "loss": 0.238,
      "step": 5800
    },
    {
      "epoch": 2.2230595327807086,
      "grad_norm": 11.008309364318848,
      "learning_rate": 1.340999432140829e-05,
      "loss": 0.2692,
      "step": 5900
    },
    {
      "epoch": 2.260738507912585,
      "grad_norm": 4.460978031158447,
      "learning_rate": 1.3126064735945485e-05,
      "loss": 0.2503,
      "step": 6000
    },
    {
      "epoch": 2.260738507912585,
      "eval_accuracy": 0.849255700018843,
      "eval_f1": 0.8491168345183836,
      "eval_loss": 0.422406941652298,
      "eval_matthews_correlation": 0.6984231007121402,
      "eval_precision": 0.8494354337351283,
      "eval_recall": 0.8489878104191548,
      "eval_runtime": 2.3552,
      "eval_samples_per_second": 2253.343,
      "eval_steps_per_second": 70.483,
      "step": 6000
    },
    {
      "epoch": 2.298417483044461,
      "grad_norm": 3.965385913848877,
      "learning_rate": 1.284213515048268e-05,
      "loss": 0.2627,
      "step": 6100
    },
    {
      "epoch": 2.3360964581763377,
      "grad_norm": 4.910733222961426,
      "learning_rate": 1.2558205565019877e-05,
      "loss": 0.2616,
      "step": 6200
    },
    {
      "epoch": 2.373775433308214,
      "grad_norm": 3.8514294624328613,
      "learning_rate": 1.227427597955707e-05,
      "loss": 0.2467,
      "step": 6300
    },
    {
      "epoch": 2.4114544084400906,
      "grad_norm": 10.71744441986084,
      "learning_rate": 1.1990346394094266e-05,
      "loss": 0.2499,
      "step": 6400
    },
    {
      "epoch": 2.4114544084400906,
      "eval_accuracy": 0.8430374976446203,
      "eval_f1": 0.8429120023776773,
      "eval_loss": 0.4689256548881531,
      "eval_matthews_correlation": 0.685945399510682,
      "eval_precision": 0.8431372799989078,
      "eval_recall": 0.8428081984500247,
      "eval_runtime": 2.3172,
      "eval_samples_per_second": 2290.233,
      "eval_steps_per_second": 71.637,
      "step": 6400
    },
    {
      "epoch": 2.449133383571967,
      "grad_norm": 4.438326835632324,
      "learning_rate": 1.1706416808631459e-05,
      "loss": 0.247,
      "step": 6500
    },
    {
      "epoch": 2.486812358703843,
      "grad_norm": 4.722977161407471,
      "learning_rate": 1.1422487223168656e-05,
      "loss": 0.2654,
      "step": 6600
    },
    {
      "epoch": 2.5244913338357198,
      "grad_norm": 4.102432727813721,
      "learning_rate": 1.1138557637705849e-05,
      "loss": 0.2616,
      "step": 6700
    },
    {
      "epoch": 2.562170308967596,
      "grad_norm": 6.317565441131592,
      "learning_rate": 1.0857467348097672e-05,
      "loss": 0.2116,
      "step": 6800
    },
    {
      "epoch": 2.562170308967596,
      "eval_accuracy": 0.8437912191445262,
      "eval_f1": 0.8437750443134209,
      "eval_loss": 0.4508095383644104,
      "eval_matthews_correlation": 0.6877059794619067,
      "eval_precision": 0.843785736806674,
      "eval_recall": 0.8439202558115546,
      "eval_runtime": 2.2952,
      "eval_samples_per_second": 2312.175,
      "eval_steps_per_second": 72.324,
      "step": 6800
    },
    {
      "epoch": 2.5998492840994727,
      "grad_norm": 5.339010238647461,
      "learning_rate": 1.0573537762634866e-05,
      "loss": 0.2795,
      "step": 6900
    },
    {
      "epoch": 2.637528259231349,
      "grad_norm": 1.574912667274475,
      "learning_rate": 1.0289608177172061e-05,
      "loss": 0.2668,
      "step": 7000
    },
    {
      "epoch": 2.675207234363225,
      "grad_norm": 8.849992752075195,
      "learning_rate": 1.0005678591709258e-05,
      "loss": 0.2356,
      "step": 7100
    },
    {
      "epoch": 2.712886209495102,
      "grad_norm": 3.47417950630188,
      "learning_rate": 9.72174900624645e-06,
      "loss": 0.2754,
      "step": 7200
    },
    {
      "epoch": 2.712886209495102,
      "eval_accuracy": 0.845863953269267,
      "eval_f1": 0.8456999849294387,
      "eval_loss": 0.44236063957214355,
      "eval_matthews_correlation": 0.6916782465690348,
      "eval_precision": 0.8461285081623364,
      "eval_recall": 0.8455499803503854,
      "eval_runtime": 2.3257,
      "eval_samples_per_second": 2281.942,
      "eval_steps_per_second": 71.378,
      "step": 7200
    },
    {
      "epoch": 2.750565184626978,
      "grad_norm": 10.417169570922852,
      "learning_rate": 9.437819420783647e-06,
      "loss": 0.2786,
      "step": 7300
    },
    {
      "epoch": 2.7882441597588548,
      "grad_norm": 5.469795227050781,
      "learning_rate": 9.15388983532084e-06,
      "loss": 0.2541,
      "step": 7400
    },
    {
      "epoch": 2.825923134890731,
      "grad_norm": 1.446331262588501,
      "learning_rate": 8.869960249858037e-06,
      "loss": 0.268,
      "step": 7500
    },
    {
      "epoch": 2.8636021100226072,
      "grad_norm": 73.17459106445312,
      "learning_rate": 8.58603066439523e-06,
      "loss": 0.2511,
      "step": 7600
    },
    {
      "epoch": 2.8636021100226072,
      "eval_accuracy": 0.8434143583945732,
      "eval_f1": 0.8433564935801842,
      "eval_loss": 0.43400317430496216,
      "eval_matthews_correlation": 0.6867135265179438,
      "eval_precision": 0.8433492995493999,
      "eval_recall": 0.8433642271307897,
      "eval_runtime": 2.3048,
      "eval_samples_per_second": 2302.628,
      "eval_steps_per_second": 72.025,
      "step": 7600
    },
    {
      "epoch": 2.901281085154484,
      "grad_norm": 11.760883331298828,
      "learning_rate": 8.302101078932424e-06,
      "loss": 0.2494,
      "step": 7700
    },
    {
      "epoch": 2.93896006028636,
      "grad_norm": 8.499065399169922,
      "learning_rate": 8.01817149346962e-06,
      "loss": 0.248,
      "step": 7800
    },
    {
      "epoch": 2.976639035418237,
      "grad_norm": 2.4190242290496826,
      "learning_rate": 7.734241908006814e-06,
      "loss": 0.2361,
      "step": 7900
    },
    {
      "epoch": 3.014318010550113,
      "grad_norm": 3.136307954788208,
      "learning_rate": 7.4503123225440095e-06,
      "loss": 0.2162,
      "step": 8000
    },
    {
      "epoch": 3.014318010550113,
      "eval_accuracy": 0.8451102317693612,
      "eval_f1": 0.8450605827181487,
      "eval_loss": 0.48274388909339905,
      "eval_matthews_correlation": 0.6901271698978645,
      "eval_precision": 0.8450402997134925,
      "eval_recall": 0.845086871755789,
      "eval_runtime": 2.3013,
      "eval_samples_per_second": 2306.096,
      "eval_steps_per_second": 72.133,
      "step": 8000
    },
    {
      "epoch": 3.0519969856819893,
      "grad_norm": 4.86250114440918,
      "learning_rate": 7.166382737081204e-06,
      "loss": 0.1959,
      "step": 8100
    },
    {
      "epoch": 3.089675960813866,
      "grad_norm": 5.24408483505249,
      "learning_rate": 6.882453151618399e-06,
      "loss": 0.1933,
      "step": 8200
    },
    {
      "epoch": 3.127354935945742,
      "grad_norm": 1.0769575834274292,
      "learning_rate": 6.598523566155594e-06,
      "loss": 0.1822,
      "step": 8300
    },
    {
      "epoch": 3.165033911077619,
      "grad_norm": 75.17521667480469,
      "learning_rate": 6.314593980692788e-06,
      "loss": 0.2017,
      "step": 8400
    },
    {
      "epoch": 3.165033911077619,
      "eval_accuracy": 0.8390804597701149,
      "eval_f1": 0.8389568995659256,
      "eval_loss": 0.5614190697669983,
      "eval_matthews_correlation": 0.6817109554948069,
      "eval_precision": 0.8417560291273202,
      "eval_recall": 0.8399572993842552,
      "eval_runtime": 2.3073,
      "eval_samples_per_second": 2300.095,
      "eval_steps_per_second": 71.946,
      "step": 8400
    },
    {
      "epoch": 3.202712886209495,
      "grad_norm": 10.428732872009277,
      "learning_rate": 6.030664395229982e-06,
      "loss": 0.2155,
      "step": 8500
    },
    {
      "epoch": 3.2403918613413714,
      "grad_norm": 2.065399408340454,
      "learning_rate": 5.746734809767178e-06,
      "loss": 0.2081,
      "step": 8600
    },
    {
      "epoch": 3.278070836473248,
      "grad_norm": 11.844659805297852,
      "learning_rate": 5.462805224304373e-06,
      "loss": 0.1919,
      "step": 8700
    },
    {
      "epoch": 3.3157498116051243,
      "grad_norm": 3.0873281955718994,
      "learning_rate": 5.181714934696195e-06,
      "loss": 0.1994,
      "step": 8800
    },
    {
      "epoch": 3.3157498116051243,
      "eval_accuracy": 0.8398341812700207,
      "eval_f1": 0.8398169767052739,
      "eval_loss": 0.5276214480400085,
      "eval_matthews_correlation": 0.6797830883648854,
      "eval_precision": 0.839825162589248,
      "eval_recall": 0.8399579387426463,
      "eval_runtime": 2.323,
      "eval_samples_per_second": 2284.522,
      "eval_steps_per_second": 71.459,
      "step": 8800
    },
    {
      "epoch": 3.353428786737001,
      "grad_norm": 6.01013708114624,
      "learning_rate": 4.89778534923339e-06,
      "loss": 0.1659,
      "step": 8900
    },
    {
      "epoch": 3.391107761868877,
      "grad_norm": 11.859792709350586,
      "learning_rate": 4.6138557637705846e-06,
      "loss": 0.2301,
      "step": 9000
    },
    {
      "epoch": 3.4287867370007534,
      "grad_norm": 22.04165267944336,
      "learning_rate": 4.329926178307779e-06,
      "loss": 0.1992,
      "step": 9100
    },
    {
      "epoch": 3.46646571213263,
      "grad_norm": 0.3672150671482086,
      "learning_rate": 4.045996592844974e-06,
      "loss": 0.2011,
      "step": 9200
    },
    {
      "epoch": 3.46646571213263,
      "eval_accuracy": 0.8385151686451856,
      "eval_f1": 0.8384916800700621,
      "eval_loss": 0.5344408750534058,
      "eval_matthews_correlation": 0.6786861420663255,
      "eval_precision": 0.8396041118521691,
      "eval_recall": 0.8390822308663477,
      "eval_runtime": 2.312,
      "eval_samples_per_second": 2295.392,
      "eval_steps_per_second": 71.799,
      "step": 9200
    },
    {
      "epoch": 3.5041446872645063,
      "grad_norm": 0.4069391191005707,
      "learning_rate": 3.762067007382169e-06,
      "loss": 0.1706,
      "step": 9300
    },
    {
      "epoch": 3.541823662396383,
      "grad_norm": 1.8335291147232056,
      "learning_rate": 3.478137421919364e-06,
      "loss": 0.2151,
      "step": 9400
    },
    {
      "epoch": 3.5795026375282593,
      "grad_norm": 12.160447120666504,
      "learning_rate": 3.1942078364565587e-06,
      "loss": 0.2057,
      "step": 9500
    },
    {
      "epoch": 3.6171816126601355,
      "grad_norm": 30.540857315063477,
      "learning_rate": 2.910278250993754e-06,
      "loss": 0.2087,
      "step": 9600
    },
    {
      "epoch": 3.6171816126601355,
      "eval_accuracy": 0.8390804597701149,
      "eval_f1": 0.8390783971303961,
      "eval_loss": 0.5450764894485474,
      "eval_matthews_correlation": 0.6790734894910012,
      "eval_precision": 0.8395935872199205,
      "eval_recall": 0.8394799117855916,
      "eval_runtime": 2.3031,
      "eval_samples_per_second": 2304.262,
      "eval_steps_per_second": 72.076,
      "step": 9600
    },
    {
      "epoch": 3.654860587792012,
      "grad_norm": 0.8601409792900085,
      "learning_rate": 2.6263486655309486e-06,
      "loss": 0.2191,
      "step": 9700
    },
    {
      "epoch": 3.6925395629238884,
      "grad_norm": 1.5607507228851318,
      "learning_rate": 2.3424190800681434e-06,
      "loss": 0.1944,
      "step": 9800
    },
    {
      "epoch": 3.730218538055765,
      "grad_norm": 3.126885175704956,
      "learning_rate": 2.061328790459966e-06,
      "loss": 0.1964,
      "step": 9900
    },
    {
      "epoch": 3.7678975131876413,
      "grad_norm": 7.526996612548828,
      "learning_rate": 1.7773992049971608e-06,
      "loss": 0.1914,
      "step": 10000
    },
    {
      "epoch": 3.7678975131876413,
      "eval_accuracy": 0.8360655737704918,
      "eval_f1": 0.8360638915834279,
      "eval_loss": 0.5296939015388489,
      "eval_matthews_correlation": 0.6725876839033406,
      "eval_precision": 0.8362581078274645,
      "eval_recall": 0.8363295798733388,
      "eval_runtime": 2.3474,
      "eval_samples_per_second": 2260.817,
      "eval_steps_per_second": 70.717,
      "step": 10000
    },
    {
      "epoch": 3.8055764883195176,
      "grad_norm": 28.27821159362793,
      "learning_rate": 1.4934696195343556e-06,
      "loss": 0.2128,
      "step": 10100
    },
    {
      "epoch": 3.8432554634513942,
      "grad_norm": 6.14760160446167,
      "learning_rate": 1.2095400340715501e-06,
      "loss": 0.1862,
      "step": 10200
    },
    {
      "epoch": 3.8809344385832705,
      "grad_norm": 0.5237334370613098,
      "learning_rate": 9.25610448608745e-07,
      "loss": 0.1975,
      "step": 10300
    },
    {
      "epoch": 3.918613413715147,
      "grad_norm": 8.713967323303223,
      "learning_rate": 6.416808631459398e-07,
      "loss": 0.2066,
      "step": 10400
    },
    {
      "epoch": 3.918613413715147,
      "eval_accuracy": 0.8349349915206331,
      "eval_f1": 0.8349349387734233,
      "eval_loss": 0.5359970331192017,
      "eval_matthews_correlation": 0.6704869632848577,
      "eval_precision": 0.8352361942951252,
      "eval_recall": 0.8352507691481446,
      "eval_runtime": 2.3654,
      "eval_samples_per_second": 2243.586,
      "eval_steps_per_second": 70.178,
      "step": 10400
    },
    {
      "epoch": 3.9562923888470234,
      "grad_norm": 18.251142501831055,
      "learning_rate": 3.577512776831346e-07,
      "loss": 0.1985,
      "step": 10500
    },
    {
      "epoch": 3.9939713639788996,
      "grad_norm": 0.8355695605278015,
      "learning_rate": 7.382169222032936e-08,
      "loss": 0.2147,
      "step": 10600
    },
    {
      "epoch": 4.0,
      "step": 10616,
      "total_flos": 2321400599150592.0,
      "train_loss": 0.2985010257140981,
      "train_runtime": 655.7011,
      "train_samples_per_second": 258.972,
      "train_steps_per_second": 16.19
    },
    {
      "epoch": 1.9774533357974495,
      "grad_norm": 5.482178688049316,
      "learning_rate": 2.990685640362225e-05,
      "loss": 0.7013,
      "step": 10700
    },
    {
      "epoch": 1.995934208094622,
      "grad_norm": 6.6019134521484375,
      "learning_rate": 2.9795971169839218e-05,
      "loss": 0.4776,
      "step": 10800
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.417794926297306,
      "eval_f1": 0.1402693008403979,
      "eval_loss": 0.45993146300315857,
      "eval_matthews_correlation": 0.2824598142281147,
      "eval_precision": 0.10513430689573038,
      "eval_recall": 0.21302646901856234,
      "eval_runtime": 475.4701,
      "eval_samples_per_second": 182.06,
      "eval_steps_per_second": 11.38,
      "step": 10822
    },
    {
      "epoch": 2.0144150803917946,
      "grad_norm": 4.098578453063965,
      "learning_rate": 2.9685085936056185e-05,
      "loss": 0.469,
      "step": 10900
    },
    {
      "epoch": 2.0328959526889667,
      "grad_norm": 4.914305686950684,
      "learning_rate": 2.957420070227315e-05,
      "loss": 0.433,
      "step": 11000
    },
    {
      "epoch": 2.0513768249861393,
      "grad_norm": 9.70093822479248,
      "learning_rate": 2.9463315468490116e-05,
      "loss": 0.4767,
      "step": 11100
    },
    {
      "epoch": 2.069857697283312,
      "grad_norm": 5.318058490753174,
      "learning_rate": 2.935243023470708e-05,
      "loss": 0.4504,
      "step": 11200
    },
    {
      "epoch": 2.0883385695804844,
      "grad_norm": 2.6993424892425537,
      "learning_rate": 2.9241545000924046e-05,
      "loss": 0.4695,
      "step": 11300
    },
    {
      "epoch": 2.1068194418776565,
      "grad_norm": 7.111072063446045,
      "learning_rate": 2.913065976714101e-05,
      "loss": 0.4101,
      "step": 11400
    },
    {
      "epoch": 2.125300314174829,
      "grad_norm": 7.392039775848389,
      "learning_rate": 2.9019774533357977e-05,
      "loss": 0.445,
      "step": 11500
    },
    {
      "epoch": 2.1437811864720016,
      "grad_norm": 6.490549087524414,
      "learning_rate": 2.890888929957494e-05,
      "loss": 0.3839,
      "step": 11600
    },
    {
      "epoch": 2.162262058769174,
      "grad_norm": 8.32364559173584,
      "learning_rate": 2.8798004065791907e-05,
      "loss": 0.5023,
      "step": 11700
    },
    {
      "epoch": 2.180742931066346,
      "grad_norm": 4.681440353393555,
      "learning_rate": 2.868711883200887e-05,
      "loss": 0.417,
      "step": 11800
    },
    {
      "epoch": 2.1992238033635187,
      "grad_norm": 6.002615451812744,
      "learning_rate": 2.8576233598225838e-05,
      "loss": 0.4244,
      "step": 11900
    },
    {
      "epoch": 2.2177046756606913,
      "grad_norm": 2.401776075363159,
      "learning_rate": 2.84653483644428e-05,
      "loss": 0.415,
      "step": 12000
    },
    {
      "epoch": 2.236185547957864,
      "grad_norm": 6.667256832122803,
      "learning_rate": 2.835446313065977e-05,
      "loss": 0.4133,
      "step": 12100
    },
    {
      "epoch": 2.254666420255036,
      "grad_norm": 3.815403699874878,
      "learning_rate": 2.8243577896876732e-05,
      "loss": 0.4179,
      "step": 12200
    },
    {
      "epoch": 2.2731472925522085,
      "grad_norm": 3.750049352645874,
      "learning_rate": 2.81326926630937e-05,
      "loss": 0.4141,
      "step": 12300
    },
    {
      "epoch": 2.291628164849381,
      "grad_norm": 3.436716079711914,
      "learning_rate": 2.8021807429310663e-05,
      "loss": 0.4204,
      "step": 12400
    },
    {
      "epoch": 2.310109037146553,
      "grad_norm": 15.010655403137207,
      "learning_rate": 2.791092219552763e-05,
      "loss": 0.3895,
      "step": 12500
    },
    {
      "epoch": 2.3285899094437257,
      "grad_norm": 26.17237663269043,
      "learning_rate": 2.7800036961744597e-05,
      "loss": 0.4407,
      "step": 12600
    },
    {
      "epoch": 2.3470707817408982,
      "grad_norm": 4.360198974609375,
      "learning_rate": 2.768915172796156e-05,
      "loss": 0.4586,
      "step": 12700
    },
    {
      "epoch": 2.3655516540380708,
      "grad_norm": 2.6065359115600586,
      "learning_rate": 2.7578266494178527e-05,
      "loss": 0.4458,
      "step": 12800
    },
    {
      "epoch": 2.384032526335243,
      "grad_norm": 1.1781998872756958,
      "learning_rate": 2.746738126039549e-05,
      "loss": 0.3796,
      "step": 12900
    },
    {
      "epoch": 2.4025133986324154,
      "grad_norm": 7.713170051574707,
      "learning_rate": 2.7356496026612458e-05,
      "loss": 0.413,
      "step": 13000
    },
    {
      "epoch": 2.420994270929588,
      "grad_norm": 17.973169326782227,
      "learning_rate": 2.724561079282942e-05,
      "loss": 0.4557,
      "step": 13100
    },
    {
      "epoch": 2.43947514322676,
      "grad_norm": 2.5604498386383057,
      "learning_rate": 2.7134725559046388e-05,
      "loss": 0.4107,
      "step": 13200
    },
    {
      "epoch": 2.4579560155239326,
      "grad_norm": 61.47383499145508,
      "learning_rate": 2.7023840325263352e-05,
      "loss": 0.4591,
      "step": 13300
    },
    {
      "epoch": 2.476436887821105,
      "grad_norm": 3.734501600265503,
      "learning_rate": 2.691295509148032e-05,
      "loss": 0.4354,
      "step": 13400
    },
    {
      "epoch": 2.4949177601182777,
      "grad_norm": 10.140778541564941,
      "learning_rate": 2.6802069857697282e-05,
      "loss": 0.4785,
      "step": 13500
    },
    {
      "epoch": 2.5133986324154503,
      "grad_norm": 7.324227333068848,
      "learning_rate": 2.669118462391425e-05,
      "loss": 0.3896,
      "step": 13600
    },
    {
      "epoch": 2.5318795047126224,
      "grad_norm": 3.1214523315429688,
      "learning_rate": 2.6580299390131213e-05,
      "loss": 0.4389,
      "step": 13700
    },
    {
      "epoch": 2.550360377009795,
      "grad_norm": 11.777928352355957,
      "learning_rate": 2.646941415634818e-05,
      "loss": 0.403,
      "step": 13800
    },
    {
      "epoch": 2.5688412493069674,
      "grad_norm": 9.03775405883789,
      "learning_rate": 2.6358528922565144e-05,
      "loss": 0.3809,
      "step": 13900
    },
    {
      "epoch": 2.5873221216041395,
      "grad_norm": 4.356823921203613,
      "learning_rate": 2.624764368878211e-05,
      "loss": 0.4569,
      "step": 14000
    },
    {
      "epoch": 2.605802993901312,
      "grad_norm": 11.652044296264648,
      "learning_rate": 2.6136758454999074e-05,
      "loss": 0.4089,
      "step": 14100
    },
    {
      "epoch": 2.6242838661984846,
      "grad_norm": 6.116857528686523,
      "learning_rate": 2.602587322121604e-05,
      "loss": 0.3848,
      "step": 14200
    },
    {
      "epoch": 2.642764738495657,
      "grad_norm": 7.366816520690918,
      "learning_rate": 2.5914987987433008e-05,
      "loss": 0.3791,
      "step": 14300
    },
    {
      "epoch": 2.6612456107928293,
      "grad_norm": 5.925858020782471,
      "learning_rate": 2.5804102753649972e-05,
      "loss": 0.365,
      "step": 14400
    },
    {
      "epoch": 2.679726483090002,
      "grad_norm": 2.5240561962127686,
      "learning_rate": 2.569321751986694e-05,
      "loss": 0.3772,
      "step": 14500
    },
    {
      "epoch": 2.6982073553871744,
      "grad_norm": 10.318095207214355,
      "learning_rate": 2.5582332286083902e-05,
      "loss": 0.3758,
      "step": 14600
    },
    {
      "epoch": 2.7166882276843465,
      "grad_norm": 7.32332706451416,
      "learning_rate": 2.547144705230087e-05,
      "loss": 0.3684,
      "step": 14700
    },
    {
      "epoch": 2.735169099981519,
      "grad_norm": 4.1497273445129395,
      "learning_rate": 2.5360561818517833e-05,
      "loss": 0.3585,
      "step": 14800
    },
    {
      "epoch": 2.7536499722786916,
      "grad_norm": 2.8001620769500732,
      "learning_rate": 2.52496765847348e-05,
      "loss": 0.4006,
      "step": 14900
    },
    {
      "epoch": 2.772130844575864,
      "grad_norm": 18.530872344970703,
      "learning_rate": 2.5138791350951763e-05,
      "loss": 0.4076,
      "step": 15000
    },
    {
      "epoch": 2.7906117168730367,
      "grad_norm": 5.196608543395996,
      "learning_rate": 2.502790611716873e-05,
      "loss": 0.3685,
      "step": 15100
    },
    {
      "epoch": 2.8090925891702088,
      "grad_norm": 5.000078201293945,
      "learning_rate": 2.4917020883385694e-05,
      "loss": 0.4097,
      "step": 15200
    },
    {
      "epoch": 2.8275734614673813,
      "grad_norm": 7.1598381996154785,
      "learning_rate": 2.480613564960266e-05,
      "loss": 0.3934,
      "step": 15300
    },
    {
      "epoch": 2.8460543337645534,
      "grad_norm": 2.880019187927246,
      "learning_rate": 2.4695250415819625e-05,
      "loss": 0.374,
      "step": 15400
    },
    {
      "epoch": 2.864535206061726,
      "grad_norm": 9.214290618896484,
      "learning_rate": 2.458436518203659e-05,
      "loss": 0.3882,
      "step": 15500
    },
    {
      "epoch": 2.8830160783588985,
      "grad_norm": 3.838944435119629,
      "learning_rate": 2.447347994825356e-05,
      "loss": 0.3403,
      "step": 15600
    },
    {
      "epoch": 2.901496950656071,
      "grad_norm": 3.529494285583496,
      "learning_rate": 2.4362594714470526e-05,
      "loss": 0.4019,
      "step": 15700
    },
    {
      "epoch": 2.9199778229532436,
      "grad_norm": 6.861685276031494,
      "learning_rate": 2.425170948068749e-05,
      "loss": 0.3354,
      "step": 15800
    },
    {
      "epoch": 2.9384586952504157,
      "grad_norm": 5.04716157913208,
      "learning_rate": 2.4140824246904456e-05,
      "loss": 0.3531,
      "step": 15900
    },
    {
      "epoch": 2.9569395675475882,
      "grad_norm": 5.238558769226074,
      "learning_rate": 2.402993901312142e-05,
      "loss": 0.3635,
      "step": 16000
    },
    {
      "epoch": 2.975420439844761,
      "grad_norm": 8.189641952514648,
      "learning_rate": 2.3919053779338387e-05,
      "loss": 0.3551,
      "step": 16100
    },
    {
      "epoch": 2.993901312141933,
      "grad_norm": 15.300286293029785,
      "learning_rate": 2.3808168545555354e-05,
      "loss": 0.3513,
      "step": 16200
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.45476179474146294,
      "eval_f1": 0.15265641019854273,
      "eval_loss": 0.28062009811401367,
      "eval_matthews_correlation": 0.3408765156065332,
      "eval_precision": 0.11397880600566378,
      "eval_recall": 0.231805188795433,
      "eval_runtime": 124.4571,
      "eval_samples_per_second": 695.533,
      "eval_steps_per_second": 43.477,
      "step": 16233
    },
    {
      "epoch": 3.0123821844391054,
      "grad_norm": 6.77324914932251,
      "learning_rate": 2.3697283311772317e-05,
      "loss": 0.3451,
      "step": 16300
    },
    {
      "epoch": 3.030863056736278,
      "grad_norm": 16.0449275970459,
      "learning_rate": 2.3586398077989284e-05,
      "loss": 0.289,
      "step": 16400
    },
    {
      "epoch": 3.0493439290334505,
      "grad_norm": 8.349220275878906,
      "learning_rate": 2.3475512844206248e-05,
      "loss": 0.2651,
      "step": 16500
    },
    {
      "epoch": 3.0678248013306226,
      "grad_norm": 0.37941408157348633,
      "learning_rate": 2.3364627610423215e-05,
      "loss": 0.2496,
      "step": 16600
    },
    {
      "epoch": 3.086305673627795,
      "grad_norm": 6.147329807281494,
      "learning_rate": 2.325374237664018e-05,
      "loss": 0.3216,
      "step": 16700
    },
    {
      "epoch": 3.1047865459249677,
      "grad_norm": 13.324562072753906,
      "learning_rate": 2.3142857142857145e-05,
      "loss": 0.2873,
      "step": 16800
    },
    {
      "epoch": 3.1232674182221403,
      "grad_norm": 3.220283269882202,
      "learning_rate": 2.303197190907411e-05,
      "loss": 0.2948,
      "step": 16900
    },
    {
      "epoch": 3.1417482905193124,
      "grad_norm": 18.07084083557129,
      "learning_rate": 2.2921086675291076e-05,
      "loss": 0.3233,
      "step": 17000
    },
    {
      "epoch": 3.160229162816485,
      "grad_norm": 8.109517097473145,
      "learning_rate": 2.281020144150804e-05,
      "loss": 0.2723,
      "step": 17100
    },
    {
      "epoch": 3.1787100351136575,
      "grad_norm": 11.616684913635254,
      "learning_rate": 2.2699316207725007e-05,
      "loss": 0.2959,
      "step": 17200
    },
    {
      "epoch": 3.19719090741083,
      "grad_norm": 1.8791489601135254,
      "learning_rate": 2.258843097394197e-05,
      "loss": 0.2264,
      "step": 17300
    },
    {
      "epoch": 3.215671779708002,
      "grad_norm": 1.6094262599945068,
      "learning_rate": 2.2477545740158937e-05,
      "loss": 0.3439,
      "step": 17400
    },
    {
      "epoch": 3.2341526520051747,
      "grad_norm": 3.0691661834716797,
      "learning_rate": 2.23666605063759e-05,
      "loss": 0.257,
      "step": 17500
    },
    {
      "epoch": 3.252633524302347,
      "grad_norm": 7.9088592529296875,
      "learning_rate": 2.2255775272592868e-05,
      "loss": 0.3149,
      "step": 17600
    },
    {
      "epoch": 3.2711143965995193,
      "grad_norm": 4.1863884925842285,
      "learning_rate": 2.2144890038809835e-05,
      "loss": 0.3445,
      "step": 17700
    },
    {
      "epoch": 3.289595268896692,
      "grad_norm": 18.81433868408203,
      "learning_rate": 2.2034004805026798e-05,
      "loss": 0.2245,
      "step": 17800
    },
    {
      "epoch": 3.3080761411938644,
      "grad_norm": 0.3337002694606781,
      "learning_rate": 2.1923119571243765e-05,
      "loss": 0.254,
      "step": 17900
    },
    {
      "epoch": 3.326557013491037,
      "grad_norm": 13.847916603088379,
      "learning_rate": 2.181223433746073e-05,
      "loss": 0.3008,
      "step": 18000
    },
    {
      "epoch": 3.345037885788209,
      "grad_norm": 4.169466972351074,
      "learning_rate": 2.1701349103677696e-05,
      "loss": 0.2718,
      "step": 18100
    },
    {
      "epoch": 3.3635187580853816,
      "grad_norm": 6.705589771270752,
      "learning_rate": 2.159046386989466e-05,
      "loss": 0.3268,
      "step": 18200
    },
    {
      "epoch": 3.381999630382554,
      "grad_norm": 21.5168399810791,
      "learning_rate": 2.1479578636111626e-05,
      "loss": 0.2768,
      "step": 18300
    },
    {
      "epoch": 3.4004805026797262,
      "grad_norm": 15.598286628723145,
      "learning_rate": 2.136869340232859e-05,
      "loss": 0.2481,
      "step": 18400
    },
    {
      "epoch": 3.418961374976899,
      "grad_norm": 3.7976412773132324,
      "learning_rate": 2.1257808168545557e-05,
      "loss": 0.2496,
      "step": 18500
    },
    {
      "epoch": 3.4374422472740713,
      "grad_norm": 0.7818374633789062,
      "learning_rate": 2.114692293476252e-05,
      "loss": 0.2377,
      "step": 18600
    },
    {
      "epoch": 3.455923119571244,
      "grad_norm": 24.750896453857422,
      "learning_rate": 2.1036037700979488e-05,
      "loss": 0.2791,
      "step": 18700
    },
    {
      "epoch": 3.4744039918684164,
      "grad_norm": 3.9840941429138184,
      "learning_rate": 2.092515246719645e-05,
      "loss": 0.2574,
      "step": 18800
    },
    {
      "epoch": 3.4928848641655885,
      "grad_norm": 0.500284731388092,
      "learning_rate": 2.0814267233413418e-05,
      "loss": 0.2113,
      "step": 18900
    },
    {
      "epoch": 3.511365736462761,
      "grad_norm": 3.401536226272583,
      "learning_rate": 2.0703381999630382e-05,
      "loss": 0.2723,
      "step": 19000
    },
    {
      "epoch": 3.5298466087599336,
      "grad_norm": 24.9200496673584,
      "learning_rate": 2.059249676584735e-05,
      "loss": 0.2786,
      "step": 19100
    },
    {
      "epoch": 3.5483274810571057,
      "grad_norm": 8.476852416992188,
      "learning_rate": 2.0481611532064312e-05,
      "loss": 0.3219,
      "step": 19200
    },
    {
      "epoch": 3.5668083533542783,
      "grad_norm": 3.3816776275634766,
      "learning_rate": 2.037072629828128e-05,
      "loss": 0.3158,
      "step": 19300
    },
    {
      "epoch": 3.585289225651451,
      "grad_norm": 31.393850326538086,
      "learning_rate": 2.0259841064498246e-05,
      "loss": 0.2745,
      "step": 19400
    },
    {
      "epoch": 3.6037700979486234,
      "grad_norm": 5.821540355682373,
      "learning_rate": 2.014895583071521e-05,
      "loss": 0.2375,
      "step": 19500
    },
    {
      "epoch": 3.6222509702457955,
      "grad_norm": 62.42961120605469,
      "learning_rate": 2.0038070596932177e-05,
      "loss": 0.2421,
      "step": 19600
    },
    {
      "epoch": 3.640731842542968,
      "grad_norm": 2.8598763942718506,
      "learning_rate": 1.992718536314914e-05,
      "loss": 0.2717,
      "step": 19700
    },
    {
      "epoch": 3.6592127148401405,
      "grad_norm": 16.08064842224121,
      "learning_rate": 1.9816300129366107e-05,
      "loss": 0.2741,
      "step": 19800
    },
    {
      "epoch": 3.6776935871373126,
      "grad_norm": 0.3366799056529999,
      "learning_rate": 1.970541489558307e-05,
      "loss": 0.2608,
      "step": 19900
    },
    {
      "epoch": 3.696174459434485,
      "grad_norm": 1.1546175479888916,
      "learning_rate": 1.9594529661800038e-05,
      "loss": 0.2469,
      "step": 20000
    },
    {
      "epoch": 3.7146553317316577,
      "grad_norm": 1.9315098524093628,
      "learning_rate": 1.9483644428017e-05,
      "loss": 0.2739,
      "step": 20100
    },
    {
      "epoch": 3.7331362040288303,
      "grad_norm": 19.679956436157227,
      "learning_rate": 1.937275919423397e-05,
      "loss": 0.2848,
      "step": 20200
    },
    {
      "epoch": 3.751617076326003,
      "grad_norm": 18.814315795898438,
      "learning_rate": 1.9261873960450932e-05,
      "loss": 0.309,
      "step": 20300
    },
    {
      "epoch": 3.770097948623175,
      "grad_norm": 49.561241149902344,
      "learning_rate": 1.91509887266679e-05,
      "loss": 0.2549,
      "step": 20400
    },
    {
      "epoch": 3.7885788209203475,
      "grad_norm": 20.7998104095459,
      "learning_rate": 1.9040103492884863e-05,
      "loss": 0.2365,
      "step": 20500
    },
    {
      "epoch": 3.80705969321752,
      "grad_norm": 0.3863603472709656,
      "learning_rate": 1.892921825910183e-05,
      "loss": 0.2527,
      "step": 20600
    },
    {
      "epoch": 3.825540565514692,
      "grad_norm": 0.19869090616703033,
      "learning_rate": 1.8818333025318793e-05,
      "loss": 0.2513,
      "step": 20700
    },
    {
      "epoch": 3.8440214378118647,
      "grad_norm": 0.5115659236907959,
      "learning_rate": 1.870744779153576e-05,
      "loss": 0.2444,
      "step": 20800
    },
    {
      "epoch": 3.862502310109037,
      "grad_norm": 21.59470558166504,
      "learning_rate": 1.8596562557752724e-05,
      "loss": 0.2625,
      "step": 20900
    },
    {
      "epoch": 3.8809831824062098,
      "grad_norm": 0.5708471536636353,
      "learning_rate": 1.848567732396969e-05,
      "loss": 0.2403,
      "step": 21000
    },
    {
      "epoch": 3.899464054703382,
      "grad_norm": 32.006046295166016,
      "learning_rate": 1.8374792090186658e-05,
      "loss": 0.2161,
      "step": 21100
    },
    {
      "epoch": 3.9179449270005544,
      "grad_norm": 32.2690544128418,
      "learning_rate": 1.826390685640362e-05,
      "loss": 0.251,
      "step": 21200
    },
    {
      "epoch": 3.936425799297727,
      "grad_norm": 8.108200073242188,
      "learning_rate": 1.815302162262059e-05,
      "loss": 0.2637,
      "step": 21300
    },
    {
      "epoch": 3.954906671594899,
      "grad_norm": 0.2295890599489212,
      "learning_rate": 1.8042136388837552e-05,
      "loss": 0.2003,
      "step": 21400
    },
    {
      "epoch": 3.9733875438920716,
      "grad_norm": 0.46579891443252563,
      "learning_rate": 1.793125115505452e-05,
      "loss": 0.3189,
      "step": 21500
    },
    {
      "epoch": 3.991868416189244,
      "grad_norm": 0.3852883577346802,
      "learning_rate": 1.7820365921271483e-05,
      "loss": 0.2579,
      "step": 21600
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.4796566702093249,
      "eval_f1": 0.16091441467042503,
      "eval_loss": 0.1608150750398636,
      "eval_matthews_correlation": 0.3804781512105604,
      "eval_precision": 0.1199147395757928,
      "eval_recall": 0.24451676526130509,
      "eval_runtime": 124.3143,
      "eval_samples_per_second": 696.332,
      "eval_steps_per_second": 43.527,
      "step": 21644
    },
    {
      "epoch": 4.010349288486417,
      "grad_norm": 0.36669936776161194,
      "learning_rate": 1.770948068748845e-05,
      "loss": 0.1963,
      "step": 21700
    },
    {
      "epoch": 4.028830160783589,
      "grad_norm": 32.7929573059082,
      "learning_rate": 1.7598595453705413e-05,
      "loss": 0.2021,
      "step": 21800
    },
    {
      "epoch": 4.047311033080762,
      "grad_norm": 2.829829692840576,
      "learning_rate": 1.748771021992238e-05,
      "loss": 0.2393,
      "step": 21900
    },
    {
      "epoch": 4.0657919053779334,
      "grad_norm": 0.6036340594291687,
      "learning_rate": 1.7376824986139344e-05,
      "loss": 0.1649,
      "step": 22000
    },
    {
      "epoch": 4.084272777675106,
      "grad_norm": 13.083638191223145,
      "learning_rate": 1.726593975235631e-05,
      "loss": 0.2139,
      "step": 22100
    },
    {
      "epoch": 4.1027536499722785,
      "grad_norm": 0.22144338488578796,
      "learning_rate": 1.7155054518573274e-05,
      "loss": 0.1671,
      "step": 22200
    },
    {
      "epoch": 4.121234522269451,
      "grad_norm": 23.05162811279297,
      "learning_rate": 1.7044169284790245e-05,
      "loss": 0.1768,
      "step": 22300
    },
    {
      "epoch": 4.139715394566624,
      "grad_norm": 0.09289250522851944,
      "learning_rate": 1.6933284051007208e-05,
      "loss": 0.1436,
      "step": 22400
    },
    {
      "epoch": 4.158196266863796,
      "grad_norm": 0.2535798251628876,
      "learning_rate": 1.6822398817224175e-05,
      "loss": 0.2114,
      "step": 22500
    },
    {
      "epoch": 4.176677139160969,
      "grad_norm": 1.1816754341125488,
      "learning_rate": 1.671151358344114e-05,
      "loss": 0.1917,
      "step": 22600
    },
    {
      "epoch": 4.19515801145814,
      "grad_norm": 0.11162790656089783,
      "learning_rate": 1.6600628349658106e-05,
      "loss": 0.1697,
      "step": 22700
    },
    {
      "epoch": 4.213638883755313,
      "grad_norm": 0.2668299376964569,
      "learning_rate": 1.6489743115875073e-05,
      "loss": 0.1282,
      "step": 22800
    },
    {
      "epoch": 4.2321197560524855,
      "grad_norm": 0.16078278422355652,
      "learning_rate": 1.6378857882092036e-05,
      "loss": 0.2298,
      "step": 22900
    },
    {
      "epoch": 4.250600628349658,
      "grad_norm": 0.1449366956949234,
      "learning_rate": 1.6267972648309003e-05,
      "loss": 0.1909,
      "step": 23000
    },
    {
      "epoch": 4.269081500646831,
      "grad_norm": 7.269837379455566,
      "learning_rate": 1.6157087414525967e-05,
      "loss": 0.1769,
      "step": 23100
    },
    {
      "epoch": 4.287562372944003,
      "grad_norm": 0.16041935980319977,
      "learning_rate": 1.6046202180742934e-05,
      "loss": 0.1888,
      "step": 23200
    },
    {
      "epoch": 4.306043245241176,
      "grad_norm": 0.0984489917755127,
      "learning_rate": 1.5935316946959898e-05,
      "loss": 0.2042,
      "step": 23300
    },
    {
      "epoch": 4.324524117538348,
      "grad_norm": 1.1378363370895386,
      "learning_rate": 1.5824431713176865e-05,
      "loss": 0.1679,
      "step": 23400
    },
    {
      "epoch": 4.34300498983552,
      "grad_norm": 0.14705082774162292,
      "learning_rate": 1.5713546479393828e-05,
      "loss": 0.21,
      "step": 23500
    },
    {
      "epoch": 4.361485862132692,
      "grad_norm": 4.385036468505859,
      "learning_rate": 1.5602661245610795e-05,
      "loss": 0.2012,
      "step": 23600
    },
    {
      "epoch": 4.379966734429865,
      "grad_norm": 71.06240844726562,
      "learning_rate": 1.549177601182776e-05,
      "loss": 0.1764,
      "step": 23700
    },
    {
      "epoch": 4.3984476067270375,
      "grad_norm": 10.771673202514648,
      "learning_rate": 1.5380890778044726e-05,
      "loss": 0.167,
      "step": 23800
    },
    {
      "epoch": 4.41692847902421,
      "grad_norm": 0.24831193685531616,
      "learning_rate": 1.527000554426169e-05,
      "loss": 0.2109,
      "step": 23900
    },
    {
      "epoch": 4.435409351321383,
      "grad_norm": 66.8711166381836,
      "learning_rate": 1.5159120310478656e-05,
      "loss": 0.1716,
      "step": 24000
    },
    {
      "epoch": 4.453890223618555,
      "grad_norm": 12.416913986206055,
      "learning_rate": 1.5048235076695622e-05,
      "loss": 0.1991,
      "step": 24100
    },
    {
      "epoch": 4.472371095915728,
      "grad_norm": 0.31459498405456543,
      "learning_rate": 1.4937349842912587e-05,
      "loss": 0.2186,
      "step": 24200
    },
    {
      "epoch": 4.490851968212899,
      "grad_norm": 6.036839962005615,
      "learning_rate": 1.4826464609129552e-05,
      "loss": 0.2017,
      "step": 24300
    },
    {
      "epoch": 4.509332840510072,
      "grad_norm": 4.514939785003662,
      "learning_rate": 1.4715579375346517e-05,
      "loss": 0.1566,
      "step": 24400
    },
    {
      "epoch": 4.527813712807244,
      "grad_norm": 0.11578355729579926,
      "learning_rate": 1.4604694141563483e-05,
      "loss": 0.1729,
      "step": 24500
    },
    {
      "epoch": 4.546294585104417,
      "grad_norm": 0.17008687555789948,
      "learning_rate": 1.4493808907780448e-05,
      "loss": 0.1625,
      "step": 24600
    },
    {
      "epoch": 4.5647754574015895,
      "grad_norm": 0.5389946103096008,
      "learning_rate": 1.4382923673997413e-05,
      "loss": 0.2002,
      "step": 24700
    },
    {
      "epoch": 4.583256329698762,
      "grad_norm": 0.21792776882648468,
      "learning_rate": 1.4272038440214379e-05,
      "loss": 0.2515,
      "step": 24800
    },
    {
      "epoch": 4.601737201995935,
      "grad_norm": 9.082592964172363,
      "learning_rate": 1.4161153206431344e-05,
      "loss": 0.1405,
      "step": 24900
    },
    {
      "epoch": 4.620218074293106,
      "grad_norm": 0.2443970888853073,
      "learning_rate": 1.4050267972648309e-05,
      "loss": 0.1756,
      "step": 25000
    },
    {
      "epoch": 4.638698946590279,
      "grad_norm": 21.528057098388672,
      "learning_rate": 1.3939382738865274e-05,
      "loss": 0.1847,
      "step": 25100
    },
    {
      "epoch": 4.657179818887451,
      "grad_norm": 0.11166098713874817,
      "learning_rate": 1.382849750508224e-05,
      "loss": 0.1969,
      "step": 25200
    },
    {
      "epoch": 4.675660691184624,
      "grad_norm": 38.49563217163086,
      "learning_rate": 1.3717612271299205e-05,
      "loss": 0.1847,
      "step": 25300
    },
    {
      "epoch": 4.6941415634817965,
      "grad_norm": 0.36529672145843506,
      "learning_rate": 1.3606727037516172e-05,
      "loss": 0.25,
      "step": 25400
    },
    {
      "epoch": 4.712622435778969,
      "grad_norm": 16.464696884155273,
      "learning_rate": 1.3495841803733137e-05,
      "loss": 0.1832,
      "step": 25500
    },
    {
      "epoch": 4.7311033080761415,
      "grad_norm": 0.125541552901268,
      "learning_rate": 1.3384956569950103e-05,
      "loss": 0.1414,
      "step": 25600
    },
    {
      "epoch": 4.749584180373313,
      "grad_norm": 2.359182834625244,
      "learning_rate": 1.3274071336167068e-05,
      "loss": 0.1768,
      "step": 25700
    },
    {
      "epoch": 4.768065052670486,
      "grad_norm": 0.1639224737882614,
      "learning_rate": 1.3163186102384033e-05,
      "loss": 0.2206,
      "step": 25800
    },
    {
      "epoch": 4.786545924967658,
      "grad_norm": 0.19270357489585876,
      "learning_rate": 1.3052300868600998e-05,
      "loss": 0.1721,
      "step": 25900
    },
    {
      "epoch": 4.805026797264831,
      "grad_norm": 6.301055431365967,
      "learning_rate": 1.2941415634817964e-05,
      "loss": 0.1826,
      "step": 26000
    },
    {
      "epoch": 4.823507669562003,
      "grad_norm": 2.9428672790527344,
      "learning_rate": 1.2830530401034929e-05,
      "loss": 0.1622,
      "step": 26100
    },
    {
      "epoch": 4.841988541859176,
      "grad_norm": 11.402495384216309,
      "learning_rate": 1.2719645167251894e-05,
      "loss": 0.1621,
      "step": 26200
    },
    {
      "epoch": 4.8604694141563485,
      "grad_norm": 18.64242172241211,
      "learning_rate": 1.260875993346886e-05,
      "loss": 0.1661,
      "step": 26300
    },
    {
      "epoch": 4.87895028645352,
      "grad_norm": 67.34082794189453,
      "learning_rate": 1.2497874699685825e-05,
      "loss": 0.2051,
      "step": 26400
    },
    {
      "epoch": 4.897431158750693,
      "grad_norm": 0.4645291268825531,
      "learning_rate": 1.238698946590279e-05,
      "loss": 0.201,
      "step": 26500
    },
    {
      "epoch": 4.915912031047865,
      "grad_norm": 5.566276550292969,
      "learning_rate": 1.2276104232119755e-05,
      "loss": 0.1616,
      "step": 26600
    },
    {
      "epoch": 4.934392903345038,
      "grad_norm": 0.11664743721485138,
      "learning_rate": 1.216521899833672e-05,
      "loss": 0.1513,
      "step": 26700
    },
    {
      "epoch": 4.95287377564221,
      "grad_norm": 0.2672179341316223,
      "learning_rate": 1.2054333764553686e-05,
      "loss": 0.1238,
      "step": 26800
    }
  ],
  "logging_steps": 100,
  "max_steps": 27055,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 400,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.497411975153152e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
