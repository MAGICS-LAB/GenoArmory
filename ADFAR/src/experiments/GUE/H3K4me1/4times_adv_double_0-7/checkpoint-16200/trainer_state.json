{
  "best_metric": 0.5396860241889954,
  "best_model_checkpoint": "output_zhihan_softmax1_Full_double/zhihan_softmax1_dnabert2_Full_double_H3K4me1/checkpoint-2800",
  "epoch": 4.954128440366972,
  "eval_steps": 200,
  "global_step": 16200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06313131313131314,
      "grad_norm": 3.1383445262908936,
      "learning_rate": 2.968098681412165e-05,
      "loss": 0.6572,
      "step": 100
    },
    {
      "epoch": 0.12626262626262627,
      "grad_norm": 2.3163554668426514,
      "learning_rate": 2.904934070608252e-05,
      "loss": 0.6169,
      "step": 200
    },
    {
      "epoch": 0.12626262626262627,
      "eval_accuracy": 0.6960227272727273,
      "eval_f1": 0.6910730811227024,
      "eval_loss": 0.60232013463974,
      "eval_matthews_correlation": 0.38710271127396806,
      "eval_precision": 0.6965240111944919,
      "eval_recall": 0.6906236649721114,
      "eval_runtime": 2.3555,
      "eval_samples_per_second": 1344.955,
      "eval_steps_per_second": 42.03,
      "step": 200
    },
    {
      "epoch": 0.1893939393939394,
      "grad_norm": 3.474822521209717,
      "learning_rate": 2.841131433432582e-05,
      "loss": 0.631,
      "step": 300
    },
    {
      "epoch": 0.25252525252525254,
      "grad_norm": 2.8896164894104004,
      "learning_rate": 2.777328796256912e-05,
      "loss": 0.612,
      "step": 400
    },
    {
      "epoch": 0.25252525252525254,
      "eval_accuracy": 0.7083333333333334,
      "eval_f1": 0.7033154681304782,
      "eval_loss": 0.5893991589546204,
      "eval_matthews_correlation": 0.41229923979488414,
      "eval_precision": 0.7096009943581022,
      "eval_recall": 0.7027550771598574,
      "eval_runtime": 2.1275,
      "eval_samples_per_second": 1489.046,
      "eval_steps_per_second": 46.533,
      "step": 400
    },
    {
      "epoch": 0.31565656565656564,
      "grad_norm": 10.085884094238281,
      "learning_rate": 2.713526159081242e-05,
      "loss": 0.5866,
      "step": 500
    },
    {
      "epoch": 0.3787878787878788,
      "grad_norm": 3.071683168411255,
      "learning_rate": 2.6497235219055724e-05,
      "loss": 0.6152,
      "step": 600
    },
    {
      "epoch": 0.3787878787878788,
      "eval_accuracy": 0.7190656565656566,
      "eval_f1": 0.716724537037037,
      "eval_loss": 0.5762286186218262,
      "eval_matthews_correlation": 0.4342421356342076,
      "eval_precision": 0.7180533821697335,
      "eval_recall": 0.7161927396904317,
      "eval_runtime": 2.1206,
      "eval_samples_per_second": 1493.891,
      "eval_steps_per_second": 46.684,
      "step": 600
    },
    {
      "epoch": 0.44191919191919193,
      "grad_norm": 6.2907023429870605,
      "learning_rate": 2.585920884729902e-05,
      "loss": 0.6031,
      "step": 700
    },
    {
      "epoch": 0.5050505050505051,
      "grad_norm": 2.455796003341675,
      "learning_rate": 2.5221182475542324e-05,
      "loss": 0.6221,
      "step": 800
    },
    {
      "epoch": 0.5050505050505051,
      "eval_accuracy": 0.5246212121212122,
      "eval_f1": 0.3739909212434401,
      "eval_loss": 0.6505450010299683,
      "eval_matthews_correlation": -0.03071211935495984,
      "eval_precision": 0.4623392824030035,
      "eval_recall": 0.493738606594232,
      "eval_runtime": 2.1198,
      "eval_samples_per_second": 1494.498,
      "eval_steps_per_second": 46.703,
      "step": 800
    },
    {
      "epoch": 0.5681818181818182,
      "grad_norm": 4.136030673980713,
      "learning_rate": 2.4583156103785624e-05,
      "loss": 0.5839,
      "step": 900
    },
    {
      "epoch": 0.6313131313131313,
      "grad_norm": 3.3695545196533203,
      "learning_rate": 2.3945129732028924e-05,
      "loss": 0.5944,
      "step": 1000
    },
    {
      "epoch": 0.6313131313131313,
      "eval_accuracy": 0.7212752525252525,
      "eval_f1": 0.7189362527948437,
      "eval_loss": 0.5802462100982666,
      "eval_matthews_correlation": 0.43868977797155845,
      "eval_precision": 0.7203029000796468,
      "eval_recall": 0.7183910439072281,
      "eval_runtime": 2.1248,
      "eval_samples_per_second": 1490.933,
      "eval_steps_per_second": 46.592,
      "step": 1000
    },
    {
      "epoch": 0.6944444444444444,
      "grad_norm": 2.6315524578094482,
      "learning_rate": 2.3307103360272227e-05,
      "loss": 0.5798,
      "step": 1100
    },
    {
      "epoch": 0.7575757575757576,
      "grad_norm": 5.670069694519043,
      "learning_rate": 2.2669076988515524e-05,
      "loss": 0.5865,
      "step": 1200
    },
    {
      "epoch": 0.7575757575757576,
      "eval_accuracy": 0.7178030303030303,
      "eval_f1": 0.7177665848723578,
      "eval_loss": 0.5721508860588074,
      "eval_matthews_correlation": 0.4445307824047615,
      "eval_precision": 0.7226669377688,
      "eval_recall": 0.7218645687652221,
      "eval_runtime": 2.1248,
      "eval_samples_per_second": 1490.944,
      "eval_steps_per_second": 46.592,
      "step": 1200
    },
    {
      "epoch": 0.8207070707070707,
      "grad_norm": 1.9423964023590088,
      "learning_rate": 2.2037430880476392e-05,
      "loss": 0.5694,
      "step": 1300
    },
    {
      "epoch": 0.8838383838383839,
      "grad_norm": 5.98557186126709,
      "learning_rate": 2.1399404508719695e-05,
      "loss": 0.5967,
      "step": 1400
    },
    {
      "epoch": 0.8838383838383839,
      "eval_accuracy": 0.7402146464646465,
      "eval_f1": 0.7377519054312649,
      "eval_loss": 0.5519833564758301,
      "eval_matthews_correlation": 0.4767964179810539,
      "eval_precision": 0.7397726094507374,
      "eval_recall": 0.7370316867305384,
      "eval_runtime": 2.1105,
      "eval_samples_per_second": 1501.062,
      "eval_steps_per_second": 46.908,
      "step": 1400
    },
    {
      "epoch": 0.946969696969697,
      "grad_norm": 3.9237401485443115,
      "learning_rate": 2.0761378136962995e-05,
      "loss": 0.575,
      "step": 1500
    },
    {
      "epoch": 1.0101010101010102,
      "grad_norm": 8.550392150878906,
      "learning_rate": 2.0123351765206295e-05,
      "loss": 0.5682,
      "step": 1600
    },
    {
      "epoch": 1.0101010101010102,
      "eval_accuracy": 0.7279040404040404,
      "eval_f1": 0.7261436054886485,
      "eval_loss": 0.5649011731147766,
      "eval_matthews_correlation": 0.4525212134486787,
      "eval_precision": 0.7267222175990081,
      "eval_recall": 0.7257999356984506,
      "eval_runtime": 2.1077,
      "eval_samples_per_second": 1503.075,
      "eval_steps_per_second": 46.971,
      "step": 1600
    },
    {
      "epoch": 1.0732323232323233,
      "grad_norm": 2.5579609870910645,
      "learning_rate": 1.94853253934496e-05,
      "loss": 0.4993,
      "step": 1700
    },
    {
      "epoch": 1.1363636363636362,
      "grad_norm": 3.9324870109558105,
      "learning_rate": 1.8847299021692896e-05,
      "loss": 0.5241,
      "step": 1800
    },
    {
      "epoch": 1.1363636363636362,
      "eval_accuracy": 0.7361111111111112,
      "eval_f1": 0.7355181748568265,
      "eval_loss": 0.5619482398033142,
      "eval_matthews_correlation": 0.4716391742929344,
      "eval_precision": 0.7353676820461972,
      "eval_recall": 0.7362723599028991,
      "eval_runtime": 2.109,
      "eval_samples_per_second": 1502.138,
      "eval_steps_per_second": 46.942,
      "step": 1800
    },
    {
      "epoch": 1.1994949494949494,
      "grad_norm": 3.083857536315918,
      "learning_rate": 1.82092726499362e-05,
      "loss": 0.5271,
      "step": 1900
    },
    {
      "epoch": 1.2626262626262625,
      "grad_norm": 3.467256784439087,
      "learning_rate": 1.7571246278179496e-05,
      "loss": 0.5103,
      "step": 2000
    },
    {
      "epoch": 1.2626262626262625,
      "eval_accuracy": 0.7462121212121212,
      "eval_f1": 0.7407461089605059,
      "eval_loss": 0.5690697431564331,
      "eval_matthews_correlation": 0.49080607392362297,
      "eval_precision": 0.751158654396596,
      "eval_recall": 0.7397793167620046,
      "eval_runtime": 2.139,
      "eval_samples_per_second": 1481.046,
      "eval_steps_per_second": 46.283,
      "step": 2000
    },
    {
      "epoch": 1.3257575757575757,
      "grad_norm": 5.059469223022461,
      "learning_rate": 1.69332199064228e-05,
      "loss": 0.5319,
      "step": 2100
    },
    {
      "epoch": 1.3888888888888888,
      "grad_norm": 7.155796051025391,
      "learning_rate": 1.6295193534666102e-05,
      "loss": 0.5222,
      "step": 2200
    },
    {
      "epoch": 1.3888888888888888,
      "eval_accuracy": 0.7503156565656566,
      "eval_f1": 0.747948672170268,
      "eval_loss": 0.5646663904190063,
      "eval_matthews_correlation": 0.497208045477307,
      "eval_precision": 0.750037261204282,
      "eval_recall": 0.7471789997385497,
      "eval_runtime": 2.1424,
      "eval_samples_per_second": 1478.685,
      "eval_steps_per_second": 46.209,
      "step": 2200
    },
    {
      "epoch": 1.452020202020202,
      "grad_norm": 11.075698852539062,
      "learning_rate": 1.56571671629094e-05,
      "loss": 0.4648,
      "step": 2300
    },
    {
      "epoch": 1.5151515151515151,
      "grad_norm": 9.892295837402344,
      "learning_rate": 1.50191407911527e-05,
      "loss": 0.4975,
      "step": 2400
    },
    {
      "epoch": 1.5151515151515151,
      "eval_accuracy": 0.7395833333333334,
      "eval_f1": 0.7304548574280901,
      "eval_loss": 0.5674094557762146,
      "eval_matthews_correlation": 0.4822053405967674,
      "eval_precision": 0.7522090007360415,
      "eval_recall": 0.7304854206446411,
      "eval_runtime": 2.1394,
      "eval_samples_per_second": 1480.767,
      "eval_steps_per_second": 46.274,
      "step": 2400
    },
    {
      "epoch": 1.5782828282828283,
      "grad_norm": 5.559296131134033,
      "learning_rate": 1.4381114419396e-05,
      "loss": 0.5221,
      "step": 2500
    },
    {
      "epoch": 1.6414141414141414,
      "grad_norm": 12.308276176452637,
      "learning_rate": 1.3743088047639304e-05,
      "loss": 0.4973,
      "step": 2600
    },
    {
      "epoch": 1.6414141414141414,
      "eval_accuracy": 0.7436868686868687,
      "eval_f1": 0.7432136308751845,
      "eval_loss": 0.5722022652626038,
      "eval_matthews_correlation": 0.487331646541714,
      "eval_precision": 0.7431500090701953,
      "eval_recall": 0.7441827317107936,
      "eval_runtime": 2.1403,
      "eval_samples_per_second": 1480.143,
      "eval_steps_per_second": 46.254,
      "step": 2600
    },
    {
      "epoch": 1.7045454545454546,
      "grad_norm": 5.126482009887695,
      "learning_rate": 1.3105061675882604e-05,
      "loss": 0.5041,
      "step": 2700
    },
    {
      "epoch": 1.7676767676767677,
      "grad_norm": 8.62969970703125,
      "learning_rate": 1.2467035304125904e-05,
      "loss": 0.5144,
      "step": 2800
    },
    {
      "epoch": 1.7676767676767677,
      "eval_accuracy": 0.7528409090909091,
      "eval_f1": 0.7493285651530545,
      "eval_loss": 0.5396860241889954,
      "eval_matthews_correlation": 0.5026307123991284,
      "eval_precision": 0.7544091001595252,
      "eval_recall": 0.7482592337385345,
      "eval_runtime": 2.1068,
      "eval_samples_per_second": 1503.727,
      "eval_steps_per_second": 46.991,
      "step": 2800
    },
    {
      "epoch": 1.8308080808080809,
      "grad_norm": 1.8933181762695312,
      "learning_rate": 1.1829008932369204e-05,
      "loss": 0.5023,
      "step": 2900
    },
    {
      "epoch": 1.893939393939394,
      "grad_norm": 14.945592880249023,
      "learning_rate": 1.1190982560612506e-05,
      "loss": 0.4856,
      "step": 3000
    },
    {
      "epoch": 1.893939393939394,
      "eval_accuracy": 0.7541035353535354,
      "eval_f1": 0.7502204156009409,
      "eval_loss": 0.5511727333068848,
      "eval_matthews_correlation": 0.5054858731148476,
      "eval_precision": 0.7564399335232669,
      "eval_recall": 0.749099237790413,
      "eval_runtime": 2.1159,
      "eval_samples_per_second": 1497.244,
      "eval_steps_per_second": 46.789,
      "step": 3000
    },
    {
      "epoch": 1.9570707070707072,
      "grad_norm": 4.8177170753479,
      "learning_rate": 1.0552956188855806e-05,
      "loss": 0.5178,
      "step": 3100
    },
    {
      "epoch": 2.0202020202020203,
      "grad_norm": 7.30759859085083,
      "learning_rate": 9.914929817099106e-06,
      "loss": 0.4682,
      "step": 3200
    },
    {
      "epoch": 2.0202020202020203,
      "eval_accuracy": 0.7509469696969697,
      "eval_f1": 0.7480621245011869,
      "eval_loss": 0.5700451731681824,
      "eval_matthews_correlation": 0.498502448216811,
      "eval_precision": 0.7513929437218152,
      "eval_recall": 0.7471277506829537,
      "eval_runtime": 2.1084,
      "eval_samples_per_second": 1502.575,
      "eval_steps_per_second": 46.955,
      "step": 3200
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 6.495081901550293,
      "learning_rate": 9.276903445342408e-06,
      "loss": 0.4142,
      "step": 3300
    },
    {
      "epoch": 2.1464646464646466,
      "grad_norm": 14.332377433776855,
      "learning_rate": 8.63887707358571e-06,
      "loss": 0.4307,
      "step": 3400
    },
    {
      "epoch": 2.1464646464646466,
      "eval_accuracy": 0.7496843434343434,
      "eval_f1": 0.7485261009535636,
      "eval_loss": 0.5842530727386475,
      "eval_matthews_correlation": 0.49705235222267813,
      "eval_precision": 0.7485368736666089,
      "eval_recall": 0.7485154790165146,
      "eval_runtime": 2.1025,
      "eval_samples_per_second": 1506.777,
      "eval_steps_per_second": 47.087,
      "step": 3400
    },
    {
      "epoch": 2.20959595959596,
      "grad_norm": 3.5677707195281982,
      "learning_rate": 8.00085070182901e-06,
      "loss": 0.3698,
      "step": 3500
    },
    {
      "epoch": 2.2727272727272725,
      "grad_norm": 16.940933227539062,
      "learning_rate": 7.36282433007231e-06,
      "loss": 0.4039,
      "step": 3600
    },
    {
      "epoch": 2.2727272727272725,
      "eval_accuracy": 0.7537878787878788,
      "eval_f1": 0.7517361111111112,
      "eval_loss": 0.5904290676116943,
      "eval_matthews_correlation": 0.5043044727998031,
      "eval_precision": 0.7532349740236927,
      "eval_recall": 0.7510741281554705,
      "eval_runtime": 2.1032,
      "eval_samples_per_second": 1506.278,
      "eval_steps_per_second": 47.071,
      "step": 3600
    },
    {
      "epoch": 2.3358585858585856,
      "grad_norm": 6.403995513916016,
      "learning_rate": 6.7311782220331774e-06,
      "loss": 0.3961,
      "step": 3700
    },
    {
      "epoch": 2.398989898989899,
      "grad_norm": 5.500329494476318,
      "learning_rate": 6.093151850276478e-06,
      "loss": 0.4184,
      "step": 3800
    },
    {
      "epoch": 2.398989898989899,
      "eval_accuracy": 0.7566287878787878,
      "eval_f1": 0.7541986267685042,
      "eval_loss": 0.5978012084960938,
      "eval_matthews_correlation": 0.5099577927958553,
      "eval_precision": 0.7566185631229236,
      "eval_recall": 0.7533497063389076,
      "eval_runtime": 2.1079,
      "eval_samples_per_second": 1502.904,
      "eval_steps_per_second": 46.966,
      "step": 3800
    },
    {
      "epoch": 2.462121212121212,
      "grad_norm": 7.748726844787598,
      "learning_rate": 5.455125478519779e-06,
      "loss": 0.3782,
      "step": 3900
    },
    {
      "epoch": 2.525252525252525,
      "grad_norm": 8.471091270446777,
      "learning_rate": 4.817099106763079e-06,
      "loss": 0.3794,
      "step": 4000
    },
    {
      "epoch": 2.525252525252525,
      "eval_accuracy": 0.7582070707070707,
      "eval_f1": 0.7561638098560668,
      "eval_loss": 0.5804193019866943,
      "eval_matthews_correlation": 0.5132108919600235,
      "eval_precision": 0.7577451953431275,
      "eval_recall": 0.755470736589063,
      "eval_runtime": 2.1007,
      "eval_samples_per_second": 1508.056,
      "eval_steps_per_second": 47.127,
      "step": 4000
    },
    {
      "epoch": 2.5883838383838382,
      "grad_norm": 11.508504867553711,
      "learning_rate": 4.179072735006381e-06,
      "loss": 0.3778,
      "step": 4100
    },
    {
      "epoch": 2.6515151515151514,
      "grad_norm": 3.4895243644714355,
      "learning_rate": 3.541046363249681e-06,
      "loss": 0.3848,
      "step": 4200
    },
    {
      "epoch": 2.6515151515151514,
      "eval_accuracy": 0.7588383838383839,
      "eval_f1": 0.7565068604777968,
      "eval_loss": 0.5827147960662842,
      "eval_matthews_correlation": 0.5144270550110038,
      "eval_precision": 0.7587597610386705,
      "eval_recall": 0.7556765335779408,
      "eval_runtime": 2.1029,
      "eval_samples_per_second": 1506.461,
      "eval_steps_per_second": 47.077,
      "step": 4200
    },
    {
      "epoch": 2.7146464646464645,
      "grad_norm": 11.495115280151367,
      "learning_rate": 2.903019991492982e-06,
      "loss": 0.3811,
      "step": 4300
    },
    {
      "epoch": 2.7777777777777777,
      "grad_norm": 5.7667131423950195,
      "learning_rate": 2.2649936197362827e-06,
      "loss": 0.3838,
      "step": 4400
    },
    {
      "epoch": 2.7777777777777777,
      "eval_accuracy": 0.7582070707070707,
      "eval_f1": 0.7553221008343711,
      "eval_loss": 0.586246132850647,
      "eval_matthews_correlation": 0.5132436623604298,
      "eval_precision": 0.7589505753832118,
      "eval_recall": 0.754314029388931,
      "eval_runtime": 2.1417,
      "eval_samples_per_second": 1479.19,
      "eval_steps_per_second": 46.225,
      "step": 4400
    },
    {
      "epoch": 2.840909090909091,
      "grad_norm": 20.969825744628906,
      "learning_rate": 1.6333475116971502e-06,
      "loss": 0.4026,
      "step": 4500
    },
    {
      "epoch": 2.904040404040404,
      "grad_norm": 7.024044036865234,
      "learning_rate": 9.953211399404509e-07,
      "loss": 0.3867,
      "step": 4600
    },
    {
      "epoch": 2.904040404040404,
      "eval_accuracy": 0.757260101010101,
      "eval_f1": 0.7551658103337814,
      "eval_loss": 0.5867707133293152,
      "eval_matthews_correlation": 0.5112850546588565,
      "eval_precision": 0.7568354307606509,
      "eval_recall": 0.7544551644834435,
      "eval_runtime": 2.1118,
      "eval_samples_per_second": 1500.177,
      "eval_steps_per_second": 46.881,
      "step": 4600
    },
    {
      "epoch": 2.967171717171717,
      "grad_norm": 10.60425090789795,
      "learning_rate": 3.572947681837516e-07,
      "loss": 0.3761,
      "step": 4700
    },
    {
      "epoch": 3.0,
      "step": 4752,
      "total_flos": 6027885076807680.0,
      "train_loss": 0.500490463141239,
      "train_runtime": 329.4701,
      "train_samples_per_second": 230.743,
      "train_steps_per_second": 14.423
    },
    {
      "epoch": 1.4678899082568808,
      "grad_norm": 6.4162139892578125,
      "learning_rate": 2.991192660550459e-05,
      "loss": 0.9037,
      "step": 4800
    },
    {
      "epoch": 1.4984709480122325,
      "grad_norm": 4.81260871887207,
      "learning_rate": 2.972844036697248e-05,
      "loss": 0.6618,
      "step": 4900
    },
    {
      "epoch": 1.529051987767584,
      "grad_norm": 7.543307304382324,
      "learning_rate": 2.9544954128440366e-05,
      "loss": 0.5834,
      "step": 5000
    },
    {
      "epoch": 1.5596330275229358,
      "grad_norm": 17.19959259033203,
      "learning_rate": 2.936146788990826e-05,
      "loss": 0.6026,
      "step": 5100
    },
    {
      "epoch": 1.5902140672782874,
      "grad_norm": 8.793458938598633,
      "learning_rate": 2.9177981651376148e-05,
      "loss": 0.6292,
      "step": 5200
    },
    {
      "epoch": 1.620795107033639,
      "grad_norm": 2.7289183139801025,
      "learning_rate": 2.8994495412844036e-05,
      "loss": 0.5931,
      "step": 5300
    },
    {
      "epoch": 1.6513761467889907,
      "grad_norm": 16.311416625976562,
      "learning_rate": 2.8811009174311927e-05,
      "loss": 0.6225,
      "step": 5400
    },
    {
      "epoch": 1.6819571865443423,
      "grad_norm": 12.734640121459961,
      "learning_rate": 2.8627522935779818e-05,
      "loss": 0.5427,
      "step": 5500
    },
    {
      "epoch": 1.7125382262996942,
      "grad_norm": 19.89996337890625,
      "learning_rate": 2.8444036697247706e-05,
      "loss": 0.5171,
      "step": 5600
    },
    {
      "epoch": 1.7431192660550459,
      "grad_norm": 15.903168678283691,
      "learning_rate": 2.8260550458715597e-05,
      "loss": 0.568,
      "step": 5700
    },
    {
      "epoch": 1.7737003058103975,
      "grad_norm": 5.69429349899292,
      "learning_rate": 2.8077064220183488e-05,
      "loss": 0.5817,
      "step": 5800
    },
    {
      "epoch": 1.8042813455657494,
      "grad_norm": 9.758621215820312,
      "learning_rate": 2.7893577981651376e-05,
      "loss": 0.5761,
      "step": 5900
    },
    {
      "epoch": 1.834862385321101,
      "grad_norm": 6.180515766143799,
      "learning_rate": 2.7710091743119267e-05,
      "loss": 0.5768,
      "step": 6000
    },
    {
      "epoch": 1.8654434250764527,
      "grad_norm": 4.010777473449707,
      "learning_rate": 2.7526605504587158e-05,
      "loss": 0.5659,
      "step": 6100
    },
    {
      "epoch": 1.8960244648318043,
      "grad_norm": 16.873458862304688,
      "learning_rate": 2.7343119266055045e-05,
      "loss": 0.6153,
      "step": 6200
    },
    {
      "epoch": 1.926605504587156,
      "grad_norm": 7.096156120300293,
      "learning_rate": 2.7159633027522937e-05,
      "loss": 0.5333,
      "step": 6300
    },
    {
      "epoch": 1.9571865443425076,
      "grad_norm": 19.22159194946289,
      "learning_rate": 2.6976146788990828e-05,
      "loss": 0.524,
      "step": 6400
    },
    {
      "epoch": 1.9877675840978593,
      "grad_norm": 7.841849327087402,
      "learning_rate": 2.6792660550458715e-05,
      "loss": 0.5401,
      "step": 6500
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.4271406727828746,
      "eval_f1": 0.1436386872235237,
      "eval_loss": 0.4440760314464569,
      "eval_matthews_correlation": 0.29753084714949046,
      "eval_precision": 0.10657442563959146,
      "eval_recall": 0.22026547544629535,
      "eval_runtime": 246.9058,
      "eval_samples_per_second": 211.903,
      "eval_steps_per_second": 13.244,
      "step": 6540
    },
    {
      "epoch": 2.018348623853211,
      "grad_norm": 16.028942108154297,
      "learning_rate": 2.6609174311926606e-05,
      "loss": 0.4733,
      "step": 6600
    },
    {
      "epoch": 2.0489296636085625,
      "grad_norm": 4.918104648590088,
      "learning_rate": 2.6425688073394497e-05,
      "loss": 0.4748,
      "step": 6700
    },
    {
      "epoch": 2.079510703363914,
      "grad_norm": 14.212108612060547,
      "learning_rate": 2.6242201834862385e-05,
      "loss": 0.5106,
      "step": 6800
    },
    {
      "epoch": 2.1100917431192663,
      "grad_norm": 10.530710220336914,
      "learning_rate": 2.6058715596330276e-05,
      "loss": 0.4585,
      "step": 6900
    },
    {
      "epoch": 2.140672782874618,
      "grad_norm": 6.178066730499268,
      "learning_rate": 2.5875229357798167e-05,
      "loss": 0.4277,
      "step": 7000
    },
    {
      "epoch": 2.1712538226299696,
      "grad_norm": 12.792125701904297,
      "learning_rate": 2.5691743119266055e-05,
      "loss": 0.4311,
      "step": 7100
    },
    {
      "epoch": 2.2018348623853212,
      "grad_norm": 39.225460052490234,
      "learning_rate": 2.5508256880733946e-05,
      "loss": 0.4632,
      "step": 7200
    },
    {
      "epoch": 2.232415902140673,
      "grad_norm": 4.748155117034912,
      "learning_rate": 2.5324770642201837e-05,
      "loss": 0.4453,
      "step": 7300
    },
    {
      "epoch": 2.2629969418960245,
      "grad_norm": 14.984720230102539,
      "learning_rate": 2.5141284403669725e-05,
      "loss": 0.3848,
      "step": 7400
    },
    {
      "epoch": 2.293577981651376,
      "grad_norm": 11.967732429504395,
      "learning_rate": 2.4957798165137616e-05,
      "loss": 0.4636,
      "step": 7500
    },
    {
      "epoch": 2.324159021406728,
      "grad_norm": 20.539630889892578,
      "learning_rate": 2.4774311926605504e-05,
      "loss": 0.4002,
      "step": 7600
    },
    {
      "epoch": 2.3547400611620795,
      "grad_norm": 62.29936599731445,
      "learning_rate": 2.4590825688073395e-05,
      "loss": 0.4309,
      "step": 7700
    },
    {
      "epoch": 2.385321100917431,
      "grad_norm": 14.069901466369629,
      "learning_rate": 2.4407339449541286e-05,
      "loss": 0.415,
      "step": 7800
    },
    {
      "epoch": 2.4159021406727827,
      "grad_norm": 11.133625030517578,
      "learning_rate": 2.4223853211009173e-05,
      "loss": 0.4099,
      "step": 7900
    },
    {
      "epoch": 2.4464831804281344,
      "grad_norm": 5.421441078186035,
      "learning_rate": 2.4040366972477065e-05,
      "loss": 0.4244,
      "step": 8000
    },
    {
      "epoch": 2.477064220183486,
      "grad_norm": 19.151762008666992,
      "learning_rate": 2.3856880733944956e-05,
      "loss": 0.3936,
      "step": 8100
    },
    {
      "epoch": 2.5076452599388377,
      "grad_norm": 12.210060119628906,
      "learning_rate": 2.3673394495412843e-05,
      "loss": 0.4215,
      "step": 8200
    },
    {
      "epoch": 2.5382262996941893,
      "grad_norm": 5.601890563964844,
      "learning_rate": 2.3489908256880734e-05,
      "loss": 0.4395,
      "step": 8300
    },
    {
      "epoch": 2.5688073394495414,
      "grad_norm": 9.987518310546875,
      "learning_rate": 2.3306422018348625e-05,
      "loss": 0.397,
      "step": 8400
    },
    {
      "epoch": 2.599388379204893,
      "grad_norm": 5.579559326171875,
      "learning_rate": 2.3122935779816513e-05,
      "loss": 0.3807,
      "step": 8500
    },
    {
      "epoch": 2.6299694189602447,
      "grad_norm": 29.31226921081543,
      "learning_rate": 2.2939449541284404e-05,
      "loss": 0.398,
      "step": 8600
    },
    {
      "epoch": 2.6605504587155964,
      "grad_norm": 22.55412483215332,
      "learning_rate": 2.2755963302752295e-05,
      "loss": 0.3755,
      "step": 8700
    },
    {
      "epoch": 2.691131498470948,
      "grad_norm": 4.903454303741455,
      "learning_rate": 2.2572477064220183e-05,
      "loss": 0.4097,
      "step": 8800
    },
    {
      "epoch": 2.7217125382262997,
      "grad_norm": 26.79241180419922,
      "learning_rate": 2.2388990825688074e-05,
      "loss": 0.3447,
      "step": 8900
    },
    {
      "epoch": 2.7522935779816513,
      "grad_norm": 20.37042236328125,
      "learning_rate": 2.2205504587155965e-05,
      "loss": 0.3734,
      "step": 9000
    },
    {
      "epoch": 2.782874617737003,
      "grad_norm": 9.403592109680176,
      "learning_rate": 2.2022018348623853e-05,
      "loss": 0.3643,
      "step": 9100
    },
    {
      "epoch": 2.8134556574923546,
      "grad_norm": 5.724164009094238,
      "learning_rate": 2.1838532110091744e-05,
      "loss": 0.3699,
      "step": 9200
    },
    {
      "epoch": 2.8440366972477067,
      "grad_norm": 8.105557441711426,
      "learning_rate": 2.1655045871559635e-05,
      "loss": 0.3693,
      "step": 9300
    },
    {
      "epoch": 2.8746177370030583,
      "grad_norm": 12.502534866333008,
      "learning_rate": 2.1471559633027523e-05,
      "loss": 0.351,
      "step": 9400
    },
    {
      "epoch": 2.90519877675841,
      "grad_norm": 20.680490493774414,
      "learning_rate": 2.1288073394495414e-05,
      "loss": 0.3056,
      "step": 9500
    },
    {
      "epoch": 2.9357798165137616,
      "grad_norm": 31.837631225585938,
      "learning_rate": 2.1104587155963305e-05,
      "loss": 0.3663,
      "step": 9600
    },
    {
      "epoch": 2.9663608562691133,
      "grad_norm": 30.25406837463379,
      "learning_rate": 2.0921100917431192e-05,
      "loss": 0.3507,
      "step": 9700
    },
    {
      "epoch": 2.996941896024465,
      "grad_norm": 11.861286163330078,
      "learning_rate": 2.073761467889908e-05,
      "loss": 0.3668,
      "step": 9800
    },
    {
      "epoch": 3.0,
      "eval_accuracy": 0.4672018348623853,
      "eval_f1": 0.15745508420558713,
      "eval_loss": 0.20473438501358032,
      "eval_matthews_correlation": 0.3627660895412828,
      "eval_precision": 0.11711280663918582,
      "eval_recall": 0.24054598656166462,
      "eval_runtime": 82.0902,
      "eval_samples_per_second": 637.348,
      "eval_steps_per_second": 39.834,
      "step": 9810
    },
    {
      "epoch": 3.0275229357798166,
      "grad_norm": 0.4280887544155121,
      "learning_rate": 2.0554128440366975e-05,
      "loss": 0.2826,
      "step": 9900
    },
    {
      "epoch": 3.058103975535168,
      "grad_norm": 2.3291800022125244,
      "learning_rate": 2.0370642201834862e-05,
      "loss": 0.219,
      "step": 10000
    },
    {
      "epoch": 3.08868501529052,
      "grad_norm": 45.33566665649414,
      "learning_rate": 2.018715596330275e-05,
      "loss": 0.2413,
      "step": 10100
    },
    {
      "epoch": 3.1192660550458715,
      "grad_norm": 5.058300971984863,
      "learning_rate": 2.0003669724770644e-05,
      "loss": 0.1872,
      "step": 10200
    },
    {
      "epoch": 3.149847094801223,
      "grad_norm": 22.941274642944336,
      "learning_rate": 1.9820183486238532e-05,
      "loss": 0.2392,
      "step": 10300
    },
    {
      "epoch": 3.180428134556575,
      "grad_norm": 20.375797271728516,
      "learning_rate": 1.963669724770642e-05,
      "loss": 0.2384,
      "step": 10400
    },
    {
      "epoch": 3.2110091743119265,
      "grad_norm": 32.37256622314453,
      "learning_rate": 1.9453211009174314e-05,
      "loss": 0.218,
      "step": 10500
    },
    {
      "epoch": 3.241590214067278,
      "grad_norm": 3.6392571926116943,
      "learning_rate": 1.9269724770642202e-05,
      "loss": 0.2311,
      "step": 10600
    },
    {
      "epoch": 3.2721712538226297,
      "grad_norm": 42.25991439819336,
      "learning_rate": 1.908623853211009e-05,
      "loss": 0.2365,
      "step": 10700
    },
    {
      "epoch": 3.302752293577982,
      "grad_norm": 11.912979125976562,
      "learning_rate": 1.8902752293577984e-05,
      "loss": 0.2516,
      "step": 10800
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.2851061522960663,
      "learning_rate": 1.8719266055045872e-05,
      "loss": 0.2753,
      "step": 10900
    },
    {
      "epoch": 3.363914373088685,
      "grad_norm": 1.859310507774353,
      "learning_rate": 1.853577981651376e-05,
      "loss": 0.1814,
      "step": 11000
    },
    {
      "epoch": 3.3944954128440368,
      "grad_norm": 13.925020217895508,
      "learning_rate": 1.8352293577981654e-05,
      "loss": 0.2603,
      "step": 11100
    },
    {
      "epoch": 3.4250764525993884,
      "grad_norm": 1.5014088153839111,
      "learning_rate": 1.816880733944954e-05,
      "loss": 0.2234,
      "step": 11200
    },
    {
      "epoch": 3.45565749235474,
      "grad_norm": 2.6470603942871094,
      "learning_rate": 1.798532110091743e-05,
      "loss": 0.2368,
      "step": 11300
    },
    {
      "epoch": 3.4862385321100917,
      "grad_norm": 29.099014282226562,
      "learning_rate": 1.7801834862385324e-05,
      "loss": 0.2571,
      "step": 11400
    },
    {
      "epoch": 3.5168195718654434,
      "grad_norm": 0.7732654213905334,
      "learning_rate": 1.761834862385321e-05,
      "loss": 0.1987,
      "step": 11500
    },
    {
      "epoch": 3.547400611620795,
      "grad_norm": 23.85601806640625,
      "learning_rate": 1.74348623853211e-05,
      "loss": 0.2131,
      "step": 11600
    },
    {
      "epoch": 3.5779816513761467,
      "grad_norm": 16.43851089477539,
      "learning_rate": 1.725137614678899e-05,
      "loss": 0.2402,
      "step": 11700
    },
    {
      "epoch": 3.6085626911314987,
      "grad_norm": 0.3112352192401886,
      "learning_rate": 1.706788990825688e-05,
      "loss": 0.1839,
      "step": 11800
    },
    {
      "epoch": 3.6391437308868504,
      "grad_norm": 14.063289642333984,
      "learning_rate": 1.688440366972477e-05,
      "loss": 0.2217,
      "step": 11900
    },
    {
      "epoch": 3.669724770642202,
      "grad_norm": 49.23537826538086,
      "learning_rate": 1.670091743119266e-05,
      "loss": 0.2455,
      "step": 12000
    },
    {
      "epoch": 3.7003058103975537,
      "grad_norm": 0.826170027256012,
      "learning_rate": 1.651743119266055e-05,
      "loss": 0.1924,
      "step": 12100
    },
    {
      "epoch": 3.7308868501529053,
      "grad_norm": 42.59464645385742,
      "learning_rate": 1.633394495412844e-05,
      "loss": 0.1941,
      "step": 12200
    },
    {
      "epoch": 3.761467889908257,
      "grad_norm": 66.84709167480469,
      "learning_rate": 1.615045871559633e-05,
      "loss": 0.2407,
      "step": 12300
    },
    {
      "epoch": 3.7920489296636086,
      "grad_norm": 0.28782933950424194,
      "learning_rate": 1.596697247706422e-05,
      "loss": 0.2098,
      "step": 12400
    },
    {
      "epoch": 3.8226299694189603,
      "grad_norm": 45.648799896240234,
      "learning_rate": 1.5783486238532112e-05,
      "loss": 0.2332,
      "step": 12500
    },
    {
      "epoch": 3.853211009174312,
      "grad_norm": 10.940828323364258,
      "learning_rate": 1.56e-05,
      "loss": 0.2611,
      "step": 12600
    },
    {
      "epoch": 3.8837920489296636,
      "grad_norm": 17.44097900390625,
      "learning_rate": 1.541651376146789e-05,
      "loss": 0.1902,
      "step": 12700
    },
    {
      "epoch": 3.914373088685015,
      "grad_norm": 0.13379602134227753,
      "learning_rate": 1.5233027522935782e-05,
      "loss": 0.1643,
      "step": 12800
    },
    {
      "epoch": 3.944954128440367,
      "grad_norm": 2.08229660987854,
      "learning_rate": 1.5049541284403671e-05,
      "loss": 0.1523,
      "step": 12900
    },
    {
      "epoch": 3.9755351681957185,
      "grad_norm": 70.01237487792969,
      "learning_rate": 1.4866055045871559e-05,
      "loss": 0.2417,
      "step": 13000
    },
    {
      "epoch": 4.0,
      "eval_accuracy": 0.48056192660550456,
      "eval_f1": 0.16188356270926732,
      "eval_loss": 0.10354822129011154,
      "eval_matthews_correlation": 0.38421446985843855,
      "eval_precision": 0.12015490814959959,
      "eval_recall": 0.24801879969089946,
      "eval_runtime": 81.9982,
      "eval_samples_per_second": 638.063,
      "eval_steps_per_second": 39.879,
      "step": 13080
    },
    {
      "epoch": 4.00611620795107,
      "grad_norm": 38.751800537109375,
      "learning_rate": 1.468256880733945e-05,
      "loss": 0.1706,
      "step": 13100
    },
    {
      "epoch": 4.036697247706422,
      "grad_norm": 0.1611298769712448,
      "learning_rate": 1.4499082568807341e-05,
      "loss": 0.1552,
      "step": 13200
    },
    {
      "epoch": 4.0672782874617734,
      "grad_norm": 45.25079345703125,
      "learning_rate": 1.4315596330275229e-05,
      "loss": 0.1355,
      "step": 13300
    },
    {
      "epoch": 4.097859327217125,
      "grad_norm": 0.15382997691631317,
      "learning_rate": 1.413211009174312e-05,
      "loss": 0.1227,
      "step": 13400
    },
    {
      "epoch": 4.128440366972477,
      "grad_norm": 0.09726107865571976,
      "learning_rate": 1.394862385321101e-05,
      "loss": 0.1301,
      "step": 13500
    },
    {
      "epoch": 4.159021406727828,
      "grad_norm": 23.81094741821289,
      "learning_rate": 1.3765137614678899e-05,
      "loss": 0.1637,
      "step": 13600
    },
    {
      "epoch": 4.18960244648318,
      "grad_norm": 29.35542106628418,
      "learning_rate": 1.358165137614679e-05,
      "loss": 0.1301,
      "step": 13700
    },
    {
      "epoch": 4.220183486238533,
      "grad_norm": 91.87478637695312,
      "learning_rate": 1.3398165137614679e-05,
      "loss": 0.1056,
      "step": 13800
    },
    {
      "epoch": 4.250764525993883,
      "grad_norm": 0.04725905880331993,
      "learning_rate": 1.3214678899082568e-05,
      "loss": 0.1285,
      "step": 13900
    },
    {
      "epoch": 4.281345565749236,
      "grad_norm": 0.3191286623477936,
      "learning_rate": 1.303119266055046e-05,
      "loss": 0.1342,
      "step": 14000
    },
    {
      "epoch": 4.3119266055045875,
      "grad_norm": 0.03901318460702896,
      "learning_rate": 1.2847706422018349e-05,
      "loss": 0.0864,
      "step": 14100
    },
    {
      "epoch": 4.342507645259939,
      "grad_norm": 5.5962138175964355,
      "learning_rate": 1.2664220183486238e-05,
      "loss": 0.1963,
      "step": 14200
    },
    {
      "epoch": 4.373088685015291,
      "grad_norm": 85.1167221069336,
      "learning_rate": 1.248073394495413e-05,
      "loss": 0.1006,
      "step": 14300
    },
    {
      "epoch": 4.4036697247706424,
      "grad_norm": 92.5989990234375,
      "learning_rate": 1.2297247706422019e-05,
      "loss": 0.1413,
      "step": 14400
    },
    {
      "epoch": 4.434250764525994,
      "grad_norm": 0.051676273345947266,
      "learning_rate": 1.2113761467889908e-05,
      "loss": 0.1417,
      "step": 14500
    },
    {
      "epoch": 4.464831804281346,
      "grad_norm": 0.232178196310997,
      "learning_rate": 1.1930275229357797e-05,
      "loss": 0.1062,
      "step": 14600
    },
    {
      "epoch": 4.495412844036697,
      "grad_norm": 11.630694389343262,
      "learning_rate": 1.1746788990825689e-05,
      "loss": 0.1392,
      "step": 14700
    },
    {
      "epoch": 4.525993883792049,
      "grad_norm": 0.0488157644867897,
      "learning_rate": 1.1563302752293578e-05,
      "loss": 0.1265,
      "step": 14800
    },
    {
      "epoch": 4.556574923547401,
      "grad_norm": 26.103981018066406,
      "learning_rate": 1.1379816513761467e-05,
      "loss": 0.1303,
      "step": 14900
    },
    {
      "epoch": 4.587155963302752,
      "grad_norm": 0.8490622043609619,
      "learning_rate": 1.1196330275229358e-05,
      "loss": 0.1627,
      "step": 15000
    },
    {
      "epoch": 4.617737003058104,
      "grad_norm": 0.4062414765357971,
      "learning_rate": 1.1012844036697248e-05,
      "loss": 0.085,
      "step": 15100
    },
    {
      "epoch": 4.648318042813456,
      "grad_norm": 22.830564498901367,
      "learning_rate": 1.0829357798165137e-05,
      "loss": 0.1326,
      "step": 15200
    },
    {
      "epoch": 4.678899082568807,
      "grad_norm": 0.1473451405763626,
      "learning_rate": 1.0645871559633028e-05,
      "loss": 0.1055,
      "step": 15300
    },
    {
      "epoch": 4.709480122324159,
      "grad_norm": 0.0477285273373127,
      "learning_rate": 1.046238532110092e-05,
      "loss": 0.1536,
      "step": 15400
    },
    {
      "epoch": 4.740061162079511,
      "grad_norm": 0.14092282950878143,
      "learning_rate": 1.0278899082568807e-05,
      "loss": 0.1322,
      "step": 15500
    },
    {
      "epoch": 4.770642201834862,
      "grad_norm": 1.1088982820510864,
      "learning_rate": 1.0095412844036698e-05,
      "loss": 0.1271,
      "step": 15600
    },
    {
      "epoch": 4.801223241590214,
      "grad_norm": 0.028065722435712814,
      "learning_rate": 9.911926605504587e-06,
      "loss": 0.1352,
      "step": 15700
    },
    {
      "epoch": 4.8318042813455655,
      "grad_norm": 0.06367191672325134,
      "learning_rate": 9.728440366972477e-06,
      "loss": 0.0976,
      "step": 15800
    },
    {
      "epoch": 4.862385321100917,
      "grad_norm": 0.02838100865483284,
      "learning_rate": 9.544954128440368e-06,
      "loss": 0.093,
      "step": 15900
    },
    {
      "epoch": 4.892966360856269,
      "grad_norm": 58.58302307128906,
      "learning_rate": 9.361467889908257e-06,
      "loss": 0.1288,
      "step": 16000
    },
    {
      "epoch": 4.92354740061162,
      "grad_norm": 0.042225372046232224,
      "learning_rate": 9.177981651376147e-06,
      "loss": 0.1497,
      "step": 16100
    },
    {
      "epoch": 4.954128440366972,
      "grad_norm": 25.260408401489258,
      "learning_rate": 8.994495412844038e-06,
      "loss": 0.1254,
      "step": 16200
    }
  ],
  "logging_steps": 100,
  "max_steps": 16350,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 5,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.205386056502477e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
