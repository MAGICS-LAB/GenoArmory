{
  "tasks": [
    "H3"
  ],
  "model": "dnabert",
  "attack_methods": "pgd",
  "attack_model_type": "dnabert",
  "base_dir": "GUE",
  "target_model_path": "magicslabnu/DNABERT-2-finetuned-H3",
  "tokenizer_path": "zhihan1996/DNABERT-2-117M",
  "output_dir_base": "test/FreeLB",
  "attack_script_path": "PGD/pgd.py",
  "num_label": 2,
  "n_gpu": 1,
  "max_seq_length": 256,
  "adv_lr": 1e-1,
  "adv_init_mag": 6e-1,
  "adv_max_norm": 0,
  "adv_steps": 2,
  "lr": 1e-5,
  "batch_size": 32,
  "gradient_accumulation_steps": 1,
  "hidden_dropout_prob": 0.1,
  "attention_probs_dropout_prob": 0,
  "max_steps": 2000,
  "warmup_steps": 100,
  "seed": 42,
  "weight_decay": 1e-2,
  "gpu": 0,
  "project_root": "./FreeLB/huggingface-transformers",
  "log_dir": "./logs",
  "ckpt_dir": "./checkpoints",
  "gue_dir": "./GUE",
  "test_script_path": "PGD/pgd.py"
}